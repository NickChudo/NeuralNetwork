{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5321255,"sourceType":"datasetVersion","datasetId":3091651},{"sourceId":5618710,"sourceType":"datasetVersion","datasetId":3230790},{"sourceId":5677279,"sourceType":"datasetVersion","datasetId":2989949},{"sourceId":5677449,"sourceType":"datasetVersion","datasetId":3071831},{"sourceId":5760288,"sourceType":"datasetVersion","datasetId":3311237},{"sourceId":8003942,"sourceType":"datasetVersion","datasetId":4230886},{"sourceId":8065936,"sourceType":"datasetVersion","datasetId":3213578}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np \nimport matplotlib\nfrom transformers import AutoModelForSeq2SeqLM, T5TokenizerFast\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n\"\"\"TO-DO:\n- накрутить в предикт исправление предсказаний корректором ошибок, из train\\test убрать корректор\n- сделать разделение на train/valid/test\n- прогнать модель с корректором на тестовом наборе\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:50:29.638137Z","iopub.execute_input":"2024-04-28T15:50:29.639329Z","iopub.status.idle":"2024-04-28T15:50:34.653709Z","shell.execute_reply.started":"2024-04-28T15:50:29.639241Z","shell.execute_reply":"2024-04-28T15:50:34.651746Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'TO-DO:\\n- накрутить в предикт исправление предсказаний корректором ошибок, из train\\test убрать корректор\\n- сделать разделение на train/valid/test\\n- прогнать модель с корректором на тестовом наборе'"},"metadata":{}}]},{"cell_type":"code","source":"def avg_wer(wer_scores, combined_ref_len):\n    return float(sum(wer_scores)) / float(combined_ref_len)\n\n\ndef _levenshtein_distance(ref, hyp):\n    m = len(ref)\n    n = len(hyp)\n\n    # special case\n    if ref == hyp:\n        return 0\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n\n    if m < n:\n        ref, hyp = hyp, ref\n        m, n = n, m\n\n    distance = np.zeros((2, n + 1), dtype=np.int32)\n\n    for j in range(0,n + 1):\n        distance[0][j] = j\n\n    for i in range(1, m + 1):\n        prev_row_idx = (i - 1) % 2\n        cur_row_idx = i % 2\n        distance[cur_row_idx][0] = i\n        for j in range(1, n + 1):\n            if ref[i - 1] == hyp[j - 1]:\n                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n            else:\n                s_num = distance[prev_row_idx][j - 1] + 1\n                i_num = distance[cur_row_idx][j - 1] + 1\n                d_num = distance[prev_row_idx][j] + 1\n                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n\n    return distance[m % 2][n]\n\n\ndef word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    ref_words = reference.split(delimiter)\n    hyp_words = hypothesis.split(delimiter)\n\n    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n    return float(edit_distance), len(ref_words)\n\n\ndef char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    join_char = ' '\n    if remove_space == True:\n        join_char = ''\n\n    reference = join_char.join(filter(None, reference.split(' ')))\n    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n\n    edit_distance = _levenshtein_distance(reference, hypothesis)\n    return float(edit_distance), len(reference)\n\n\ndef wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n                                         delimiter)\n\n    if ref_len == 0:\n        raise ValueError(\"Reference's word number should be greater than 0.\")\n\n    wer = float(edit_distance) / ref_len\n    return wer\n\n\ndef cer(reference, hypothesis, ignore_case=False, remove_space=False):\n    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n                                         remove_space)\n\n    if ref_len == 0:\n        raise ValueError(\"Length of reference should be greater than 0.\")\n\n    cer = float(edit_distance) / ref_len\n    return cer\n\nclass TextTransform:\n    def __init__(self):\n        self.char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n                  \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n                  \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n                  \"я\": 31, \"х\": 32, \" \": 33}\n\n        self.index_map = {}\n        for key, value in self.char_map.items():\n            self.index_map[value] = key\n\n    def text_to_int(self, text):\n        int_sequence = []\n        for c in text:\n            ch = self.char_map[c]\n            int_sequence.append(ch)\n        return int_sequence\n\n    def int_to_text(self, labels):\n        string = []\n        for i in labels:\n            string.append(self.index_map[i])\n        return ''.join(string)\n\n\ntrain_audio_transforms = nn.Sequential(\n    torchaudio.transforms.MFCC(n_mfcc=20)\n)\n\n\nvalid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n\ntext_transform = TextTransform()\n\ndef data_processing(data, data_type=\"train\"):\n    spectrograms = []\n    labels = []\n    input_lengths = []\n    label_lengths = []\n    for (waveform, utterance) in data:\n        if data_type == 'train':\n            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        elif data_type == 'valid':\n            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        else:\n            raise Exception('data_type should be train or valid')\n        spectrograms.append(spec)\n        label = torch.Tensor(text_transform.text_to_int(utterance))\n        labels.append(label)\n        input_lengths.append(spec.shape[0]//3)\n        label_lengths.append(len(label))\n    \n    spectrograms1 = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n            \n    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n\n    return spectrograms1, labels, input_lengths, label_lengths\n\n\ndef GreedyDecoder(output, labels, label_lengths, blank_label=34, collapse_repeated=True):\n    arg_maxes = torch.argmax(output, dim=2)\n    decodes = []\n    targets = []\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n        for j, index in enumerate(args):\n            if index != blank_label:\n                if collapse_repeated and j != 0 and index == args[j -1]:\n                    continue\n                decode.append(index.item())\n        decodes.append(text_transform.int_to_text(decode))\n    return decodes, targets","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:50:36.549631Z","iopub.execute_input":"2024-04-28T15:50:36.550372Z","iopub.status.idle":"2024-04-28T15:50:36.703300Z","shell.execute_reply.started":"2024-04-28T15:50:36.550329Z","shell.execute_reply":"2024-04-28T15:50:36.702211Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"class BidirectionalGRU(nn.Module):\n\n    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n        super(BidirectionalGRU, self).__init__()\n\n        self.BiGRU = nn.GRU(\n            input_size=rnn_dim, hidden_size=hidden_size,\n            num_layers=1, batch_first=batch_first, bidirectional=True)\n        self.layer_norm = nn.LayerNorm(rnn_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        x = F.gelu(x)\n        x, _ = self.BiGRU(x)\n        x = self.dropout(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:50:39.665353Z","iopub.execute_input":"2024-04-28T15:50:39.666514Z","iopub.status.idle":"2024-04-28T15:50:39.675903Z","shell.execute_reply.started":"2024-04-28T15:50:39.666454Z","shell.execute_reply":"2024-04-28T15:50:39.674182Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Поменял там, где происходит загрузка, сохраняется id звукового файла, а потом в excel файле по колонке old_id ищется текст\n#И того звук и текст к нему\n\nimport pandas as pd\nimport librosa\n\nfile = pd.read_excel('/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches v1.xlsx')\n#y = [sentence for sentence in file['text']]\ny = []\ndir_name = \"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"\nfiles_in_dir = os.listdir(dir_name)\n\nX = []\ni = 1\n\nfor e in os.listdir(\"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"):\n    file_name = e\n    for old_id in range(0, 2073):\n        if file_name.startswith(str(file['old_id'][old_id]) + '.'):\n            y.extend([''.join(file['text'][old_id])])\n            sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n            sampl = sampl[np.newaxis, :]\n            X.append(torch.Tensor(sampl))\n            break","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:50:42.869746Z","iopub.execute_input":"2024-04-28T15:50:42.870350Z","iopub.status.idle":"2024-04-28T15:52:48.613116Z","shell.execute_reply.started":"2024-04-28T15:50:42.870269Z","shell.execute_reply":"2024-04-28T15:52:48.611409Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import random\npairs = list(zip(X, y))\nrandom.Random(42).shuffle(pairs)\nX, y = zip(*pairs)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:52:57.563197Z","iopub.execute_input":"2024-04-28T15:52:57.564644Z","iopub.status.idle":"2024-04-28T15:52:57.578629Z","shell.execute_reply.started":"2024-04-28T15:52:57.564584Z","shell.execute_reply":"2024-04-28T15:52:57.577199Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y[:3]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:00.021248Z","iopub.execute_input":"2024-04-28T15:53:00.021784Z","iopub.status.idle":"2024-04-28T15:53:00.030410Z","shell.execute_reply.started":"2024-04-28T15:53:00.021741Z","shell.execute_reply":"2024-04-28T15:53:00.028911Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Твоя новая прическа выглядит отлично!',\n 'Бабочки порхают',\n 'Соединённые Штаты Америки - чуть поменьше.')"},"metadata":{}}]},{"cell_type":"code","source":"X[:3]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:05.702413Z","iopub.execute_input":"2024-04-28T15:53:05.702843Z","iopub.status.idle":"2024-04-28T15:53:05.728409Z","shell.execute_reply.started":"2024-04-28T15:53:05.702805Z","shell.execute_reply":"2024-04-28T15:53:05.726466Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 7.0572e-06, -8.0303e-06,  8.9534e-06,  ...,  6.0889e-05,\n          -1.5082e-04,  0.0000e+00]]),\n tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0016, -0.0016, -0.0040]]),\n tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0003, -0.0011,  0.0000]]))"},"metadata":{}}]},{"cell_type":"code","source":"torchaudio.save('/kaggle/working/audio.wav', X[540], 16000)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:52:46.826831Z","iopub.execute_input":"2024-04-02T14:52:46.827791Z","iopub.status.idle":"2024-04-02T14:52:46.834792Z","shell.execute_reply.started":"2024-04-02T14:52:46.827746Z","shell.execute_reply":"2024-04-02T14:52:46.833811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = torchaudio.load('/kaggle/working/audio.wav')  # Загрузка аудиофайла\ntorchaudio.play(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:22:15.368540Z","iopub.execute_input":"2024-04-02T07:22:15.368969Z","iopub.status.idle":"2024-04-02T07:22:15.395250Z","shell.execute_reply.started":"2024-04-02T07:22:15.368930Z","shell.execute_reply":"2024-04-02T07:22:15.393666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n            \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n            \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n            \"я\": 31, \"х\": 32, \" \": 33}\n\ndef remove_characters(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.replace('4', 'четыре').replace('Р-220', 'р двести двадцать').replace('6', 'шесть').replace(\"-\", \" \")\n    sentence = ''.join(filter(lambda x: x in char_map, sentence))\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ny = list(map(remove_characters, y))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:10.230557Z","iopub.execute_input":"2024-04-28T15:53:10.231069Z","iopub.status.idle":"2024-04-28T15:53:10.270990Z","shell.execute_reply.started":"2024-04-28T15:53:10.231026Z","shell.execute_reply":"2024-04-28T15:53:10.269638Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\"\"\"#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nX_train = X[:1800]\nX_test = X[1800:]\ny_train = y[:1800]\ny_test = y[1800:]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:37:46.667673Z","iopub.execute_input":"2024-04-23T15:37:46.668626Z","iopub.status.idle":"2024-04-23T15:37:46.902039Z","shell.execute_reply.started":"2024-04-23T15:37:46.668577Z","shell.execute_reply":"2024-04-23T15:37:46.901064Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\\nX_train = X[:1800]\\nX_test = X[1800:]\\ny_train = y[:1800]\\ny_test = y[1800:]'"},"metadata":{}}]},{"cell_type":"code","source":"X_train = X[:2430]\nX_test = X[2430:]\ny_train = y[:2430]\ny_test = y[2430:]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:14.321647Z","iopub.execute_input":"2024-04-28T15:53:14.322188Z","iopub.status.idle":"2024-04-28T15:53:14.330362Z","shell.execute_reply.started":"2024-04-28T15:53:14.322139Z","shell.execute_reply":"2024-04-28T15:53:14.328691Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass AudioDataset(Dataset):\n    def __init__(self, audio_list, text_list):\n        self.audio_list = audio_list\n        self.text_list = text_list\n        \n    def __len__(self):\n        return len(self.text_list)\n    \n    def __getitem__(self, index):\n        audio = self.audio_list[index]\n        text = self.text_list[index]\n        return audio, text","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:16.374063Z","iopub.execute_input":"2024-04-28T15:53:16.374608Z","iopub.status.idle":"2024-04-28T15:53:16.385728Z","shell.execute_reply.started":"2024-04-28T15:53:16.374556Z","shell.execute_reply":"2024-04-28T15:53:16.383356Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class SpeechRecognitionModel1(nn.Module):\n    def __init__(self, num_classes):\n        super(SpeechRecognitionModel1, self).__init__()\n        self.conv = nn.Sequential(\n            nn.BatchNorm2d(1),\n            nn.Conv2d(1, 32, kernel_size=(4,4), stride=(3,3), padding=(2,2)),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n            nn.Conv2d(128, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n        )\n        \n        self.fc_1 = nn.Sequential(\n            nn.Linear(896, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n        )\n        \n        self.BiGRU_1 = BidirectionalGRU(270, 270, 0, True)\n        self.BiGRU_2 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_3 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_4 = BidirectionalGRU(540, 270, 0.5, True)\n        \n        self.fc_2 = nn.Sequential(\n            nn.Linear(540, num_classes),\n        )\n        self.softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.view(x.size(0), x.size(1), -1)\n        x = self.fc_1(x)\n        x = self.BiGRU_1(x)\n        x = self.BiGRU_2(x)\n        x = self.BiGRU_3(x)\n        x = self.BiGRU_4(x)\n        x = self.fc_2(x)\n        x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:16.729134Z","iopub.execute_input":"2024-04-28T15:53:16.729719Z","iopub.status.idle":"2024-04-28T15:53:16.750476Z","shell.execute_reply.started":"2024-04-28T15:53:16.729672Z","shell.execute_reply":"2024-04-28T15:53:16.749289Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"TOKENIZERS_PARALLELISM=True","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:14:12.214440Z","iopub.execute_input":"2024-04-04T16:14:12.215402Z","iopub.status.idle":"2024-04-04T16:14:12.220648Z","shell.execute_reply.started":"2024-04-04T16:14:12.215355Z","shell.execute_reply":"2024-04-04T16:14:12.219629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Зададим название выбронной модели из хаба\nMODEL_NAME = 'UrukHan/t5-russian-spell'\nMAX_INPUT = 256\n\n# Загрузка модели и токенизатора\ntokenizer = T5TokenizerFast.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n\n# Входные данные (можно массив фраз или текст)\ninput_sequences = 'сеглдыя хорош ден'   # или можно использовать одиночные фразы:  input_sequences = 'сеглдыя хорош ден'","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:13:34.768051Z","iopub.execute_input":"2024-04-04T16:13:34.769406Z","iopub.status.idle":"2024-04-04T16:13:50.721738Z","shell.execute_reply.started":"2024-04-04T16:13:34.769360Z","shell.execute_reply":"2024-04-04T16:13:50.720460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"task_prefix = \"Spell correct: \"                 # Токенизирование данных\nif type(input_sequences) != list: input_sequences = [input_sequences]\nencoded = tokenizer(\n  [task_prefix + sequence for sequence in input_sequences],\n  padding=\"longest\",\n  max_length=MAX_INPUT,\n  truncation=True,\n  return_tensors=\"pt\",\n)   # # Прогнозирование","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:13:50.724069Z","iopub.execute_input":"2024-04-04T16:13:50.724428Z","iopub.status.idle":"2024-04-04T16:13:50.736359Z","shell.execute_reply.started":"2024-04-04T16:13:50.724380Z","shell.execute_reply":"2024-04-04T16:13:50.735263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts = model.generate(**encoded.to(device))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:13:52.768924Z","iopub.execute_input":"2024-04-04T16:13:52.770010Z","iopub.status.idle":"2024-04-04T16:13:56.523644Z","shell.execute_reply.started":"2024-04-04T16:13:52.769955Z","shell.execute_reply":"2024-04-04T16:13:56.522572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]  # Декодируем данные","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:14:16.919739Z","iopub.execute_input":"2024-04-04T16:14:16.920586Z","iopub.status.idle":"2024-04-04T16:14:19.686824Z","shell.execute_reply.started":"2024-04-04T16:14:16.920544Z","shell.execute_reply":"2024-04-04T16:14:19.685743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOKENIZERS_PARALLELISM=True","metadata":{"execution":{"iopub.status.busy":"2024-04-22T14:30:30.812195Z","iopub.execute_input":"2024-04-22T14:30:30.813150Z","iopub.status.idle":"2024-04-22T14:30:30.817675Z","shell.execute_reply.started":"2024-04-22T14:30:30.813103Z","shell.execute_reply":"2024-04-22T14:30:30.816503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Зададим название выбронной модели из хаба\nMODEL_NAME = 'UrukHan/t5-russian-spell'\nMAX_INPUT = 256\n\n# Загрузка модели и токенизатора\ntokenizer = T5TokenizerFast.from_pretrained(MODEL_NAME)\ncorrector = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:53:31.476087Z","iopub.execute_input":"2024-04-28T15:53:31.476691Z","iopub.status.idle":"2024-04-28T15:53:55.322687Z","shell.execute_reply.started":"2024-04-28T15:53:31.476640Z","shell.execute_reply":"2024-04-28T15:53:55.320978Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32993a48c1d840bcab6ab9023023cfd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b481cfde7c7348a09bf34a3bbbdd92b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/2.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b5df5befa040cb9fadd00569905ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6cee0fe60a42aab531c6fb76925736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91999fcb93784e44b66157d4808a983e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca68dfdec104521ae8aeaf379a6ccfe"}},"metadata":{}}]},{"cell_type":"code","source":"class IterMeter(object):\n    def __init__(self):\n        self.val = 0\n\n    def step(self):\n        self.val += 1\n\n    def get(self):\n        return self.val\n\n\ndef train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n    model.train()\n    train_loss = 0\n    train_cer, train_wer = [], []\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data \n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms) \n        output = output.transpose(0, 1)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        train_loss += loss.item() / len(train_loader)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        iter_meter.step()\n        if batch_idx % 20 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n        for j in range(len(decoded_preds)):\n            # убрать корректор отсюда и докинуть его в predict\n    \n            input_sequences = decoded_preds[j]\n            \n            task_prefix = \"Spell correct: \"\n            \n            #TOKENIZERS_PARALLELISM=True\n            \n            if type(input_sequences) != list: input_sequences = [input_sequences]\n            encoded = tokenizer(\n              [task_prefix + sequence for sequence in input_sequences],\n              padding=\"longest\",\n              max_length=MAX_INPUT,\n              truncation=True,\n              return_tensors=\"pt\",\n            )\n            \n            predicts = corrector.generate(**encoded.to(device))\n            # # Прогнозирование\n            \n            input_sequences = tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]\n            \n            train_cer.append(cer(decoded_targets[j], input_sequences))\n            train_wer.append(wer(decoded_targets[j], input_sequences))\n    \n    avg_cer = sum(train_cer)/len(train_cer)\n    avg_wer = sum(train_wer)/len(train_wer)\n            \n    print('Train set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(train_loss, avg_cer, avg_wer))\n            \n    \n\ndef test(model, device, test_loader, criterion, epoch, iter_meter):\n    print('\\nevaluating...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data \n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n            \n            output = model(spectrograms)\n            output = output.transpose(0, 1)\n            \n            loss = criterion(output, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n            \n            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n            for j in range(len(decoded_preds)):\n                # убрать корректор отсюда и докинуть его в predict\n                input_sequences = decoded_preds[j]\n                \n                task_prefix = \"Spell correct: \"\n                \n                if type(input_sequences) != list: input_sequences = [input_sequences]\n                encoded = tokenizer(\n                  [task_prefix + sequence for sequence in input_sequences],\n                  padding=\"longest\",\n                  max_length=MAX_INPUT,\n                  truncation=True,\n                  return_tensors=\"pt\",\n                )\n\n                predicts = corrector.generate(**encoded.to(device))   # # Прогнозирование\n                \n                input_sequences = tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]\n                \n                test_cer.append(cer(decoded_targets[j], input_sequences))\n                test_wer.append(wer(decoded_targets[j], input_sequences))\n    \n   \n    avg_cer = sum(test_cer)/len(test_cer)\n    avg_wer = sum(test_wer)/len(test_wer)\n\n    median_cer = np.median(np.array(test_cer))\n    median_wer = np.median(np.array(test_wer))\n           \n    print('Test set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(test_loss, avg_cer, avg_wer, median_cer, median_wer))\n    \n\ndef main(learning_rate=5e-4, batch_size=20, epochs=10):\n\n    hparams = {\n        \"learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"epochs\": epochs\n    }\n\n    use_cuda = torch.cuda.is_available()\n    torch.manual_seed(7)\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    train_dataset = AudioDataset(X_train, y_train)\n    test_dataset = AudioDataset(X_test, y_test)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n    train_loader = data.DataLoader(dataset=train_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=True,\n                                collate_fn=lambda x: data_processing(x, 'train'),\n                                **kwargs)\n    test_loader = data.DataLoader(dataset=test_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=False,\n                                collate_fn=lambda x: data_processing(x, 'valid'),\n                                **kwargs)\n\n    model = SpeechRecognitionModel1(35).to(device)\n\n    print(model)\n    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n\n    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n    criterion = nn.CTCLoss(blank=34).to(device)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\n    \n    iter_meter = IterMeter()\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n        test(model, device, test_loader, criterion, epoch, iter_meter)\n        \n    torch.save(model, '/kaggle/working/model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T15:38:08.116253Z","iopub.execute_input":"2024-04-22T15:38:08.116695Z","iopub.status.idle":"2024-04-22T15:38:08.155610Z","shell.execute_reply.started":"2024-04-22T15:38:08.116648Z","shell.execute_reply":"2024-04-22T15:38:08.154431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IterMeter(object):\n    def __init__(self):\n        self.val = 0\n\n    def step(self):\n        self.val += 1\n\n    def get(self):\n        return self.val\n\n\ndef train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n    model.train()\n    train_loss = 0\n    train_cer, train_wer = [], []\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data \n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms) \n        output = output.transpose(0, 1)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        train_loss += loss.item() / len(train_loader)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        iter_meter.step()\n        if batch_idx % 20 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n        \"\"\"decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n        for j in range(len(decoded_preds)):\n            train_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n            train_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n    avg_cer = sum(train_cer)/len(train_cer)\n    avg_wer = sum(train_wer)/len(train_wer)\n            \n    print('Train set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(train_loss, avg_cer, avg_wer))\"\"\"\n            \n    \n\ndef test(model, device, test_loader, criterion, epoch, iter_meter):\n    print('\\nevaluating...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data \n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n            \n            output = model(spectrograms)\n            output = output.transpose(0, 1)\n            \n            loss = criterion(output, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n            \n            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n            for j in range(len(decoded_preds)):\n                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n   \n    avg_cer = sum(test_cer)/len(test_cer)\n    avg_wer = sum(test_wer)/len(test_wer)\n\n    median_cer = np.median(np.array(test_cer))\n    median_wer = np.median(np.array(test_wer))\n           \n    print('Test set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(test_loss, avg_cer, avg_wer, median_cer, median_wer))\n    \n\ndef main(learning_rate=5e-4, batch_size=20, epochs=10):\n\n    hparams = {\n        \"learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"epochs\": epochs\n    }\n\n    use_cuda = torch.cuda.is_available()\n    torch.manual_seed(7)\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    train_dataset = AudioDataset(X_train, y_train)\n    test_dataset = AudioDataset(X_test, y_test)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n    train_loader = data.DataLoader(dataset=train_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=True,\n                                collate_fn=lambda x: data_processing(x, 'train'),\n                                **kwargs)\n    test_loader = data.DataLoader(dataset=test_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=False,\n                                collate_fn=lambda x: data_processing(x, 'valid'),\n                                **kwargs)\n\n    model = SpeechRecognitionModel1(35).to(device)\n\n    print(model)\n    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n\n    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n    criterion = nn.CTCLoss(blank=34).to(device)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\n    \n    iter_meter = IterMeter()\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n        test(model, device, test_loader, criterion, epoch, iter_meter)\n        \n    torch.save(model, '/kaggle/working/model_for_correction_test.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:38:59.069560Z","iopub.execute_input":"2024-04-23T15:38:59.070464Z","iopub.status.idle":"2024-04-23T15:38:59.103759Z","shell.execute_reply.started":"2024-04-23T15:38:59.070423Z","shell.execute_reply":"2024-04-23T15:38:59.102627Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict(model, file_name, device):\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    sampl = librosa.load(file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    print(spectrogram_tensor.size())\n\n    with torch.no_grad():\n        spectrogram_tensor.to(device)\n        output = model(spectrogram_tensor)\n        print(output.size())\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n\n    return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:39:06.843911Z","iopub.execute_input":"2024-04-23T15:39:06.844840Z","iopub.status.idle":"2024-04-23T15:39:06.856677Z","shell.execute_reply.started":"2024-04-23T15:39:06.844793Z","shell.execute_reply":"2024-04-23T15:39:06.855630Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict_with_tensor(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    #sampl = librosa.load(file_name, sr=16000)[0]\n    #sampl = sampl[np.newaxis, :]\n    #sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    print(spectrogram_tensor.size())\n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    print(decodes[0])        \n    \"\"\"input_sequences = decodes[0]\n                \n    task_prefix = \"Spell correct: \"\n\n    if type(input_sequences) != list: input_sequences = [input_sequences]\n    encoded = tokenizer(\n      [task_prefix + sequence for sequence in input_sequences],\n      padding=\"longest\",\n      max_length=MAX_INPUT,\n      truncation=True,\n      return_tensors=\"pt\",\n    )\n\n    predicts = corrector.generate(**encoded.to(needed_device))   # # Прогнозирование\n\n    input_sequences = tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]\n    input_sequences = remove_characters(input_sequences)\n    print(input_sequences)\n\n    return input_sequences\"\"\"\n\n    return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:54:09.536716Z","iopub.execute_input":"2024-04-28T15:54:09.537223Z","iopub.status.idle":"2024-04-28T15:54:09.553187Z","shell.execute_reply.started":"2024-04-28T15:54:09.537181Z","shell.execute_reply":"2024-04-28T15:54:09.551718Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%%time \nlearning_rate = 0.002\nbatch_size = 20\nepochs = 100\n\nmain(learning_rate, batch_size, epochs)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-23T15:39:13.887360Z","iopub.execute_input":"2024-04-23T15:39:13.887767Z","iopub.status.idle":"2024-04-23T16:21:14.253909Z","shell.execute_reply.started":"2024-04-23T15:39:13.887728Z","shell.execute_reply":"2024-04-23T16:21:14.252471Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"SpeechRecognitionModel1(\n  (conv): Sequential(\n    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Conv2d(1, 32, kernel_size=(4, 4), stride=(3, 3), padding=(2, 2))\n    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): GELU(approximate='none')\n    (4): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): GELU(approximate='none')\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): GELU(approximate='none')\n  )\n  (fc_1): Sequential(\n    (0): Linear(in_features=896, out_features=270, bias=True)\n    (1): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Linear(in_features=270, out_features=270, bias=True)\n    (4): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (5): GELU(approximate='none')\n    (6): Linear(in_features=270, out_features=270, bias=True)\n    (7): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (8): GELU(approximate='none')\n  )\n  (BiGRU_1): BidirectionalGRU(\n    (BiGRU): GRU(270, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_2): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_3): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_4): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (fc_2): Sequential(\n    (0): Linear(in_features=540, out_features=35, bias=True)\n  )\n  (softmax): LogSoftmax(dim=2)\n)\nNum Model Parameters 5422923\nTrain Epoch: 1 [0/2430 (0%)]\tLoss: 15.914103\nTrain Epoch: 1 [400/2430 (16%)]\tLoss: 3.783211\nTrain Epoch: 1 [800/2430 (33%)]\tLoss: 3.421986\nTrain Epoch: 1 [1200/2430 (49%)]\tLoss: 3.397056\nTrain Epoch: 1 [1600/2430 (66%)]\tLoss: 3.412205\nTrain Epoch: 1 [2000/2430 (82%)]\tLoss: 3.331148\nTrain Epoch: 1 [2400/2430 (98%)]\tLoss: 3.322500\n\nevaluating...\nTest set:\tAverage loss: 3.3034, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 2 [0/2430 (0%)]\tLoss: 3.215621\nTrain Epoch: 2 [400/2430 (16%)]\tLoss: 3.350299\nTrain Epoch: 2 [800/2430 (33%)]\tLoss: 3.271542\nTrain Epoch: 2 [1200/2430 (49%)]\tLoss: 3.257287\nTrain Epoch: 2 [1600/2430 (66%)]\tLoss: 3.243409\nTrain Epoch: 2 [2000/2430 (82%)]\tLoss: 3.386810\nTrain Epoch: 2 [2400/2430 (98%)]\tLoss: 3.321886\n\nevaluating...\nTest set:\tAverage loss: 3.2473, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 3 [0/2430 (0%)]\tLoss: 3.270939\nTrain Epoch: 3 [400/2430 (16%)]\tLoss: 3.135468\nTrain Epoch: 3 [800/2430 (33%)]\tLoss: 3.090810\nTrain Epoch: 3 [1200/2430 (49%)]\tLoss: 2.987660\nTrain Epoch: 3 [1600/2430 (66%)]\tLoss: 2.893801\nTrain Epoch: 3 [2000/2430 (82%)]\tLoss: 2.793364\nTrain Epoch: 3 [2400/2430 (98%)]\tLoss: 2.659066\n\nevaluating...\nTest set:\tAverage loss: 2.6337, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 4 [0/2430 (0%)]\tLoss: 2.511607\nTrain Epoch: 4 [400/2430 (16%)]\tLoss: 2.442860\nTrain Epoch: 4 [800/2430 (33%)]\tLoss: 2.321865\nTrain Epoch: 4 [1200/2430 (49%)]\tLoss: 2.120672\nTrain Epoch: 4 [1600/2430 (66%)]\tLoss: 2.093824\nTrain Epoch: 4 [2000/2430 (82%)]\tLoss: 1.818407\nTrain Epoch: 4 [2400/2430 (98%)]\tLoss: 1.688916\n\nevaluating...\nTest set:\tAverage loss: 1.6384, Average CER: 0.530880 Average WER: 0.9913\n\nTrain Epoch: 5 [0/2430 (0%)]\tLoss: 1.883784\nTrain Epoch: 5 [400/2430 (16%)]\tLoss: 1.739164\nTrain Epoch: 5 [800/2430 (33%)]\tLoss: 1.596637\nTrain Epoch: 5 [1200/2430 (49%)]\tLoss: 1.589664\nTrain Epoch: 5 [1600/2430 (66%)]\tLoss: 1.229277\nTrain Epoch: 5 [2000/2430 (82%)]\tLoss: 1.195563\nTrain Epoch: 5 [2400/2430 (98%)]\tLoss: 1.462000\n\nevaluating...\nTest set:\tAverage loss: 1.2410, Average CER: 0.394708 Average WER: 0.9757\n\nTrain Epoch: 6 [0/2430 (0%)]\tLoss: 1.365607\nTrain Epoch: 6 [400/2430 (16%)]\tLoss: 1.151859\nTrain Epoch: 6 [800/2430 (33%)]\tLoss: 1.294096\nTrain Epoch: 6 [1200/2430 (49%)]\tLoss: 1.090973\nTrain Epoch: 6 [1600/2430 (66%)]\tLoss: 1.190919\nTrain Epoch: 6 [2000/2430 (82%)]\tLoss: 0.933165\nTrain Epoch: 6 [2400/2430 (98%)]\tLoss: 1.037659\n\nevaluating...\nTest set:\tAverage loss: 1.0680, Average CER: 0.349832 Average WER: 0.9418\n\nTrain Epoch: 7 [0/2430 (0%)]\tLoss: 0.908361\nTrain Epoch: 7 [400/2430 (16%)]\tLoss: 0.952473\nTrain Epoch: 7 [800/2430 (33%)]\tLoss: 0.943050\nTrain Epoch: 7 [1200/2430 (49%)]\tLoss: 0.991048\nTrain Epoch: 7 [1600/2430 (66%)]\tLoss: 1.004704\nTrain Epoch: 7 [2000/2430 (82%)]\tLoss: 0.972264\nTrain Epoch: 7 [2400/2430 (98%)]\tLoss: 0.736844\n\nevaluating...\nTest set:\tAverage loss: 0.8780, Average CER: 0.275983 Average WER: 0.8674\n\nTrain Epoch: 8 [0/2430 (0%)]\tLoss: 0.858533\nTrain Epoch: 8 [400/2430 (16%)]\tLoss: 0.694183\nTrain Epoch: 8 [800/2430 (33%)]\tLoss: 0.648883\nTrain Epoch: 8 [1200/2430 (49%)]\tLoss: 0.810860\nTrain Epoch: 8 [1600/2430 (66%)]\tLoss: 0.735317\nTrain Epoch: 8 [2000/2430 (82%)]\tLoss: 0.719811\nTrain Epoch: 8 [2400/2430 (98%)]\tLoss: 0.921428\n\nevaluating...\nTest set:\tAverage loss: 0.9530, Average CER: 0.295436 Average WER: 0.9261\n\nTrain Epoch: 9 [0/2430 (0%)]\tLoss: 0.761528\nTrain Epoch: 9 [400/2430 (16%)]\tLoss: 0.697792\nTrain Epoch: 9 [800/2430 (33%)]\tLoss: 0.684133\nTrain Epoch: 9 [1200/2430 (49%)]\tLoss: 0.573465\nTrain Epoch: 9 [1600/2430 (66%)]\tLoss: 0.730320\nTrain Epoch: 9 [2000/2430 (82%)]\tLoss: 0.740725\nTrain Epoch: 9 [2400/2430 (98%)]\tLoss: 0.776471\n\nevaluating...\nTest set:\tAverage loss: 0.8186, Average CER: 0.259112 Average WER: 0.8587\n\nTrain Epoch: 10 [0/2430 (0%)]\tLoss: 0.559313\nTrain Epoch: 10 [400/2430 (16%)]\tLoss: 0.505941\nTrain Epoch: 10 [800/2430 (33%)]\tLoss: 0.616161\nTrain Epoch: 10 [1200/2430 (49%)]\tLoss: 0.594568\nTrain Epoch: 10 [1600/2430 (66%)]\tLoss: 0.703091\nTrain Epoch: 10 [2000/2430 (82%)]\tLoss: 0.554966\nTrain Epoch: 10 [2400/2430 (98%)]\tLoss: 0.624180\n\nevaluating...\nTest set:\tAverage loss: 0.8113, Average CER: 0.257064 Average WER: 0.8426\n\nTrain Epoch: 11 [0/2430 (0%)]\tLoss: 0.510619\nTrain Epoch: 11 [400/2430 (16%)]\tLoss: 0.513576\nTrain Epoch: 11 [800/2430 (33%)]\tLoss: 0.572794\nTrain Epoch: 11 [1200/2430 (49%)]\tLoss: 0.526359\nTrain Epoch: 11 [1600/2430 (66%)]\tLoss: 0.712449\nTrain Epoch: 11 [2000/2430 (82%)]\tLoss: 0.706335\nTrain Epoch: 11 [2400/2430 (98%)]\tLoss: 0.845923\n\nevaluating...\nTest set:\tAverage loss: 0.8128, Average CER: 0.265271 Average WER: 0.8553\n\nTrain Epoch: 12 [0/2430 (0%)]\tLoss: 0.502571\nTrain Epoch: 12 [400/2430 (16%)]\tLoss: 0.294236\nTrain Epoch: 12 [800/2430 (33%)]\tLoss: 0.635650\nTrain Epoch: 12 [1200/2430 (49%)]\tLoss: 0.569421\nTrain Epoch: 12 [1600/2430 (66%)]\tLoss: 0.424189\nTrain Epoch: 12 [2000/2430 (82%)]\tLoss: 0.510559\nTrain Epoch: 12 [2400/2430 (98%)]\tLoss: 0.581317\n\nevaluating...\nTest set:\tAverage loss: 0.7545, Average CER: 0.233066 Average WER: 0.8035\n\nTrain Epoch: 13 [0/2430 (0%)]\tLoss: 0.420854\nTrain Epoch: 13 [400/2430 (16%)]\tLoss: 0.394443\nTrain Epoch: 13 [800/2430 (33%)]\tLoss: 0.443491\nTrain Epoch: 13 [1200/2430 (49%)]\tLoss: 0.557879\nTrain Epoch: 13 [1600/2430 (66%)]\tLoss: 0.607932\nTrain Epoch: 13 [2000/2430 (82%)]\tLoss: 0.365067\nTrain Epoch: 13 [2400/2430 (98%)]\tLoss: 0.497519\n\nevaluating...\nTest set:\tAverage loss: 0.7288, Average CER: 0.224517 Average WER: 0.8034\n\nTrain Epoch: 14 [0/2430 (0%)]\tLoss: 0.404064\nTrain Epoch: 14 [400/2430 (16%)]\tLoss: 0.527770\nTrain Epoch: 14 [800/2430 (33%)]\tLoss: 0.447431\nTrain Epoch: 14 [1200/2430 (49%)]\tLoss: 0.345033\nTrain Epoch: 14 [1600/2430 (66%)]\tLoss: 0.511995\nTrain Epoch: 14 [2000/2430 (82%)]\tLoss: 0.518499\nTrain Epoch: 14 [2400/2430 (98%)]\tLoss: 0.558781\n\nevaluating...\nTest set:\tAverage loss: 0.7319, Average CER: 0.221626 Average WER: 0.7855\n\nTrain Epoch: 15 [0/2430 (0%)]\tLoss: 0.376568\nTrain Epoch: 15 [400/2430 (16%)]\tLoss: 0.199365\nTrain Epoch: 15 [800/2430 (33%)]\tLoss: 0.401771\nTrain Epoch: 15 [1200/2430 (49%)]\tLoss: 0.379449\nTrain Epoch: 15 [1600/2430 (66%)]\tLoss: 0.333317\nTrain Epoch: 15 [2000/2430 (82%)]\tLoss: 0.423027\nTrain Epoch: 15 [2400/2430 (98%)]\tLoss: 0.363474\n\nevaluating...\nTest set:\tAverage loss: 0.8222, Average CER: 0.237836 Average WER: 0.8147\n\nTrain Epoch: 16 [0/2430 (0%)]\tLoss: 0.351088\nTrain Epoch: 16 [400/2430 (16%)]\tLoss: 0.394757\nTrain Epoch: 16 [800/2430 (33%)]\tLoss: 0.366720\nTrain Epoch: 16 [1200/2430 (49%)]\tLoss: 0.360122\nTrain Epoch: 16 [1600/2430 (66%)]\tLoss: 0.301422\nTrain Epoch: 16 [2000/2430 (82%)]\tLoss: 0.391830\nTrain Epoch: 16 [2400/2430 (98%)]\tLoss: 0.543821\n\nevaluating...\nTest set:\tAverage loss: 0.7949, Average CER: 0.228262 Average WER: 0.8176\n\nTrain Epoch: 17 [0/2430 (0%)]\tLoss: 0.323644\nTrain Epoch: 17 [400/2430 (16%)]\tLoss: 0.289936\nTrain Epoch: 17 [800/2430 (33%)]\tLoss: 0.297563\nTrain Epoch: 17 [1200/2430 (49%)]\tLoss: 0.324412\nTrain Epoch: 17 [1600/2430 (66%)]\tLoss: 0.290417\nTrain Epoch: 17 [2000/2430 (82%)]\tLoss: 0.409474\nTrain Epoch: 17 [2400/2430 (98%)]\tLoss: 0.364011\n\nevaluating...\nTest set:\tAverage loss: 0.8601, Average CER: 0.232209 Average WER: 0.8137\n\nTrain Epoch: 18 [0/2430 (0%)]\tLoss: 0.357816\nTrain Epoch: 18 [400/2430 (16%)]\tLoss: 0.534980\nTrain Epoch: 18 [800/2430 (33%)]\tLoss: 0.350309\nTrain Epoch: 18 [1200/2430 (49%)]\tLoss: 0.392299\nTrain Epoch: 18 [1600/2430 (66%)]\tLoss: 0.415757\nTrain Epoch: 18 [2000/2430 (82%)]\tLoss: 0.429658\nTrain Epoch: 18 [2400/2430 (98%)]\tLoss: 0.373816\n\nevaluating...\nTest set:\tAverage loss: 0.7558, Average CER: 0.215778 Average WER: 0.7664\n\nTrain Epoch: 19 [0/2430 (0%)]\tLoss: 0.307983\nTrain Epoch: 19 [400/2430 (16%)]\tLoss: 0.324043\nTrain Epoch: 19 [800/2430 (33%)]\tLoss: 0.277396\nTrain Epoch: 19 [1200/2430 (49%)]\tLoss: 0.197210\nTrain Epoch: 19 [1600/2430 (66%)]\tLoss: 0.371353\nTrain Epoch: 19 [2000/2430 (82%)]\tLoss: 0.316518\nTrain Epoch: 19 [2400/2430 (98%)]\tLoss: 0.347037\n\nevaluating...\nTest set:\tAverage loss: 0.8084, Average CER: 0.234949 Average WER: 0.8087\n\nTrain Epoch: 20 [0/2430 (0%)]\tLoss: 0.258667\nTrain Epoch: 20 [400/2430 (16%)]\tLoss: 0.285751\nTrain Epoch: 20 [800/2430 (33%)]\tLoss: 0.319228\nTrain Epoch: 20 [1200/2430 (49%)]\tLoss: 0.263942\nTrain Epoch: 20 [1600/2430 (66%)]\tLoss: 0.488021\nTrain Epoch: 20 [2000/2430 (82%)]\tLoss: 0.280379\nTrain Epoch: 20 [2400/2430 (98%)]\tLoss: 0.385063\n\nevaluating...\nTest set:\tAverage loss: 0.7712, Average CER: 0.216085 Average WER: 0.7707\n\nTrain Epoch: 21 [0/2430 (0%)]\tLoss: 0.143052\nTrain Epoch: 21 [400/2430 (16%)]\tLoss: 0.337181\nTrain Epoch: 21 [800/2430 (33%)]\tLoss: 0.213809\nTrain Epoch: 21 [1200/2430 (49%)]\tLoss: 0.230655\nTrain Epoch: 21 [1600/2430 (66%)]\tLoss: 0.268582\nTrain Epoch: 21 [2000/2430 (82%)]\tLoss: 0.347431\nTrain Epoch: 21 [2400/2430 (98%)]\tLoss: 0.370261\n\nevaluating...\nTest set:\tAverage loss: 0.7826, Average CER: 0.207039 Average WER: 0.7515\n\nTrain Epoch: 22 [0/2430 (0%)]\tLoss: 0.248966\nTrain Epoch: 22 [400/2430 (16%)]\tLoss: 0.198464\nTrain Epoch: 22 [800/2430 (33%)]\tLoss: 0.264219\nTrain Epoch: 22 [1200/2430 (49%)]\tLoss: 0.162045\nTrain Epoch: 22 [1600/2430 (66%)]\tLoss: 0.277109\nTrain Epoch: 22 [2000/2430 (82%)]\tLoss: 0.335897\nTrain Epoch: 22 [2400/2430 (98%)]\tLoss: 0.276796\n\nevaluating...\nTest set:\tAverage loss: 0.8280, Average CER: 0.220055 Average WER: 0.7932\n\nTrain Epoch: 23 [0/2430 (0%)]\tLoss: 0.186680\nTrain Epoch: 23 [400/2430 (16%)]\tLoss: 0.237045\nTrain Epoch: 23 [800/2430 (33%)]\tLoss: 0.354140\nTrain Epoch: 23 [1200/2430 (49%)]\tLoss: 0.294356\nTrain Epoch: 23 [1600/2430 (66%)]\tLoss: 0.314915\nTrain Epoch: 23 [2000/2430 (82%)]\tLoss: 0.360932\nTrain Epoch: 23 [2400/2430 (98%)]\tLoss: 0.452503\n\nevaluating...\nTest set:\tAverage loss: 0.9412, Average CER: 0.230746 Average WER: 0.7842\n\nTrain Epoch: 24 [0/2430 (0%)]\tLoss: 0.462490\nTrain Epoch: 24 [400/2430 (16%)]\tLoss: 0.305390\nTrain Epoch: 24 [800/2430 (33%)]\tLoss: 0.355288\nTrain Epoch: 24 [1200/2430 (49%)]\tLoss: 0.392011\nTrain Epoch: 24 [1600/2430 (66%)]\tLoss: 0.272312\nTrain Epoch: 24 [2000/2430 (82%)]\tLoss: 0.356492\nTrain Epoch: 24 [2400/2430 (98%)]\tLoss: 0.318125\n\nevaluating...\nTest set:\tAverage loss: 0.8259, Average CER: 0.211489 Average WER: 0.7692\n\nTrain Epoch: 25 [0/2430 (0%)]\tLoss: 0.249308\nTrain Epoch: 25 [400/2430 (16%)]\tLoss: 0.242278\nTrain Epoch: 25 [800/2430 (33%)]\tLoss: 0.266341\nTrain Epoch: 25 [1200/2430 (49%)]\tLoss: 0.330441\nTrain Epoch: 25 [1600/2430 (66%)]\tLoss: 0.235211\nTrain Epoch: 25 [2000/2430 (82%)]\tLoss: 0.273125\nTrain Epoch: 25 [2400/2430 (98%)]\tLoss: 0.285268\n\nevaluating...\nTest set:\tAverage loss: 0.8461, Average CER: 0.212281 Average WER: 0.7828\n\nTrain Epoch: 26 [0/2430 (0%)]\tLoss: 0.237504\nTrain Epoch: 26 [400/2430 (16%)]\tLoss: 0.372103\nTrain Epoch: 26 [800/2430 (33%)]\tLoss: 0.262193\nTrain Epoch: 26 [1200/2430 (49%)]\tLoss: 0.229349\nTrain Epoch: 26 [1600/2430 (66%)]\tLoss: 0.282656\nTrain Epoch: 26 [2000/2430 (82%)]\tLoss: 0.357508\nTrain Epoch: 26 [2400/2430 (98%)]\tLoss: 0.234232\n\nevaluating...\nTest set:\tAverage loss: 0.8729, Average CER: 0.207091 Average WER: 0.7366\n\nTrain Epoch: 27 [0/2430 (0%)]\tLoss: 0.178397\nTrain Epoch: 27 [400/2430 (16%)]\tLoss: 0.344743\nTrain Epoch: 27 [800/2430 (33%)]\tLoss: 0.260359\nTrain Epoch: 27 [1200/2430 (49%)]\tLoss: 0.179508\nTrain Epoch: 27 [1600/2430 (66%)]\tLoss: 0.226450\nTrain Epoch: 27 [2000/2430 (82%)]\tLoss: 0.341589\nTrain Epoch: 27 [2400/2430 (98%)]\tLoss: 0.297339\n\nevaluating...\nTest set:\tAverage loss: 0.8381, Average CER: 0.214213 Average WER: 0.7618\n\nTrain Epoch: 28 [0/2430 (0%)]\tLoss: 0.264850\nTrain Epoch: 28 [400/2430 (16%)]\tLoss: 0.284084\nTrain Epoch: 28 [800/2430 (33%)]\tLoss: 0.322094\nTrain Epoch: 28 [1200/2430 (49%)]\tLoss: 0.264988\nTrain Epoch: 28 [1600/2430 (66%)]\tLoss: 0.262007\nTrain Epoch: 28 [2000/2430 (82%)]\tLoss: 0.447979\nTrain Epoch: 28 [2400/2430 (98%)]\tLoss: 0.286405\n\nevaluating...\nTest set:\tAverage loss: 0.8905, Average CER: 0.219550 Average WER: 0.7609\n\nTrain Epoch: 29 [0/2430 (0%)]\tLoss: 0.280003\nTrain Epoch: 29 [400/2430 (16%)]\tLoss: 0.379599\nTrain Epoch: 29 [800/2430 (33%)]\tLoss: 0.212442\nTrain Epoch: 29 [1200/2430 (49%)]\tLoss: 0.161282\nTrain Epoch: 29 [1600/2430 (66%)]\tLoss: 0.259577\nTrain Epoch: 29 [2000/2430 (82%)]\tLoss: 0.229164\nTrain Epoch: 29 [2400/2430 (98%)]\tLoss: 0.285802\n\nevaluating...\nTest set:\tAverage loss: 0.8274, Average CER: 0.207744 Average WER: 0.7682\n\nTrain Epoch: 30 [0/2430 (0%)]\tLoss: 0.124196\nTrain Epoch: 30 [400/2430 (16%)]\tLoss: 0.279492\nTrain Epoch: 30 [800/2430 (33%)]\tLoss: 0.319404\nTrain Epoch: 30 [1200/2430 (49%)]\tLoss: 0.264122\nTrain Epoch: 30 [1600/2430 (66%)]\tLoss: 0.329605\nTrain Epoch: 30 [2000/2430 (82%)]\tLoss: 0.347496\nTrain Epoch: 30 [2400/2430 (98%)]\tLoss: 0.260229\n\nevaluating...\nTest set:\tAverage loss: 0.8368, Average CER: 0.210224 Average WER: 0.7559\n\nTrain Epoch: 31 [0/2430 (0%)]\tLoss: 0.222688\nTrain Epoch: 31 [400/2430 (16%)]\tLoss: 0.275890\nTrain Epoch: 31 [800/2430 (33%)]\tLoss: 0.342352\nTrain Epoch: 31 [1200/2430 (49%)]\tLoss: 0.186461\nTrain Epoch: 31 [1600/2430 (66%)]\tLoss: 0.308071\nTrain Epoch: 31 [2000/2430 (82%)]\tLoss: 0.219248\nTrain Epoch: 31 [2400/2430 (98%)]\tLoss: 0.270379\n\nevaluating...\nTest set:\tAverage loss: 0.8578, Average CER: 0.207036 Average WER: 0.7458\n\nTrain Epoch: 32 [0/2430 (0%)]\tLoss: 0.170941\nTrain Epoch: 32 [400/2430 (16%)]\tLoss: 0.198975\nTrain Epoch: 32 [800/2430 (33%)]\tLoss: 0.207034\nTrain Epoch: 32 [1200/2430 (49%)]\tLoss: 0.256399\nTrain Epoch: 32 [1600/2430 (66%)]\tLoss: 0.184792\nTrain Epoch: 32 [2000/2430 (82%)]\tLoss: 0.396563\nTrain Epoch: 32 [2400/2430 (98%)]\tLoss: 0.156389\n\nevaluating...\nTest set:\tAverage loss: 0.8680, Average CER: 0.203580 Average WER: 0.7432\n\nTrain Epoch: 33 [0/2430 (0%)]\tLoss: 0.207713\nTrain Epoch: 33 [400/2430 (16%)]\tLoss: 0.172019\nTrain Epoch: 33 [800/2430 (33%)]\tLoss: 0.291952\nTrain Epoch: 33 [1200/2430 (49%)]\tLoss: 0.218417\nTrain Epoch: 33 [1600/2430 (66%)]\tLoss: 0.233121\nTrain Epoch: 33 [2000/2430 (82%)]\tLoss: 0.203622\nTrain Epoch: 33 [2400/2430 (98%)]\tLoss: 0.201781\n\nevaluating...\nTest set:\tAverage loss: 0.7874, Average CER: 0.186919 Average WER: 0.7358\n\nTrain Epoch: 34 [0/2430 (0%)]\tLoss: 0.169000\nTrain Epoch: 34 [400/2430 (16%)]\tLoss: 0.098604\nTrain Epoch: 34 [800/2430 (33%)]\tLoss: 0.192732\nTrain Epoch: 34 [1200/2430 (49%)]\tLoss: 0.091184\nTrain Epoch: 34 [1600/2430 (66%)]\tLoss: 0.231403\nTrain Epoch: 34 [2000/2430 (82%)]\tLoss: 0.170087\nTrain Epoch: 34 [2400/2430 (98%)]\tLoss: 0.142052\n\nevaluating...\nTest set:\tAverage loss: 0.8206, Average CER: 0.193462 Average WER: 0.7271\n\nTrain Epoch: 35 [0/2430 (0%)]\tLoss: 0.161132\nTrain Epoch: 35 [400/2430 (16%)]\tLoss: 0.195874\nTrain Epoch: 35 [800/2430 (33%)]\tLoss: 0.154641\nTrain Epoch: 35 [1200/2430 (49%)]\tLoss: 0.150636\nTrain Epoch: 35 [1600/2430 (66%)]\tLoss: 0.127223\nTrain Epoch: 35 [2000/2430 (82%)]\tLoss: 0.057950\nTrain Epoch: 35 [2400/2430 (98%)]\tLoss: 0.129299\n\nevaluating...\nTest set:\tAverage loss: 0.8373, Average CER: 0.184783 Average WER: 0.6637\n\nTrain Epoch: 36 [0/2430 (0%)]\tLoss: 0.098089\nTrain Epoch: 36 [400/2430 (16%)]\tLoss: 0.098637\nTrain Epoch: 36 [800/2430 (33%)]\tLoss: 0.115784\nTrain Epoch: 36 [1200/2430 (49%)]\tLoss: 0.069158\nTrain Epoch: 36 [1600/2430 (66%)]\tLoss: 0.118460\nTrain Epoch: 36 [2000/2430 (82%)]\tLoss: 0.156719\nTrain Epoch: 36 [2400/2430 (98%)]\tLoss: 0.163820\n\nevaluating...\nTest set:\tAverage loss: 0.9029, Average CER: 0.190406 Average WER: 0.6898\n\nTrain Epoch: 37 [0/2430 (0%)]\tLoss: 0.161335\nTrain Epoch: 37 [400/2430 (16%)]\tLoss: 0.097851\nTrain Epoch: 37 [800/2430 (33%)]\tLoss: 0.095243\nTrain Epoch: 37 [1200/2430 (49%)]\tLoss: 0.097106\nTrain Epoch: 37 [1600/2430 (66%)]\tLoss: 0.099383\nTrain Epoch: 37 [2000/2430 (82%)]\tLoss: 0.166336\nTrain Epoch: 37 [2400/2430 (98%)]\tLoss: 0.204524\n\nevaluating...\nTest set:\tAverage loss: 0.8813, Average CER: 0.183508 Average WER: 0.7154\n\nTrain Epoch: 38 [0/2430 (0%)]\tLoss: 0.079264\nTrain Epoch: 38 [400/2430 (16%)]\tLoss: 0.123486\nTrain Epoch: 38 [800/2430 (33%)]\tLoss: 0.120078\nTrain Epoch: 38 [1200/2430 (49%)]\tLoss: 0.107307\nTrain Epoch: 38 [1600/2430 (66%)]\tLoss: 0.258702\nTrain Epoch: 38 [2000/2430 (82%)]\tLoss: 0.211865\nTrain Epoch: 38 [2400/2430 (98%)]\tLoss: 0.160316\n\nevaluating...\nTest set:\tAverage loss: 0.9676, Average CER: 0.208485 Average WER: 0.7289\n\nTrain Epoch: 39 [0/2430 (0%)]\tLoss: 0.175254\nTrain Epoch: 39 [400/2430 (16%)]\tLoss: 0.208371\nTrain Epoch: 39 [800/2430 (33%)]\tLoss: 0.137441\nTrain Epoch: 39 [1200/2430 (49%)]\tLoss: 0.189855\nTrain Epoch: 39 [1600/2430 (66%)]\tLoss: 0.124849\nTrain Epoch: 39 [2000/2430 (82%)]\tLoss: 0.094083\nTrain Epoch: 39 [2400/2430 (98%)]\tLoss: 0.179507\n\nevaluating...\nTest set:\tAverage loss: 0.8062, Average CER: 0.174326 Average WER: 0.6886\n\nTrain Epoch: 40 [0/2430 (0%)]\tLoss: 0.078554\nTrain Epoch: 40 [400/2430 (16%)]\tLoss: 0.093127\nTrain Epoch: 40 [800/2430 (33%)]\tLoss: 0.098058\nTrain Epoch: 40 [1200/2430 (49%)]\tLoss: 0.127614\nTrain Epoch: 40 [1600/2430 (66%)]\tLoss: 0.159723\nTrain Epoch: 40 [2000/2430 (82%)]\tLoss: 0.139747\nTrain Epoch: 40 [2400/2430 (98%)]\tLoss: 0.160302\n\nevaluating...\nTest set:\tAverage loss: 0.8485, Average CER: 0.180896 Average WER: 0.6815\n\nTrain Epoch: 41 [0/2430 (0%)]\tLoss: 0.207988\nTrain Epoch: 41 [400/2430 (16%)]\tLoss: 0.125366\nTrain Epoch: 41 [800/2430 (33%)]\tLoss: 0.089750\nTrain Epoch: 41 [1200/2430 (49%)]\tLoss: 0.101303\nTrain Epoch: 41 [1600/2430 (66%)]\tLoss: 0.075803\nTrain Epoch: 41 [2000/2430 (82%)]\tLoss: 0.091188\nTrain Epoch: 41 [2400/2430 (98%)]\tLoss: 0.133260\n\nevaluating...\nTest set:\tAverage loss: 0.8779, Average CER: 0.181552 Average WER: 0.6952\n\nTrain Epoch: 42 [0/2430 (0%)]\tLoss: 0.072577\nTrain Epoch: 42 [400/2430 (16%)]\tLoss: 0.041673\nTrain Epoch: 42 [800/2430 (33%)]\tLoss: 0.033100\nTrain Epoch: 42 [1200/2430 (49%)]\tLoss: 0.049529\nTrain Epoch: 42 [1600/2430 (66%)]\tLoss: 0.042420\nTrain Epoch: 42 [2000/2430 (82%)]\tLoss: 0.057041\nTrain Epoch: 42 [2400/2430 (98%)]\tLoss: 0.060207\n\nevaluating...\nTest set:\tAverage loss: 0.8588, Average CER: 0.173113 Average WER: 0.6833\n\nTrain Epoch: 43 [0/2430 (0%)]\tLoss: 0.072959\nTrain Epoch: 43 [400/2430 (16%)]\tLoss: 0.033734\nTrain Epoch: 43 [800/2430 (33%)]\tLoss: 0.061582\nTrain Epoch: 43 [1200/2430 (49%)]\tLoss: 0.078480\nTrain Epoch: 43 [1600/2430 (66%)]\tLoss: 0.073569\nTrain Epoch: 43 [2000/2430 (82%)]\tLoss: 0.071743\nTrain Epoch: 43 [2400/2430 (98%)]\tLoss: 0.073242\n\nevaluating...\nTest set:\tAverage loss: 0.8900, Average CER: 0.171310 Average WER: 0.6874\n\nTrain Epoch: 44 [0/2430 (0%)]\tLoss: 0.045355\nTrain Epoch: 44 [400/2430 (16%)]\tLoss: 0.088881\nTrain Epoch: 44 [800/2430 (33%)]\tLoss: 0.099001\nTrain Epoch: 44 [1200/2430 (49%)]\tLoss: 0.081157\nTrain Epoch: 44 [1600/2430 (66%)]\tLoss: 0.106021\nTrain Epoch: 44 [2000/2430 (82%)]\tLoss: 0.085812\nTrain Epoch: 44 [2400/2430 (98%)]\tLoss: 0.125004\n\nevaluating...\nTest set:\tAverage loss: 0.8623, Average CER: 0.177410 Average WER: 0.6814\n\nTrain Epoch: 45 [0/2430 (0%)]\tLoss: 0.071621\nTrain Epoch: 45 [400/2430 (16%)]\tLoss: 0.051093\nTrain Epoch: 45 [800/2430 (33%)]\tLoss: 0.037373\nTrain Epoch: 45 [1200/2430 (49%)]\tLoss: 0.068236\nTrain Epoch: 45 [1600/2430 (66%)]\tLoss: 0.085162\nTrain Epoch: 45 [2000/2430 (82%)]\tLoss: 0.113651\nTrain Epoch: 45 [2400/2430 (98%)]\tLoss: 0.070496\n\nevaluating...\nTest set:\tAverage loss: 0.9352, Average CER: 0.180493 Average WER: 0.6996\n\nTrain Epoch: 46 [0/2430 (0%)]\tLoss: 0.041464\nTrain Epoch: 46 [400/2430 (16%)]\tLoss: 0.054265\nTrain Epoch: 46 [800/2430 (33%)]\tLoss: 0.038212\nTrain Epoch: 46 [1200/2430 (49%)]\tLoss: 0.120474\nTrain Epoch: 46 [1600/2430 (66%)]\tLoss: 0.054774\nTrain Epoch: 46 [2000/2430 (82%)]\tLoss: 0.056940\nTrain Epoch: 46 [2400/2430 (98%)]\tLoss: 0.088006\n\nevaluating...\nTest set:\tAverage loss: 0.9206, Average CER: 0.177708 Average WER: 0.6868\n\nTrain Epoch: 47 [0/2430 (0%)]\tLoss: 0.054749\nTrain Epoch: 47 [400/2430 (16%)]\tLoss: 0.106859\nTrain Epoch: 47 [800/2430 (33%)]\tLoss: 0.021038\nTrain Epoch: 47 [1200/2430 (49%)]\tLoss: 0.057009\nTrain Epoch: 47 [1600/2430 (66%)]\tLoss: 0.067530\nTrain Epoch: 47 [2000/2430 (82%)]\tLoss: 0.068359\nTrain Epoch: 47 [2400/2430 (98%)]\tLoss: 0.024854\n\nevaluating...\nTest set:\tAverage loss: 0.9317, Average CER: 0.171136 Average WER: 0.6741\n\nTrain Epoch: 48 [0/2430 (0%)]\tLoss: 0.057184\nTrain Epoch: 48 [400/2430 (16%)]\tLoss: 0.022345\nTrain Epoch: 48 [800/2430 (33%)]\tLoss: 0.073483\nTrain Epoch: 48 [1200/2430 (49%)]\tLoss: 0.076517\nTrain Epoch: 48 [1600/2430 (66%)]\tLoss: 0.089281\nTrain Epoch: 48 [2000/2430 (82%)]\tLoss: 0.097413\nTrain Epoch: 48 [2400/2430 (98%)]\tLoss: 0.072619\n\nevaluating...\nTest set:\tAverage loss: 0.9437, Average CER: 0.178610 Average WER: 0.6855\n\nTrain Epoch: 49 [0/2430 (0%)]\tLoss: 0.044745\nTrain Epoch: 49 [400/2430 (16%)]\tLoss: 0.072951\nTrain Epoch: 49 [800/2430 (33%)]\tLoss: 0.123720\nTrain Epoch: 49 [1200/2430 (49%)]\tLoss: 0.046572\nTrain Epoch: 49 [1600/2430 (66%)]\tLoss: 0.057633\nTrain Epoch: 49 [2000/2430 (82%)]\tLoss: 0.039975\nTrain Epoch: 49 [2400/2430 (98%)]\tLoss: 0.060176\n\nevaluating...\nTest set:\tAverage loss: 0.8967, Average CER: 0.168386 Average WER: 0.6738\n\nTrain Epoch: 50 [0/2430 (0%)]\tLoss: 0.058420\nTrain Epoch: 50 [400/2430 (16%)]\tLoss: 0.029769\nTrain Epoch: 50 [800/2430 (33%)]\tLoss: 0.056863\nTrain Epoch: 50 [1200/2430 (49%)]\tLoss: 0.059421\nTrain Epoch: 50 [1600/2430 (66%)]\tLoss: 0.120043\nTrain Epoch: 50 [2000/2430 (82%)]\tLoss: 0.045565\nTrain Epoch: 50 [2400/2430 (98%)]\tLoss: 0.103581\n\nevaluating...\nTest set:\tAverage loss: 0.9540, Average CER: 0.175878 Average WER: 0.6632\n\nTrain Epoch: 51 [0/2430 (0%)]\tLoss: 0.055376\nTrain Epoch: 51 [400/2430 (16%)]\tLoss: 0.066006\nTrain Epoch: 51 [800/2430 (33%)]\tLoss: 0.071260\nTrain Epoch: 51 [1200/2430 (49%)]\tLoss: 0.040815\nTrain Epoch: 51 [1600/2430 (66%)]\tLoss: 0.076488\nTrain Epoch: 51 [2000/2430 (82%)]\tLoss: 0.055014\nTrain Epoch: 51 [2400/2430 (98%)]\tLoss: 0.026319\n\nevaluating...\nTest set:\tAverage loss: 0.8897, Average CER: 0.166799 Average WER: 0.6588\n\nTrain Epoch: 52 [0/2430 (0%)]\tLoss: 0.034428\nTrain Epoch: 52 [400/2430 (16%)]\tLoss: 0.054605\nTrain Epoch: 52 [800/2430 (33%)]\tLoss: 0.020040\nTrain Epoch: 52 [1200/2430 (49%)]\tLoss: 0.044672\nTrain Epoch: 52 [1600/2430 (66%)]\tLoss: 0.024887\nTrain Epoch: 52 [2000/2430 (82%)]\tLoss: 0.081766\nTrain Epoch: 52 [2400/2430 (98%)]\tLoss: 0.094673\n\nevaluating...\nTest set:\tAverage loss: 0.9574, Average CER: 0.170516 Average WER: 0.6530\n\nTrain Epoch: 53 [0/2430 (0%)]\tLoss: 0.025803\nTrain Epoch: 53 [400/2430 (16%)]\tLoss: 0.052578\nTrain Epoch: 53 [800/2430 (33%)]\tLoss: 0.029399\nTrain Epoch: 53 [1200/2430 (49%)]\tLoss: 0.038044\nTrain Epoch: 53 [1600/2430 (66%)]\tLoss: 0.027176\nTrain Epoch: 53 [2000/2430 (82%)]\tLoss: 0.015811\nTrain Epoch: 53 [2400/2430 (98%)]\tLoss: 0.080975\n\nevaluating...\nTest set:\tAverage loss: 1.0811, Average CER: 0.178807 Average WER: 0.6631\n\nTrain Epoch: 54 [0/2430 (0%)]\tLoss: 0.059334\nTrain Epoch: 54 [400/2430 (16%)]\tLoss: 0.072813\nTrain Epoch: 54 [800/2430 (33%)]\tLoss: 0.053724\nTrain Epoch: 54 [1200/2430 (49%)]\tLoss: 0.151815\nTrain Epoch: 54 [1600/2430 (66%)]\tLoss: 0.127270\nTrain Epoch: 54 [2000/2430 (82%)]\tLoss: 0.056953\nTrain Epoch: 54 [2400/2430 (98%)]\tLoss: 0.048044\n\nevaluating...\nTest set:\tAverage loss: 0.9900, Average CER: 0.169919 Average WER: 0.6746\n\nTrain Epoch: 55 [0/2430 (0%)]\tLoss: 0.058776\nTrain Epoch: 55 [400/2430 (16%)]\tLoss: 0.057441\nTrain Epoch: 55 [800/2430 (33%)]\tLoss: 0.117962\nTrain Epoch: 55 [1200/2430 (49%)]\tLoss: 0.155966\nTrain Epoch: 55 [1600/2430 (66%)]\tLoss: 0.128511\nTrain Epoch: 55 [2000/2430 (82%)]\tLoss: 0.135341\nTrain Epoch: 55 [2400/2430 (98%)]\tLoss: 0.083536\n\nevaluating...\nTest set:\tAverage loss: 0.9767, Average CER: 0.184088 Average WER: 0.7030\n\nTrain Epoch: 56 [0/2430 (0%)]\tLoss: 0.046413\nTrain Epoch: 56 [400/2430 (16%)]\tLoss: 0.046307\nTrain Epoch: 56 [800/2430 (33%)]\tLoss: 0.052325\nTrain Epoch: 56 [1200/2430 (49%)]\tLoss: 0.061856\nTrain Epoch: 56 [1600/2430 (66%)]\tLoss: 0.090166\nTrain Epoch: 56 [2000/2430 (82%)]\tLoss: 0.065329\nTrain Epoch: 56 [2400/2430 (98%)]\tLoss: 0.092244\n\nevaluating...\nTest set:\tAverage loss: 0.9472, Average CER: 0.177541 Average WER: 0.6754\n\nTrain Epoch: 57 [0/2430 (0%)]\tLoss: 0.032323\nTrain Epoch: 57 [400/2430 (16%)]\tLoss: 0.076714\nTrain Epoch: 57 [800/2430 (33%)]\tLoss: 0.075906\nTrain Epoch: 57 [1200/2430 (49%)]\tLoss: 0.060468\nTrain Epoch: 57 [1600/2430 (66%)]\tLoss: 0.037566\nTrain Epoch: 57 [2000/2430 (82%)]\tLoss: 0.043124\nTrain Epoch: 57 [2400/2430 (98%)]\tLoss: 0.068674\n\nevaluating...\nTest set:\tAverage loss: 0.9631, Average CER: 0.180023 Average WER: 0.6836\n\nTrain Epoch: 58 [0/2430 (0%)]\tLoss: 0.059699\nTrain Epoch: 58 [400/2430 (16%)]\tLoss: 0.021224\nTrain Epoch: 58 [800/2430 (33%)]\tLoss: 0.042894\nTrain Epoch: 58 [1200/2430 (49%)]\tLoss: 0.034615\nTrain Epoch: 58 [1600/2430 (66%)]\tLoss: 0.016984\nTrain Epoch: 58 [2000/2430 (82%)]\tLoss: 0.023601\nTrain Epoch: 58 [2400/2430 (98%)]\tLoss: 0.039242\n\nevaluating...\nTest set:\tAverage loss: 0.9149, Average CER: 0.162114 Average WER: 0.6546\n\nTrain Epoch: 59 [0/2430 (0%)]\tLoss: 0.029720\nTrain Epoch: 59 [400/2430 (16%)]\tLoss: 0.031028\nTrain Epoch: 59 [800/2430 (33%)]\tLoss: 0.018325\nTrain Epoch: 59 [1200/2430 (49%)]\tLoss: 0.088939\nTrain Epoch: 59 [1600/2430 (66%)]\tLoss: 0.050038\nTrain Epoch: 59 [2000/2430 (82%)]\tLoss: 0.047139\nTrain Epoch: 59 [2400/2430 (98%)]\tLoss: 0.070039\n\nevaluating...\nTest set:\tAverage loss: 0.9560, Average CER: 0.168488 Average WER: 0.6532\n\nTrain Epoch: 60 [0/2430 (0%)]\tLoss: 0.050171\nTrain Epoch: 60 [400/2430 (16%)]\tLoss: 0.050980\nTrain Epoch: 60 [800/2430 (33%)]\tLoss: 0.030719\nTrain Epoch: 60 [1200/2430 (49%)]\tLoss: 0.032378\nTrain Epoch: 60 [1600/2430 (66%)]\tLoss: 0.039390\nTrain Epoch: 60 [2000/2430 (82%)]\tLoss: 0.070056\nTrain Epoch: 60 [2400/2430 (98%)]\tLoss: 0.060034\n\nevaluating...\nTest set:\tAverage loss: 0.9930, Average CER: 0.168948 Average WER: 0.6536\n\nTrain Epoch: 61 [0/2430 (0%)]\tLoss: 0.025571\nTrain Epoch: 61 [400/2430 (16%)]\tLoss: 0.054735\nTrain Epoch: 61 [800/2430 (33%)]\tLoss: 0.047918\nTrain Epoch: 61 [1200/2430 (49%)]\tLoss: 0.031343\nTrain Epoch: 61 [1600/2430 (66%)]\tLoss: 0.031056\nTrain Epoch: 61 [2000/2430 (82%)]\tLoss: 0.026570\nTrain Epoch: 61 [2400/2430 (98%)]\tLoss: 0.056177\n\nevaluating...\nTest set:\tAverage loss: 0.9190, Average CER: 0.162197 Average WER: 0.6506\n\nTrain Epoch: 62 [0/2430 (0%)]\tLoss: 0.012120\nTrain Epoch: 62 [400/2430 (16%)]\tLoss: 0.013803\nTrain Epoch: 62 [800/2430 (33%)]\tLoss: 0.010771\nTrain Epoch: 62 [1200/2430 (49%)]\tLoss: 0.026215\nTrain Epoch: 62 [1600/2430 (66%)]\tLoss: 0.029196\nTrain Epoch: 62 [2000/2430 (82%)]\tLoss: 0.017166\nTrain Epoch: 62 [2400/2430 (98%)]\tLoss: 0.021002\n\nevaluating...\nTest set:\tAverage loss: 0.9605, Average CER: 0.160052 Average WER: 0.6434\n\nTrain Epoch: 63 [0/2430 (0%)]\tLoss: 0.024012\nTrain Epoch: 63 [400/2430 (16%)]\tLoss: 0.018711\nTrain Epoch: 63 [800/2430 (33%)]\tLoss: 0.009139\nTrain Epoch: 63 [1200/2430 (49%)]\tLoss: 0.020337\nTrain Epoch: 63 [1600/2430 (66%)]\tLoss: 0.005212\nTrain Epoch: 63 [2000/2430 (82%)]\tLoss: 0.019746\nTrain Epoch: 63 [2400/2430 (98%)]\tLoss: 0.004578\n\nevaluating...\nTest set:\tAverage loss: 0.9101, Average CER: 0.149343 Average WER: 0.6130\n\nTrain Epoch: 64 [0/2430 (0%)]\tLoss: 0.006171\nTrain Epoch: 64 [400/2430 (16%)]\tLoss: 0.003451\nTrain Epoch: 64 [800/2430 (33%)]\tLoss: 0.005437\nTrain Epoch: 64 [1200/2430 (49%)]\tLoss: 0.001517\nTrain Epoch: 64 [1600/2430 (66%)]\tLoss: 0.007454\nTrain Epoch: 64 [2000/2430 (82%)]\tLoss: 0.016195\nTrain Epoch: 64 [2400/2430 (98%)]\tLoss: 0.032561\n\nevaluating...\nTest set:\tAverage loss: 0.9410, Average CER: 0.145470 Average WER: 0.6039\n\nTrain Epoch: 65 [0/2430 (0%)]\tLoss: 0.001922\nTrain Epoch: 65 [400/2430 (16%)]\tLoss: 0.004707\nTrain Epoch: 65 [800/2430 (33%)]\tLoss: 0.004495\nTrain Epoch: 65 [1200/2430 (49%)]\tLoss: 0.002420\nTrain Epoch: 65 [1600/2430 (66%)]\tLoss: 0.001842\nTrain Epoch: 65 [2000/2430 (82%)]\tLoss: 0.001417\nTrain Epoch: 65 [2400/2430 (98%)]\tLoss: 0.002793\n\nevaluating...\nTest set:\tAverage loss: 0.9044, Average CER: 0.142556 Average WER: 0.5990\n\nTrain Epoch: 66 [0/2430 (0%)]\tLoss: 0.003237\nTrain Epoch: 66 [400/2430 (16%)]\tLoss: 0.009495\nTrain Epoch: 66 [800/2430 (33%)]\tLoss: 0.029752\nTrain Epoch: 66 [1200/2430 (49%)]\tLoss: 0.003946\nTrain Epoch: 66 [1600/2430 (66%)]\tLoss: 0.013756\nTrain Epoch: 66 [2000/2430 (82%)]\tLoss: 0.005697\nTrain Epoch: 66 [2400/2430 (98%)]\tLoss: 0.008932\n\nevaluating...\nTest set:\tAverage loss: 0.9494, Average CER: 0.148967 Average WER: 0.5997\n\nTrain Epoch: 67 [0/2430 (0%)]\tLoss: 0.002554\nTrain Epoch: 67 [400/2430 (16%)]\tLoss: 0.002395\nTrain Epoch: 67 [800/2430 (33%)]\tLoss: 0.001329\nTrain Epoch: 67 [1200/2430 (49%)]\tLoss: 0.000847\nTrain Epoch: 67 [1600/2430 (66%)]\tLoss: 0.006866\nTrain Epoch: 67 [2000/2430 (82%)]\tLoss: 0.002072\nTrain Epoch: 67 [2400/2430 (98%)]\tLoss: 0.001880\n\nevaluating...\nTest set:\tAverage loss: 0.9723, Average CER: 0.148042 Average WER: 0.6084\n\nTrain Epoch: 68 [0/2430 (0%)]\tLoss: 0.000955\nTrain Epoch: 68 [400/2430 (16%)]\tLoss: 0.001081\nTrain Epoch: 68 [800/2430 (33%)]\tLoss: 0.008294\nTrain Epoch: 68 [1200/2430 (49%)]\tLoss: 0.006235\nTrain Epoch: 68 [1600/2430 (66%)]\tLoss: 0.002351\nTrain Epoch: 68 [2000/2430 (82%)]\tLoss: 0.012179\nTrain Epoch: 68 [2400/2430 (98%)]\tLoss: 0.008988\n\nevaluating...\nTest set:\tAverage loss: 1.0000, Average CER: 0.155970 Average WER: 0.6233\n\nTrain Epoch: 69 [0/2430 (0%)]\tLoss: 0.003807\nTrain Epoch: 69 [400/2430 (16%)]\tLoss: 0.027497\nTrain Epoch: 69 [800/2430 (33%)]\tLoss: 0.006749\nTrain Epoch: 69 [1200/2430 (49%)]\tLoss: 0.016183\nTrain Epoch: 69 [1600/2430 (66%)]\tLoss: 0.013617\nTrain Epoch: 69 [2000/2430 (82%)]\tLoss: 0.011911\nTrain Epoch: 69 [2400/2430 (98%)]\tLoss: 0.036496\n\nevaluating...\nTest set:\tAverage loss: 1.1129, Average CER: 0.175257 Average WER: 0.6669\n\nTrain Epoch: 70 [0/2430 (0%)]\tLoss: 0.017073\nTrain Epoch: 70 [400/2430 (16%)]\tLoss: 0.065249\nTrain Epoch: 70 [800/2430 (33%)]\tLoss: 0.023110\nTrain Epoch: 70 [1200/2430 (49%)]\tLoss: 0.034462\nTrain Epoch: 70 [1600/2430 (66%)]\tLoss: 0.055312\nTrain Epoch: 70 [2000/2430 (82%)]\tLoss: 0.032922\nTrain Epoch: 70 [2400/2430 (98%)]\tLoss: 0.032230\n\nevaluating...\nTest set:\tAverage loss: 1.0202, Average CER: 0.166531 Average WER: 0.6560\n\nTrain Epoch: 71 [0/2430 (0%)]\tLoss: 0.021771\nTrain Epoch: 71 [400/2430 (16%)]\tLoss: 0.025667\nTrain Epoch: 71 [800/2430 (33%)]\tLoss: 0.026167\nTrain Epoch: 71 [1200/2430 (49%)]\tLoss: 0.013183\nTrain Epoch: 71 [1600/2430 (66%)]\tLoss: 0.014510\nTrain Epoch: 71 [2000/2430 (82%)]\tLoss: 0.016833\nTrain Epoch: 71 [2400/2430 (98%)]\tLoss: 0.024026\n\nevaluating...\nTest set:\tAverage loss: 1.0199, Average CER: 0.163169 Average WER: 0.6246\n\nTrain Epoch: 72 [0/2430 (0%)]\tLoss: 0.007827\nTrain Epoch: 72 [400/2430 (16%)]\tLoss: 0.024220\nTrain Epoch: 72 [800/2430 (33%)]\tLoss: 0.020349\nTrain Epoch: 72 [1200/2430 (49%)]\tLoss: 0.034703\nTrain Epoch: 72 [1600/2430 (66%)]\tLoss: 0.015484\nTrain Epoch: 72 [2000/2430 (82%)]\tLoss: 0.018173\nTrain Epoch: 72 [2400/2430 (98%)]\tLoss: 0.017345\n\nevaluating...\nTest set:\tAverage loss: 0.9760, Average CER: 0.156790 Average WER: 0.6279\n\nTrain Epoch: 73 [0/2430 (0%)]\tLoss: 0.003659\nTrain Epoch: 73 [400/2430 (16%)]\tLoss: 0.027729\nTrain Epoch: 73 [800/2430 (33%)]\tLoss: 0.014544\nTrain Epoch: 73 [1200/2430 (49%)]\tLoss: 0.007031\nTrain Epoch: 73 [1600/2430 (66%)]\tLoss: 0.005815\nTrain Epoch: 73 [2000/2430 (82%)]\tLoss: 0.009832\nTrain Epoch: 73 [2400/2430 (98%)]\tLoss: 0.004151\n\nevaluating...\nTest set:\tAverage loss: 0.9757, Average CER: 0.148345 Average WER: 0.6075\n\nTrain Epoch: 74 [0/2430 (0%)]\tLoss: 0.002143\nTrain Epoch: 74 [400/2430 (16%)]\tLoss: 0.001884\nTrain Epoch: 74 [800/2430 (33%)]\tLoss: 0.001566\nTrain Epoch: 74 [1200/2430 (49%)]\tLoss: 0.006026\nTrain Epoch: 74 [1600/2430 (66%)]\tLoss: 0.007240\nTrain Epoch: 74 [2000/2430 (82%)]\tLoss: 0.001742\nTrain Epoch: 74 [2400/2430 (98%)]\tLoss: 0.001908\n\nevaluating...\nTest set:\tAverage loss: 0.9772, Average CER: 0.144996 Average WER: 0.5932\n\nTrain Epoch: 75 [0/2430 (0%)]\tLoss: 0.002452\nTrain Epoch: 75 [400/2430 (16%)]\tLoss: 0.001363\nTrain Epoch: 75 [800/2430 (33%)]\tLoss: 0.001265\nTrain Epoch: 75 [1200/2430 (49%)]\tLoss: 0.000762\nTrain Epoch: 75 [1600/2430 (66%)]\tLoss: 0.000914\nTrain Epoch: 75 [2000/2430 (82%)]\tLoss: 0.001070\nTrain Epoch: 75 [2400/2430 (98%)]\tLoss: 0.001369\n\nevaluating...\nTest set:\tAverage loss: 0.9835, Average CER: 0.147265 Average WER: 0.5989\n\nTrain Epoch: 76 [0/2430 (0%)]\tLoss: 0.000592\nTrain Epoch: 76 [400/2430 (16%)]\tLoss: 0.000446\nTrain Epoch: 76 [800/2430 (33%)]\tLoss: 0.000699\nTrain Epoch: 76 [1200/2430 (49%)]\tLoss: 0.000588\nTrain Epoch: 76 [1600/2430 (66%)]\tLoss: 0.000530\nTrain Epoch: 76 [2000/2430 (82%)]\tLoss: 0.000580\nTrain Epoch: 76 [2400/2430 (98%)]\tLoss: 0.011366\n\nevaluating...\nTest set:\tAverage loss: 0.9828, Average CER: 0.145071 Average WER: 0.5922\n\nTrain Epoch: 77 [0/2430 (0%)]\tLoss: 0.000261\nTrain Epoch: 77 [400/2430 (16%)]\tLoss: 0.000224\nTrain Epoch: 77 [800/2430 (33%)]\tLoss: 0.000553\nTrain Epoch: 77 [1200/2430 (49%)]\tLoss: 0.000303\nTrain Epoch: 77 [1600/2430 (66%)]\tLoss: 0.000391\nTrain Epoch: 77 [2000/2430 (82%)]\tLoss: 0.000342\nTrain Epoch: 77 [2400/2430 (98%)]\tLoss: 0.000352\n\nevaluating...\nTest set:\tAverage loss: 0.9834, Average CER: 0.142813 Average WER: 0.5885\n\nTrain Epoch: 78 [0/2430 (0%)]\tLoss: 0.000261\nTrain Epoch: 78 [400/2430 (16%)]\tLoss: 0.000482\nTrain Epoch: 78 [800/2430 (33%)]\tLoss: 0.000393\nTrain Epoch: 78 [1200/2430 (49%)]\tLoss: 0.000474\nTrain Epoch: 78 [1600/2430 (66%)]\tLoss: 0.000300\nTrain Epoch: 78 [2000/2430 (82%)]\tLoss: 0.000265\nTrain Epoch: 78 [2400/2430 (98%)]\tLoss: 0.000194\n\nevaluating...\nTest set:\tAverage loss: 0.9850, Average CER: 0.142649 Average WER: 0.5830\n\nTrain Epoch: 79 [0/2430 (0%)]\tLoss: 0.000202\nTrain Epoch: 79 [400/2430 (16%)]\tLoss: 0.000157\nTrain Epoch: 79 [800/2430 (33%)]\tLoss: 0.000274\nTrain Epoch: 79 [1200/2430 (49%)]\tLoss: 0.000135\nTrain Epoch: 79 [1600/2430 (66%)]\tLoss: 0.000252\nTrain Epoch: 79 [2000/2430 (82%)]\tLoss: 0.000229\nTrain Epoch: 79 [2400/2430 (98%)]\tLoss: 0.000220\n\nevaluating...\nTest set:\tAverage loss: 0.9936, Average CER: 0.142431 Average WER: 0.5855\n\nTrain Epoch: 80 [0/2430 (0%)]\tLoss: 0.000369\nTrain Epoch: 80 [400/2430 (16%)]\tLoss: 0.000220\nTrain Epoch: 80 [800/2430 (33%)]\tLoss: 0.000430\nTrain Epoch: 80 [1200/2430 (49%)]\tLoss: 0.000191\nTrain Epoch: 80 [1600/2430 (66%)]\tLoss: 0.000343\nTrain Epoch: 80 [2000/2430 (82%)]\tLoss: 0.000314\nTrain Epoch: 80 [2400/2430 (98%)]\tLoss: 0.000188\n\nevaluating...\nTest set:\tAverage loss: 0.9985, Average CER: 0.141441 Average WER: 0.5822\n\nTrain Epoch: 81 [0/2430 (0%)]\tLoss: 0.000155\nTrain Epoch: 81 [400/2430 (16%)]\tLoss: 0.000249\nTrain Epoch: 81 [800/2430 (33%)]\tLoss: 0.000137\nTrain Epoch: 81 [1200/2430 (49%)]\tLoss: 0.000165\nTrain Epoch: 81 [1600/2430 (66%)]\tLoss: 0.000167\nTrain Epoch: 81 [2000/2430 (82%)]\tLoss: 0.000247\nTrain Epoch: 81 [2400/2430 (98%)]\tLoss: 0.000178\n\nevaluating...\nTest set:\tAverage loss: 1.0036, Average CER: 0.142983 Average WER: 0.5872\n\nTrain Epoch: 82 [0/2430 (0%)]\tLoss: 0.000112\nTrain Epoch: 82 [400/2430 (16%)]\tLoss: 0.000222\nTrain Epoch: 82 [800/2430 (33%)]\tLoss: 0.000173\nTrain Epoch: 82 [1200/2430 (49%)]\tLoss: 0.000338\nTrain Epoch: 82 [1600/2430 (66%)]\tLoss: 0.000286\nTrain Epoch: 82 [2000/2430 (82%)]\tLoss: 0.000140\nTrain Epoch: 82 [2400/2430 (98%)]\tLoss: 0.000300\n\nevaluating...\nTest set:\tAverage loss: 1.0049, Average CER: 0.141204 Average WER: 0.5805\n\nTrain Epoch: 83 [0/2430 (0%)]\tLoss: 0.000291\nTrain Epoch: 83 [400/2430 (16%)]\tLoss: 0.000091\nTrain Epoch: 83 [800/2430 (33%)]\tLoss: 0.000192\nTrain Epoch: 83 [1200/2430 (49%)]\tLoss: 0.000198\nTrain Epoch: 83 [1600/2430 (66%)]\tLoss: 0.000086\nTrain Epoch: 83 [2000/2430 (82%)]\tLoss: 0.000184\nTrain Epoch: 83 [2400/2430 (98%)]\tLoss: 0.000245\n\nevaluating...\nTest set:\tAverage loss: 1.0073, Average CER: 0.141198 Average WER: 0.5789\n\nTrain Epoch: 84 [0/2430 (0%)]\tLoss: 0.000254\nTrain Epoch: 84 [400/2430 (16%)]\tLoss: 0.000296\nTrain Epoch: 84 [800/2430 (33%)]\tLoss: 0.000105\nTrain Epoch: 84 [1200/2430 (49%)]\tLoss: 0.000131\nTrain Epoch: 84 [1600/2430 (66%)]\tLoss: 0.000146\nTrain Epoch: 84 [2000/2430 (82%)]\tLoss: 0.000171\nTrain Epoch: 84 [2400/2430 (98%)]\tLoss: 0.000124\n\nevaluating...\nTest set:\tAverage loss: 1.0129, Average CER: 0.142959 Average WER: 0.5885\n\nTrain Epoch: 85 [0/2430 (0%)]\tLoss: 0.000168\nTrain Epoch: 85 [400/2430 (16%)]\tLoss: 0.000142\nTrain Epoch: 85 [800/2430 (33%)]\tLoss: 0.000125\nTrain Epoch: 85 [1200/2430 (49%)]\tLoss: 0.000102\nTrain Epoch: 85 [1600/2430 (66%)]\tLoss: 0.000108\nTrain Epoch: 85 [2000/2430 (82%)]\tLoss: 0.000097\nTrain Epoch: 85 [2400/2430 (98%)]\tLoss: 0.000302\n\nevaluating...\nTest set:\tAverage loss: 1.0156, Average CER: 0.141847 Average WER: 0.5845\n\nTrain Epoch: 86 [0/2430 (0%)]\tLoss: 0.000109\nTrain Epoch: 86 [400/2430 (16%)]\tLoss: 0.000151\nTrain Epoch: 86 [800/2430 (33%)]\tLoss: 0.000166\nTrain Epoch: 86 [1200/2430 (49%)]\tLoss: 0.000204\nTrain Epoch: 86 [1600/2430 (66%)]\tLoss: 0.000104\nTrain Epoch: 86 [2000/2430 (82%)]\tLoss: 0.000251\nTrain Epoch: 86 [2400/2430 (98%)]\tLoss: 0.000171\n\nevaluating...\nTest set:\tAverage loss: 1.0169, Average CER: 0.141277 Average WER: 0.5830\n\nTrain Epoch: 87 [0/2430 (0%)]\tLoss: 0.000083\nTrain Epoch: 87 [400/2430 (16%)]\tLoss: 0.000222\nTrain Epoch: 87 [800/2430 (33%)]\tLoss: 0.000180\nTrain Epoch: 87 [1200/2430 (49%)]\tLoss: 0.000230\nTrain Epoch: 87 [1600/2430 (66%)]\tLoss: 0.000085\nTrain Epoch: 87 [2000/2430 (82%)]\tLoss: 0.000077\nTrain Epoch: 87 [2400/2430 (98%)]\tLoss: 0.000126\n\nevaluating...\nTest set:\tAverage loss: 1.0173, Average CER: 0.141880 Average WER: 0.5835\n\nTrain Epoch: 88 [0/2430 (0%)]\tLoss: 0.000134\nTrain Epoch: 88 [400/2430 (16%)]\tLoss: 0.000116\nTrain Epoch: 88 [800/2430 (33%)]\tLoss: 0.000111\nTrain Epoch: 88 [1200/2430 (49%)]\tLoss: 0.000110\nTrain Epoch: 88 [1600/2430 (66%)]\tLoss: 0.000196\nTrain Epoch: 88 [2000/2430 (82%)]\tLoss: 0.000111\nTrain Epoch: 88 [2400/2430 (98%)]\tLoss: 0.000150\n\nevaluating...\nTest set:\tAverage loss: 1.0220, Average CER: 0.140190 Average WER: 0.5768\n\nTrain Epoch: 89 [0/2430 (0%)]\tLoss: 0.000098\nTrain Epoch: 89 [400/2430 (16%)]\tLoss: 0.000097\nTrain Epoch: 89 [800/2430 (33%)]\tLoss: 0.000169\nTrain Epoch: 89 [1200/2430 (49%)]\tLoss: 0.000085\nTrain Epoch: 89 [1600/2430 (66%)]\tLoss: 0.000073\nTrain Epoch: 89 [2000/2430 (82%)]\tLoss: 0.000245\nTrain Epoch: 89 [2400/2430 (98%)]\tLoss: 0.000154\n\nevaluating...\nTest set:\tAverage loss: 1.0237, Average CER: 0.140666 Average WER: 0.5789\n\nTrain Epoch: 90 [0/2430 (0%)]\tLoss: 0.000178\nTrain Epoch: 90 [400/2430 (16%)]\tLoss: 0.000131\nTrain Epoch: 90 [800/2430 (33%)]\tLoss: 0.000068\nTrain Epoch: 90 [1200/2430 (49%)]\tLoss: 0.000098\nTrain Epoch: 90 [1600/2430 (66%)]\tLoss: 0.000096\nTrain Epoch: 90 [2000/2430 (82%)]\tLoss: 0.000159\nTrain Epoch: 90 [2400/2430 (98%)]\tLoss: 0.000101\n\nevaluating...\nTest set:\tAverage loss: 1.0242, Average CER: 0.140831 Average WER: 0.5839\n\nTrain Epoch: 91 [0/2430 (0%)]\tLoss: 0.000235\nTrain Epoch: 91 [400/2430 (16%)]\tLoss: 0.000075\nTrain Epoch: 91 [800/2430 (33%)]\tLoss: 0.000311\nTrain Epoch: 91 [1200/2430 (49%)]\tLoss: 0.000067\nTrain Epoch: 91 [1600/2430 (66%)]\tLoss: 0.000058\nTrain Epoch: 91 [2000/2430 (82%)]\tLoss: 0.000093\nTrain Epoch: 91 [2400/2430 (98%)]\tLoss: 0.000178\n\nevaluating...\nTest set:\tAverage loss: 1.0257, Average CER: 0.141395 Average WER: 0.5849\n\nTrain Epoch: 92 [0/2430 (0%)]\tLoss: 0.000123\nTrain Epoch: 92 [400/2430 (16%)]\tLoss: 0.000104\nTrain Epoch: 92 [800/2430 (33%)]\tLoss: 0.000122\nTrain Epoch: 92 [1200/2430 (49%)]\tLoss: 0.000111\nTrain Epoch: 92 [1600/2430 (66%)]\tLoss: 0.000121\nTrain Epoch: 92 [2000/2430 (82%)]\tLoss: 0.000089\nTrain Epoch: 92 [2400/2430 (98%)]\tLoss: 0.000077\n\nevaluating...\nTest set:\tAverage loss: 1.0279, Average CER: 0.140742 Average WER: 0.5867\n\nTrain Epoch: 93 [0/2430 (0%)]\tLoss: 0.000057\nTrain Epoch: 93 [400/2430 (16%)]\tLoss: 0.000121\nTrain Epoch: 93 [800/2430 (33%)]\tLoss: 0.000169\nTrain Epoch: 93 [1200/2430 (49%)]\tLoss: 0.000096\nTrain Epoch: 93 [1600/2430 (66%)]\tLoss: 0.000101\nTrain Epoch: 93 [2000/2430 (82%)]\tLoss: 0.000134\nTrain Epoch: 93 [2400/2430 (98%)]\tLoss: 0.000066\n\nevaluating...\nTest set:\tAverage loss: 1.0316, Average CER: 0.142168 Average WER: 0.5865\n\nTrain Epoch: 94 [0/2430 (0%)]\tLoss: 0.000084\nTrain Epoch: 94 [400/2430 (16%)]\tLoss: 0.000099\nTrain Epoch: 94 [800/2430 (33%)]\tLoss: 0.000078\nTrain Epoch: 94 [1200/2430 (49%)]\tLoss: 0.000147\nTrain Epoch: 94 [1600/2430 (66%)]\tLoss: 0.000106\nTrain Epoch: 94 [2000/2430 (82%)]\tLoss: 0.000116\nTrain Epoch: 94 [2400/2430 (98%)]\tLoss: 0.000161\n\nevaluating...\nTest set:\tAverage loss: 1.0338, Average CER: 0.141439 Average WER: 0.5839\n\nTrain Epoch: 95 [0/2430 (0%)]\tLoss: 0.000097\nTrain Epoch: 95 [400/2430 (16%)]\tLoss: 0.000160\nTrain Epoch: 95 [800/2430 (33%)]\tLoss: 0.000053\nTrain Epoch: 95 [1200/2430 (49%)]\tLoss: 0.000129\nTrain Epoch: 95 [1600/2430 (66%)]\tLoss: 0.000126\nTrain Epoch: 95 [2000/2430 (82%)]\tLoss: 0.000178\nTrain Epoch: 95 [2400/2430 (98%)]\tLoss: 0.000151\n\nevaluating...\nTest set:\tAverage loss: 1.0339, Average CER: 0.141631 Average WER: 0.5846\n\nTrain Epoch: 96 [0/2430 (0%)]\tLoss: 0.000114\nTrain Epoch: 96 [400/2430 (16%)]\tLoss: 0.000108\nTrain Epoch: 96 [800/2430 (33%)]\tLoss: 0.000083\nTrain Epoch: 96 [1200/2430 (49%)]\tLoss: 0.000071\nTrain Epoch: 96 [1600/2430 (66%)]\tLoss: 0.000197\nTrain Epoch: 96 [2000/2430 (82%)]\tLoss: 0.000071\nTrain Epoch: 96 [2400/2430 (98%)]\tLoss: 0.000052\n\nevaluating...\nTest set:\tAverage loss: 1.0352, Average CER: 0.140798 Average WER: 0.5807\n\nTrain Epoch: 97 [0/2430 (0%)]\tLoss: 0.000079\nTrain Epoch: 97 [400/2430 (16%)]\tLoss: 0.000095\nTrain Epoch: 97 [800/2430 (33%)]\tLoss: 0.000150\nTrain Epoch: 97 [1200/2430 (49%)]\tLoss: 0.000069\nTrain Epoch: 97 [1600/2430 (66%)]\tLoss: 0.000072\nTrain Epoch: 97 [2000/2430 (82%)]\tLoss: 0.000051\nTrain Epoch: 97 [2400/2430 (98%)]\tLoss: 0.000084\n\nevaluating...\nTest set:\tAverage loss: 1.0351, Average CER: 0.140005 Average WER: 0.5814\n\nTrain Epoch: 98 [0/2430 (0%)]\tLoss: 0.000070\nTrain Epoch: 98 [400/2430 (16%)]\tLoss: 0.000080\nTrain Epoch: 98 [800/2430 (33%)]\tLoss: 0.000063\nTrain Epoch: 98 [1200/2430 (49%)]\tLoss: 0.000104\nTrain Epoch: 98 [1600/2430 (66%)]\tLoss: 0.000048\nTrain Epoch: 98 [2000/2430 (82%)]\tLoss: 0.000115\nTrain Epoch: 98 [2400/2430 (98%)]\tLoss: 0.000095\n\nevaluating...\nTest set:\tAverage loss: 1.0349, Average CER: 0.140023 Average WER: 0.5798\n\nTrain Epoch: 99 [0/2430 (0%)]\tLoss: 0.000126\nTrain Epoch: 99 [400/2430 (16%)]\tLoss: 0.000066\nTrain Epoch: 99 [800/2430 (33%)]\tLoss: 0.000123\nTrain Epoch: 99 [1200/2430 (49%)]\tLoss: 0.000175\nTrain Epoch: 99 [1600/2430 (66%)]\tLoss: 0.000137\nTrain Epoch: 99 [2000/2430 (82%)]\tLoss: 0.000068\nTrain Epoch: 99 [2400/2430 (98%)]\tLoss: 0.000090\n\nevaluating...\nTest set:\tAverage loss: 1.0364, Average CER: 0.140877 Average WER: 0.5850\n\nTrain Epoch: 100 [0/2430 (0%)]\tLoss: 0.000087\nTrain Epoch: 100 [400/2430 (16%)]\tLoss: 0.000076\nTrain Epoch: 100 [800/2430 (33%)]\tLoss: 0.000109\nTrain Epoch: 100 [1200/2430 (49%)]\tLoss: 0.000110\nTrain Epoch: 100 [1600/2430 (66%)]\tLoss: 0.000102\nTrain Epoch: 100 [2000/2430 (82%)]\tLoss: 0.000134\nTrain Epoch: 100 [2400/2430 (98%)]\tLoss: 0.000052\n\nevaluating...\nTest set:\tAverage loss: 1.0367, Average CER: 0.141366 Average WER: 0.5847\n\nCPU times: user 41min 5s, sys: 49.1 s, total: 41min 54s\nWall time: 42min\n","output_type":"stream"}]},{"cell_type":"code","source":"#use_cuda = torch.cuda.is_available()\n#device = torch.device(\"cpu\")\nneeded_device = torch.device(\"cpu\")\nmodel = torch.load('/kaggle/input/dop-test-files/model_for_correction_test.pt', map_location=torch.device('cpu'))\n\n#1543 1882 1372\n\nmodel.to(needed_device)\nprint(needed_device)\n#predict(model, '/kaggle/input/upd-speech/mono_voice/1964.wav', device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:55:01.136223Z","iopub.execute_input":"2024-04-28T15:55:01.138891Z","iopub.status.idle":"2024-04-28T15:55:01.459718Z","shell.execute_reply.started":"2024-04-28T15:55:01.138833Z","shell.execute_reply":"2024-04-28T15:55:01.458440Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"d = {'X_test': X_test, 'label': y_test}\ndf_test = pd.DataFrame(data=d)\ndf_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:54:23.847934Z","iopub.execute_input":"2024-04-28T15:54:23.849448Z","iopub.status.idle":"2024-04-28T15:54:31.631350Z","shell.execute_reply.started":"2024-04-28T15:54:23.849381Z","shell.execute_reply":"2024-04-28T15:54:31.629755Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                              X_test  \\\n0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n1  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n2  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n3  [[tensor(2.1031e-08), tensor(3.2072e-09), tens...   \n4  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n\n                                               label  \n0                                             машина  \n1                         любовь всегда находит путь  \n2  лучший способ предсказать будущее создать его ...  \n3                                   живописный закат  \n4                           горячий пирог с яблоками  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_test</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>машина</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>любовь всегда находит путь</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>лучший способ предсказать будущее создать его ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[tensor(2.1031e-08), tensor(3.2072e-09), tens...</td>\n      <td>живописный закат</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>горячий пирог с яблоками</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:31:55.368248Z","iopub.execute_input":"2024-04-23T15:31:55.368985Z","iopub.status.idle":"2024-04-23T15:31:55.375900Z","shell.execute_reply.started":"2024-04-23T15:31:55.368942Z","shell.execute_reply":"2024-04-23T15:31:55.374762Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['машина',\n 'любовь всегда находит путь',\n 'лучший способ предсказать будущее создать его самому',\n 'живописный закат',\n 'горячий пирог с яблоками']"},"metadata":{}}]},{"cell_type":"code","source":"def count_test_cer(row, model):\n    prediction = predict_with_tensor(model, row['X_test'])\n    return cer(row['label'], prediction)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:55:05.816702Z","iopub.execute_input":"2024-04-28T15:55:05.818397Z","iopub.status.idle":"2024-04-28T15:55:05.825470Z","shell.execute_reply.started":"2024-04-28T15:55:05.818292Z","shell.execute_reply":"2024-04-28T15:55:05.824500Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_test['CER'] = df_test.apply(count_test_cer, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:57:15.439249Z","iopub.execute_input":"2024-04-28T15:57:15.439853Z","iopub.status.idle":"2024-04-28T15:57:53.328053Z","shell.execute_reply.started":"2024-04-28T15:57:15.439806Z","shell.execute_reply":"2024-04-28T15:57:53.326635Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 20, 123])\nмашина\ntorch.Size([1, 1, 20, 432])\nлюбосы всегда находит пот\ntorch.Size([1, 1, 20, 710])\nлучис пособ пречказать будущие сяздать его сомому\ntorch.Size([1, 1, 20, 451])\nживаписный изакат\ntorch.Size([1, 1, 20, 538])\nгрячий перакс яблаканмы\ntorch.Size([1, 1, 20, 524])\nцветущий ысад ипольнеет ароматом\ntorch.Size([1, 1, 20, 521])\nчто думаешь ол новом афильме\ntorch.Size([1, 1, 20, 574])\nникогда не поздно осуществлять свои мечты\ntorch.Size([1, 1, 20, 462])\nложичка из светра\ntorch.Size([1, 1, 20, 252])\nидя пудварус\ntorch.Size([1, 1, 20, 282])\nвоздушная пошка\ntorch.Size([1, 1, 20, 427])\nшикатыйтью до рошка\ntorch.Size([1, 1, 20, 782])\nблюбокий взгляд может раскрыт молоко тай\ntorch.Size([1, 1, 20, 380])\nте понон\ntorch.Size([1, 1, 20, 459])\nонаникома неотка зовыло помочь\ntorch.Size([1, 1, 20, 200])\nтехий звук\ntorch.Size([1, 1, 20, 598])\nсвидетельствуют о праблемах спецнью\ntorch.Size([1, 1, 20, 343])\nпоттыши мою петецию\ntorch.Size([1, 1, 20, 408])\nпрости ная сегодня вертолют\ntorch.Size([1, 1, 20, 401])\nготовишь уже обед и линет\ntorch.Size([1, 1, 20, 806])\nбе тебе вы хотинас замяся вечером\ntorch.Size([1, 1, 20, 243])\nкак буридано в осё\ntorch.Size([1, 1, 20, 149])\nкак дела\ntorch.Size([1, 1, 20, 435])\nабрагна полнился дожтевой водой\ntorch.Size([1, 1, 20, 528])\nбыла удевительно встретится стобой\ntorch.Size([1, 1, 20, 471])\nбесцея выголоки\ntorch.Size([1, 1, 20, 341])\nспортивный костюм для бега\ntorch.Size([1, 1, 20, 347])\nладно ты меня уговорила\ntorch.Size([1, 1, 20, 325])\nпочемубном леполитечь\ntorch.Size([1, 1, 20, 376])\nсвежие ягоды на кустах\ntorch.Size([1, 1, 20, 451])\nкак скозать ей обэтом\ntorch.Size([1, 1, 20, 185])\nдоруга\ntorch.Size([1, 1, 20, 809])\nэто занятие кошу потходит для дите\ntorch.Size([1, 1, 20, 459])\nнаданобести порядок уже бы\ntorch.Size([1, 1, 20, 582])\nфотографии заприщены в этом бесте\ntorch.Size([1, 1, 20, 258])\nблагоприятный\ntorch.Size([1, 1, 20, 333])\nрассморение на должность\ntorch.Size([1, 1, 20, 471])\nпочесь поспотиред сириар\ntorch.Size([1, 1, 20, 294])\nобернутся на зад\ntorch.Size([1, 1, 20, 438])\nкрасивые раваски\ntorch.Size([1, 1, 20, 342])\nя завадель\ntorch.Size([1, 1, 20, 132])\nрешетка\ntorch.Size([1, 1, 20, 340])\nпопробу этот торт\ntorch.Size([1, 1, 20, 555])\nурокий скрипки бывают очень сложными\ntorch.Size([1, 1, 20, 493])\nмига во вшемние\ntorch.Size([1, 1, 20, 178])\nбольшуй залом\ntorch.Size([1, 1, 20, 431])\nдопрай ноги\ntorch.Size([1, 1, 20, 381])\nкрасивый закат над океаном\ntorch.Size([1, 1, 20, 399])\nин формоционная сестема\ntorch.Size([1, 1, 20, 809])\nокак выт ладит твой идеотный мушина\ntorch.Size([1, 1, 20, 574])\nдушавный разговор с близким человеком\ntorch.Size([1, 1, 20, 489])\nпромая тат салация\ntorch.Size([1, 1, 20, 374])\nсказал с гореча\ntorch.Size([1, 1, 20, 621])\nвкоторыйчас мы вуходим на работу завтра\ntorch.Size([1, 1, 20, 227])\nзнания сила\ntorch.Size([1, 1, 20, 354])\nмня возникли проблемы\ntorch.Size([1, 1, 20, 229])\nсбыт\ntorch.Size([1, 1, 20, 287])\nгустая трова\ntorch.Size([1, 1, 20, 692])\nпустые обещение хуже чем нет обещаний вовсе\ntorch.Size([1, 1, 20, 427])\nобпныни кранке\ntorch.Size([1, 1, 20, 188])\nглубокий сон\ntorch.Size([1, 1, 20, 336])\nэто блюдо очень пострае\ntorch.Size([1, 1, 20, 582])\nнайдиче сьпособ быть полезном другим людем\ntorch.Size([1, 1, 20, 782])\nя уже поставил бельо встиру\ntorch.Size([1, 1, 20, 677])\nваса всицая в ертмни\ntorch.Size([1, 1, 20, 268])\nя взал себя в руке\ntorch.Size([1, 1, 20, 397])\nвоходные скора ачнутся\ntorch.Size([1, 1, 20, 507])\nтвой новый маряд выглядят порясающе\ntorch.Size([1, 1, 20, 401])\nоновый день новое возможности\ntorch.Size([1, 1, 20, 454])\nтихий зму сучя\ntorch.Size([1, 1, 20, 509])\nлефо с откидвайщимся диспвыем\ntorch.Size([1, 1, 20, 268])\nперевод песни\ntorch.Size([1, 1, 20, 489])\nнесунете шу раздажает\ntorch.Size([1, 1, 20, 397])\nработаю повыходным дням\ntorch.Size([1, 1, 20, 516])\nончаста потесествует из за работы\ntorch.Size([1, 1, 20, 564])\nкупить продо ты на ррнке\ntorch.Size([1, 1, 20, 210])\nдобиться целий\ntorch.Size([1, 1, 20, 537])\nдоский дне олпенис ма\ntorch.Size([1, 1, 20, 724])\nбыке сипырет зтаевыт полоз неганнаркол\ntorch.Size([1, 1, 20, 447])\nвемя коррее\ntorch.Size([1, 1, 20, 308])\nинструменты\ntorch.Size([1, 1, 20, 168])\nсмирись\ntorch.Size([1, 1, 20, 595])\nулыбайтесь чаще э то нделаютмирь светлее\ntorch.Size([1, 1, 20, 722])\nнадеесь мы получим заказанный товар дозавтра\ntorch.Size([1, 1, 20, 582])\nважнабыть глагодарным за тов что имиеш\ntorch.Size([1, 1, 20, 383])\nначалосилима весма итересное\ntorch.Size([1, 1, 20, 696])\nонавы выставела девя зядвер\ntorch.Size([1, 1, 20, 468])\nбезинторнето тут очин т кочно\ntorch.Size([1, 1, 20, 540])\nвызавите мне акший пожалуйста\ntorch.Size([1, 1, 20, 241])\nя покуша\ntorch.Size([1, 1, 20, 472])\nжизнь безсцили десцильноя жизнь\ntorch.Size([1, 1, 20, 674])\nвдетствея был оченьзостенчивый етехи ребено\ntorch.Size([1, 1, 20, 400])\nкрулий начь\ntorch.Size([1, 1, 20, 607])\nвможете передать мне этот болокнот пожалуйста\ntorch.Size([1, 1, 20, 227])\nсладкий запах\ntorch.Size([1, 1, 20, 178])\nтихий уголок\ntorch.Size([1, 1, 20, 240])\nсинот в помойке\ntorch.Size([1, 1, 20, 454])\nзолотаярывка истолняет жилания\ntorch.Size([1, 1, 20, 429])\nэто было невероятно крута\ntorch.Size([1, 1, 20, 383])\nна ушники застряли на провад\ntorch.Size([1, 1, 20, 602])\nрамантысачая дерьстви\ntorch.Size([1, 1, 20, 365])\nжаркий ен\ntorch.Size([1, 1, 20, 404])\nпокаещё в грашини эдольвейс\ntorch.Size([1, 1, 20, 565])\nакое чуство будто жизин проходет мима\ntorch.Size([1, 1, 20, 564])\nсвиркающий не селнчессног\ntorch.Size([1, 1, 20, 201])\nочки ссолфет ко\ntorch.Size([1, 1, 20, 252])\nчитаю книгу\ntorch.Size([1, 1, 20, 1110])\nотнасения основываются на давериие друк к другу\ntorch.Size([1, 1, 20, 273])\nрокзак дуратка невый\ntorch.Size([1, 1, 20, 498])\nпосмотреть серил вечеро\ntorch.Size([1, 1, 20, 369])\nпоен\ntorch.Size([1, 1, 20, 660])\nотстантеон займятся связью когда приидет\ntorch.Size([1, 1, 20, 544])\nкристоже нымталется\ntorch.Size([1, 1, 20, 431])\nлето тлитцся просто бесконечно\ntorch.Size([1, 1, 20, 545])\nснег подоет крупнони лопьеми\ntorch.Size([1, 1, 20, 575])\nздесь в глубинес слышу тволюемя снова\ntorch.Size([1, 1, 20, 367])\nком пошел за продуктами\ntorch.Size([1, 1, 20, 333])\nне порочное зачатие\ntorch.Size([1, 1, 20, 337])\nбухий не знает усталости\ntorch.Size([1, 1, 20, 149])\nсиалае сить \ntorch.Size([1, 1, 20, 352])\nхочиться печеный картофиль\ntorch.Size([1, 1, 20, 407])\nсвежий забар\ntorch.Size([1, 1, 20, 633])\nмазакопвтыт с навесь новой спр\ntorch.Size([1, 1, 20, 472])\nважная бувага\ntorch.Size([1, 1, 20, 389])\nразвиваться всегда нужно\ntorch.Size([1, 1, 20, 841])\nне закровой глаза на менуто потамочта могуд поменяться все\ntorch.Size([1, 1, 20, 281])\nморыщ ц мокоронами\ntorch.Size([1, 1, 20, 614])\nкрасивый закат нат городом\ntorch.Size([1, 1, 20, 1008])\nникто ни может изаменить прошлое на дожить настоящим и смореть в будущее\ntorch.Size([1, 1, 20, 236])\nбелый снег\ntorch.Size([1, 1, 20, 499])\nлучше быте диноким чем в плохой компании\ntorch.Size([1, 1, 20, 294])\nтаплюнный\ntorch.Size([1, 1, 20, 955])\nсекссом пособе дле меня нетак важен как эмоциананное понимание\ntorch.Size([1, 1, 20, 180])\nсправка\ntorch.Size([1, 1, 20, 486])\nможно я подыйду нимного поблизы\ntorch.Size([1, 1, 20, 786])\nприя набелисти вреля систарили друзьями\ntorch.Size([1, 1, 20, 284])\nпоплывём на переганки\ntorch.Size([1, 1, 20, 373])\nя езжу на автобусе\ntorch.Size([1, 1, 20, 392])\nшумный городской транспорт\ntorch.Size([1, 1, 20, 1062])\nкаждаи подение эта новый сал поднатся ещё вс\ntorch.Size([1, 1, 20, 295])\nобними крепче\ntorch.Size([1, 1, 20, 234])\nкрасивый закат\ntorch.Size([1, 1, 20, 199])\nжаркий день\ntorch.Size([1, 1, 20, 718])\nкурить табок придумали индерици\ntorch.Size([1, 1, 20, 260])\nдоктай\ntorch.Size([1, 1, 20, 802])\n стаять в очерте задовым плейстерсин\ntorch.Size([1, 1, 20, 424])\nнам нуже покетик молока\ntorch.Size([1, 1, 20, 243])\nя люблю рановстовач\ntorch.Size([1, 1, 20, 490])\nжаркое лето время для утпуска\ntorch.Size([1, 1, 20, 176])\nмодо лист\ntorch.Size([1, 1, 20, 442])\nгыты кокда васколка\ntorch.Size([1, 1, 20, 316])\nдайте волку банад\ntorch.Size([1, 1, 20, 228])\nмлекпитаещие\ntorch.Size([1, 1, 20, 361])\nнуетаеще ког посмотреть\ntorch.Size([1, 1, 20, 307])\nсталовая для стадентов\ntorch.Size([1, 1, 20, 415])\nмир начинается с голавы\ntorch.Size([1, 1, 20, 216])\nсокрощение\ntorch.Size([1, 1, 20, 340])\nрассвет на вершине горыд\ntorch.Size([1, 1, 20, 363])\nпосле дождо\ntorch.Size([1, 1, 20, 362])\nумоего дома\ntorch.Size([1, 1, 20, 547])\nдоружба не сет поддержку и понимание\ntorch.Size([1, 1, 20, 316])\nвкусное морожное\ntorch.Size([1, 1, 20, 569])\nспосибоза приглошение на я не смогу\ntorch.Size([1, 1, 20, 326])\nжелаю сомого наи лучшело\ntorch.Size([1, 1, 20, 1004])\nжизнь долодет быстра носролнайтесьий кайный ды\ntorch.Size([1, 1, 20, 1017])\nголька на в ножливось па безлужне рамненом\ntorch.Size([1, 1, 20, 416])\nкак можно добраться до\ntorch.Size([1, 1, 20, 440])\nкакака выглидит твоз идеальный мушшина\ntorch.Size([1, 1, 20, 106])\nтанец\ntorch.Size([1, 1, 20, 759])\nа бычно рапею ча и е буте град\ntorch.Size([1, 1, 20, 438])\nтебе точна больсе нечего делать\ntorch.Size([1, 1, 20, 182])\nсильный запах\ntorch.Size([1, 1, 20, 145])\nнна долга\ntorch.Size([1, 1, 20, 267])\nпервый снег зимой\ntorch.Size([1, 1, 20, 538])\nу меня сегодня просто ужасный день\ntorch.Size([1, 1, 20, 442])\nжелтый лист на дериви\ntorch.Size([1, 1, 20, 244])\nкрасивый рассвет\ntorch.Size([1, 1, 20, 524])\nкрабил копод святднимнебо\ntorch.Size([1, 1, 20, 163])\nсегодня\ntorch.Size([1, 1, 20, 132])\nпогурец\ntorch.Size([1, 1, 20, 361])\nи что дальше\ntorch.Size([1, 1, 20, 263])\nжив курилка\ntorch.Size([1, 1, 20, 567])\nзалочисстый песок на плаже\ntorch.Size([1, 1, 20, 345])\nможешь притащит едуб\ntorch.Size([1, 1, 20, 601])\nсегодно с лучилысь много хорошего\ntorch.Size([1, 1, 20, 301])\nшарная авторучка\ntorch.Size([1, 1, 20, 416])\nаработу ю вканпалие\ntorch.Size([1, 1, 20, 665])\nмечрыстали быльу только еслеты вере вних\ntorch.Size([1, 1, 20, 390])\nчто тый обычно ешь на завтрак\ntorch.Size([1, 1, 20, 429])\nпросторная светлая комната\ntorch.Size([1, 1, 20, 475])\nморской бриз ду у побережие\ntorch.Size([1, 1, 20, 340])\nкристальный водопад\ntorch.Size([1, 1, 20, 432])\nчистое бельё пошлестирки\ntorch.Size([1, 1, 20, 342])\nжелание\ntorch.Size([1, 1, 20, 574])\nне могу позовонить у меня сел телефон\ntorch.Size([1, 1, 20, 642])\nодежда отражает нашо личность\ntorch.Size([1, 1, 20, 719])\nвашатеть заивляет и крайне нердична чтоон невиновен\ntorch.Size([1, 1, 20, 387])\nкансейт\ntorch.Size([1, 1, 20, 298])\nинтерес\ntorch.Size([1, 1, 20, 262])\nмедльный процесс\ntorch.Size([1, 1, 20, 144])\nпогнали\ntorch.Size([1, 1, 20, 821])\nхороший овдых залок продуктивной работи\ntorch.Size([1, 1, 20, 296])\nчерный кошмар\ntorch.Size([1, 1, 20, 299])\nнести свою лебто\ntorch.Size([1, 1, 20, 569])\nтвоиновая штаны выглядот здорова\ntorch.Size([1, 1, 20, 507])\nоден эспрессо пожалуйста\ntorch.Size([1, 1, 20, 277])\nсемиро казлят\ntorch.Size([1, 1, 20, 438])\nбальшон завт\ntorch.Size([1, 1, 20, 276])\nтемная комната\ntorch.Size([1, 1, 20, 163])\nположить\ntorch.Size([1, 1, 20, 450])\nвеща вый день рождения с друзьями\ntorch.Size([1, 1, 20, 542])\nпрости других ради со мого себя\ntorch.Size([1, 1, 20, 534])\nбудьтесильном кдавы чувствуете слабость\ntorch.Size([1, 1, 20, 451])\nзаберозмны а зручоб\ntorch.Size([1, 1, 20, 354])\nзабирош меня с учеб\ntorch.Size([1, 1, 20, 306])\nмогический сумтрак леса\ntorch.Size([1, 1, 20, 190])\nполскольский\ntorch.Size([1, 1, 20, 410])\nмогдо ланц в сетыки закрылся\ntorch.Size([1, 1, 20, 289])\nпринцесся спослас\ntorch.Size([1, 1, 20, 192])\nтехий вечер\ntorch.Size([1, 1, 20, 196])\nчистая река\ntorch.Size([1, 1, 20, 848])\nнавнужно болс добаты в этоммие\ntorch.Size([1, 1, 20, 444])\nтальночный лучи\ntorch.Size([1, 1, 20, 724])\nтенеприт стувтарес цо мне слачилось\ntorch.Size([1, 1, 20, 212])\nдом\ntorch.Size([1, 1, 20, 292])\nкрепкий кофе\ntorch.Size([1, 1, 20, 482])\nпо чупесах\ntorch.Size([1, 1, 20, 666])\nуменя вазникли проблема\ntorch.Size([1, 1, 20, 216])\nно с с кольцом\ntorch.Size([1, 1, 20, 282])\nнодо купить продокты\ntorch.Size([1, 1, 20, 206])\nкорозь то сковал\ntorch.Size([1, 1, 20, 263])\nмат мне не боголубоя\ntorch.Size([1, 1, 20, 607])\nзеленый гозон идеальный места для пекника\ntorch.Size([1, 1, 20, 529])\nсльдиме делает опут\ntorch.Size([1, 1, 20, 402])\nэто очнь нилось ваший стораны\ntorch.Size([1, 1, 20, 243])\nна рушение\ntorch.Size([1, 1, 20, 688])\nлески фит различными гребами и жин нестью\ntorch.Size([1, 1, 20, 708])\nуверты врозатсдра и других\ntorch.Size([1, 1, 20, 233])\nскольский тип\ntorch.Size([1, 1, 20, 429])\nрепкий запах бревесины\ntorch.Size([1, 1, 20, 514])\nездить по ушам гвоздями подоске\ntorch.Size([1, 1, 20, 252])\nграмкий смех\ntorch.Size([1, 1, 20, 440])\nтапки не стоит оставлять на улицы\ntorch.Size([1, 1, 20, 434])\nкупить лекарство от на смодка\ntorch.Size([1, 1, 20, 1012])\nзабаться о своих близких дудих эта ате из ключий ксчастью жизни\ntorch.Size([1, 1, 20, 509])\nжело оказалась силный\ntorch.Size([1, 1, 20, 612])\nвольивляется главном двибетелям пуспеха\ntorch.Size([1, 1, 20, 411])\nватный диск\ntorch.Size([1, 1, 20, 692])\nперинская плата усторела для новых протессеров\ntorch.Size([1, 1, 20, 957])\nмогический тотем и верчцим плевени гвасиутл\ntorch.Size([1, 1, 20, 281])\nя не могу дышать\ntorch.Size([1, 1, 20, 449])\nнекто не может понравится всем\ntorch.Size([1, 1, 20, 220])\nрож попоя с\ntorch.Size([1, 1, 20, 221])\nсломаный инстромен\ntorch.Size([1, 1, 20, 316])\nзубуная паста\ntorch.Size([1, 1, 20, 411])\nзаправить топливо вмашину\ntorch.Size([1, 1, 20, 536])\nбезмя тесный закат\ntorch.Size([1, 1, 20, 340])\nобненно красный закат\ntorch.Size([1, 1, 20, 462])\nзелены окумулятор\ntorch.Size([1, 1, 20, 387])\nимсррумерты\ntorch.Size([1, 1, 20, 582])\nвода вузере простращная ичистая\ntorch.Size([1, 1, 20, 158])\nсоциальность\ntorch.Size([1, 1, 20, 282])\nкуда мы идем дальше\ntorch.Size([1, 1, 20, 276])\nбесконечное небу\ntorch.Size([1, 1, 20, 383])\nгустой туман\ntorch.Size([1, 1, 20, 378])\nстрана где не заходит солнце\ntorch.Size([1, 1, 20, 533])\nзакат навир синего рыт\ntorch.Size([1, 1, 20, 420])\nкрасивый цветок\ntorch.Size([1, 1, 20, 233])\nнадо сменить тему\ntorch.Size([1, 1, 20, 294])\nпопасты в просак\ntorch.Size([1, 1, 20, 775])\nтакан может пежит радел ую войну\ntorch.Size([1, 1, 20, 727])\nкрасное яблако на зленый траве вглядит опекисна\ntorch.Size([1, 1, 20, 438])\nпопас к прощак\ntorch.Size([1, 1, 20, 435])\nхложба вармии делосерьязное\ntorch.Size([1, 1, 20, 1113])\nнестыснай тись выть уросвимыми это признак силел\ntorch.Size([1, 1, 20, 693])\nвзакаа гола ваз в залась в ненеса\ntorch.Size([1, 1, 20, 670])\nкупла сегодня продукты что добавит встесок\ntorch.Size([1, 1, 20, 374])\nвызвитем не таксий пожалуйста\ntorch.Size([1, 1, 20, 1114])\nвдетситве я был очень застенкивый и сихил ребянок\ntorch.Size([1, 1, 20, 308])\nникаких поломер\ntorch.Size([1, 1, 20, 341])\nпроизнес громка\ntorch.Size([1, 1, 20, 407])\nкакой фиим сморен сегодня\ntorch.Size([1, 1, 20, 308])\nчто вы посоветуите\ntorch.Size([1, 1, 20, 451])\nтамначалство все время мняется\ntorch.Size([1, 1, 20, 184])\nя пытался\ntorch.Size([1, 1, 20, 415])\nлистья надеревьях меняет цвет\ntorch.Size([1, 1, 20, 424])\nя устал и хочу лечь спать\ntorch.Size([1, 1, 20, 400])\nедушка мне тёмная материя\ntorch.Size([1, 1, 20, 802])\nспать рчепере тесав день не очен полезно для организма\ntorch.Size([1, 1, 20, 325])\nрамантизация действий\ntorch.Size([1, 1, 20, 349])\nгроми смих друфей\ntorch.Size([1, 1, 20, 450])\nестили новости из школы\ntorch.Size([1, 1, 20, 396])\nтивая гаван\ntorch.Size([1, 1, 20, 214])\nкруглый мядчь\ntorch.Size([1, 1, 20, 365])\nвладелец\ntorch.Size([1, 1, 20, 372])\nкорный лес\ntorch.Size([1, 1, 20, 144])\nуспех\ntorch.Size([1, 1, 20, 282])\nколько для вызрослых\ntorch.Size([1, 1, 20, 232])\nбленная дорога\ntorch.Size([1, 1, 20, 316])\nнакроет горад с головой\ntorch.Size([1, 1, 20, 284])\nя не хочу в стовать\ntorch.Size([1, 1, 20, 836])\nкогда бы лего не позвали он всегда отзывался на помощь другин\ntorch.Size([1, 1, 20, 257])\nтубиновая птится\ntorch.Size([1, 1, 20, 528])\nзабота о здоровье близких людий\ntorch.Size([1, 1, 20, 143])\nжевоя огонь\ntorch.Size([1, 1, 20, 411])\nкренпкий длепон\ntorch.Size([1, 1, 20, 307])\nдовел добелого коления к\ntorch.Size([1, 1, 20, 740])\nродители приедут завтра на доубурать вартиру\ntorch.Size([1, 1, 20, 730])\nпренимой изнменения покшанс на новое возможлости\ntorch.Size([1, 1, 20, 412])\nвыглядешь хорошо сегодня\ntorch.Size([1, 1, 20, 423])\nсколсечейтик\ntorch.Size([1, 1, 20, 475])\nиний арнаминт на ковре\ntorch.Size([1, 1, 20, 802])\nхорожая побода давай сходим на бровумку\ntorch.Size([1, 1, 20, 128])\nо светых\ntorch.Size([1, 1, 20, 279])\nжаркий пустыр\ntorch.Size([1, 1, 20, 480])\nкто ниботь здесь говорит по руски\ntorch.Size([1, 1, 20, 400])\nизмухи слана\ntorch.Size([1, 1, 20, 805])\nнеобходимость идобретать это мать всех эзабретений\ntorch.Size([1, 1, 20, 309])\nдекий тляж\ntorch.Size([1, 1, 20, 471])\nи уже не гуду\ntorch.Size([1, 1, 20, 243])\nбаланс в жизни\ntorch.Size([1, 1, 20, 445])\nстискцивою убм\ntorch.Size([1, 1, 20, 333])\nбанковская карта\ntorch.Size([1, 1, 20, 230])\nглубокий с мысал\ntorch.Size([1, 1, 20, 309])\nкарандаш без грефеля\ntorch.Size([1, 1, 20, 209])\nшладкий шоколад\ntorch.Size([1, 1, 20, 384])\nполскол счи\ntorch.Size([1, 1, 20, 192])\nсвежий запах\ntorch.Size([1, 1, 20, 330])\nты знаешь чты ябоюсь\ntorch.Size([1, 1, 20, 296])\nснежный поцелуй\ntorch.Size([1, 1, 20, 407])\nгристалный купак\ntorch.Size([1, 1, 20, 416])\nуозима холоддуе и белое время\ntorch.Size([1, 1, 20, 622])\nлюбовь этосчило способное изменить мир\ntorch.Size([1, 1, 20, 309])\nтемный цвет\ntorch.Size([1, 1, 20, 432])\nчерный кофе с печеньцами\ntorch.Size([1, 1, 20, 271])\nчто за облом\ntorch.Size([1, 1, 20, 704])\nяркое дето вы зывает залду\ntorch.Size([1, 1, 20, 403])\nлогкий утеник\ntorch.Size([1, 1, 20, 528])\nкосмось не перестоёт нас удивлять\ntorch.Size([1, 1, 20, 686])\nготовить можно с разный водой но лучше схороший\ntorch.Size([1, 1, 20, 335])\nэто оученлигко делается\ntorch.Size([1, 1, 20, 551])\nкрикет восу иваномскую\ntorch.Size([1, 1, 20, 356])\nя не могутерпить обрикосе\ntorch.Size([1, 1, 20, 190])\nбумага есть\ntorch.Size([1, 1, 20, 400])\nгустол лес\ntorch.Size([1, 1, 20, 251])\nкочта со стразаний\ntorch.Size([1, 1, 20, 352])\nцветыв соду прекрасные\ntorch.Size([1, 1, 20, 396])\nтапле ца\ntorch.Size([1, 1, 20, 373])\nблага приядны\ntorch.Size([1, 1, 20, 259])\nпприятного опетита\ntorch.Size([1, 1, 20, 327])\nкакой увас любимый цвет\ntorch.Size([1, 1, 20, 294])\nи морестанят солоний\ntorch.Size([1, 1, 20, 289])\nмуладно я тоже\ntorch.Size([1, 1, 20, 847])\nмогулея попросить вашсовит поповоду этого провлемного лапролса\ntorch.Size([1, 1, 20, 251])\nтректория\ntorch.Size([1, 1, 20, 232])\nподтновлемие\ntorch.Size([1, 1, 20, 145])\nпапка\ntorch.Size([1, 1, 20, 196])\nбольшой пекап\ntorch.Size([1, 1, 20, 294])\nвойна продолжается\ntorch.Size([1, 1, 20, 657])\nмягкий пуховы плед создаю туютную отмасферу\ntorch.Size([1, 1, 20, 731])\nвзедда стараттесь выдланься истолпы\ntorch.Size([1, 1, 20, 282])\nморской бриз\ntorch.Size([1, 1, 20, 332])\nмокрая кошка\ntorch.Size([1, 1, 20, 199])\nкрепкий телефон\ntorch.Size([1, 1, 20, 411])\nкалиш начас\ntorch.Size([1, 1, 20, 452])\nток хорошо жить на свете\ntorch.Size([1, 1, 20, 229])\nяркая звезда\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test['CER'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T15:58:21.648749Z","iopub.execute_input":"2024-04-28T15:58:21.649241Z","iopub.status.idle":"2024-04-28T15:58:21.659077Z","shell.execute_reply.started":"2024-04-28T15:58:21.649201Z","shell.execute_reply":"2024-04-28T15:58:21.657687Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.13971105628910815"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2023-05-24T10:26:24.339488Z","iopub.execute_input":"2023-05-24T10:26:24.340405Z","iopub.status.idle":"2023-05-24T10:26:24.350954Z","shell.execute_reply.started":"2023-05-24T10:26:24.340364Z","shell.execute_reply":"2023-05-24T10:26:24.349831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:16:11.401175Z","iopub.execute_input":"2023-05-13T16:16:11.401879Z","iopub.status.idle":"2023-05-13T16:16:11.430020Z","shell.execute_reply.started":"2023-05-13T16:16:11.401838Z","shell.execute_reply":"2023-05-13T16:16:11.428960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(directory):\n    total_duration = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            filepath = os.path.join(directory, filename)\n            with wave.open(filepath, 'r') as wav_file:\n                frames = wav_file.getnframes()\n                rate = wav_file.getframerate()\n                duration = frames / float(rate)\n                total_duration += duration\n    return total_duration\n\ndirectory = '/kaggle/input/upd-speech/mono_voice'\ntotal_duration = get_wav_duration(directory)\nprint('Total duration of WAV files:', total_duration, 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:15.415086Z","iopub.execute_input":"2023-07-05T10:09:15.415876Z","iopub.status.idle":"2023-07-05T10:09:18.755936Z","shell.execute_reply.started":"2023-07-05T10:09:15.415836Z","shell.execute_reply":"2023-07-05T10:09:18.754693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))\nseconds = 3661\nformatted_time = format_time(total_duration)\nprint(formatted_time)  # Output: '01:01:01'","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:23.353548Z","iopub.execute_input":"2023-07-05T10:09:23.354296Z","iopub.status.idle":"2023-07-05T10:09:23.361628Z","shell.execute_reply.started":"2023-07-05T10:09:23.354254Z","shell.execute_reply":"2023-07-05T10:09:23.360431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}