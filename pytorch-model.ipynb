{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5321255,"sourceType":"datasetVersion","datasetId":3091651},{"sourceId":5618710,"sourceType":"datasetVersion","datasetId":3230790},{"sourceId":5677279,"sourceType":"datasetVersion","datasetId":2989949},{"sourceId":5677449,"sourceType":"datasetVersion","datasetId":3071831},{"sourceId":5760288,"sourceType":"datasetVersion","datasetId":3311237},{"sourceId":8515857,"sourceType":"datasetVersion","datasetId":3213578},{"sourceId":8537485,"sourceType":"datasetVersion","datasetId":5099750},{"sourceId":8537499,"sourceType":"datasetVersion","datasetId":5099761},{"sourceId":8537514,"sourceType":"datasetVersion","datasetId":5099772},{"sourceId":8537530,"sourceType":"datasetVersion","datasetId":5099776},{"sourceId":8560616,"sourceType":"datasetVersion","datasetId":4230886},{"sourceId":8562283,"sourceType":"datasetVersion","datasetId":5118180}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np \nimport matplotlib\nfrom transformers import AutoModelForSeq2SeqLM, T5TokenizerFast\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:14:12.217308Z","iopub.execute_input":"2024-06-09T04:14:12.218229Z","iopub.status.idle":"2024-06-09T04:14:17.076722Z","shell.execute_reply.started":"2024-06-09T04:14:12.218182Z","shell.execute_reply":"2024-06-09T04:14:17.075454Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def avg_wer(wer_scores, combined_ref_len):\n    return float(sum(wer_scores)) / float(combined_ref_len)\n\n\ndef _levenshtein_distance(ref, hyp):\n    m = len(ref)\n    n = len(hyp)\n\n    # special case\n    if ref == hyp:\n        return 0\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n\n    if m < n:\n        ref, hyp = hyp, ref\n        m, n = n, m\n\n    distance = np.zeros((2, n + 1), dtype=np.int32)\n\n    for j in range(0,n + 1):\n        distance[0][j] = j\n\n    for i in range(1, m + 1):\n        prev_row_idx = (i - 1) % 2\n        cur_row_idx = i % 2\n        distance[cur_row_idx][0] = i\n        for j in range(1, n + 1):\n            if ref[i - 1] == hyp[j - 1]:\n                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n            else:\n                s_num = distance[prev_row_idx][j - 1] + 1\n                i_num = distance[cur_row_idx][j - 1] + 1\n                d_num = distance[prev_row_idx][j] + 1\n                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n\n    return distance[m % 2][n]\n\n\ndef word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    ref_words = reference.split(delimiter)\n    hyp_words = hypothesis.split(delimiter)\n\n    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n    return float(edit_distance), len(ref_words)\n\n\ndef char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    join_char = ' '\n    if remove_space == True:\n        join_char = ''\n\n    reference = join_char.join(filter(None, reference.split(' ')))\n    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n\n    edit_distance = _levenshtein_distance(reference, hypothesis)\n    return float(edit_distance), len(reference)\n\n\ndef wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n                                         delimiter)\n\n    if ref_len == 0:\n        raise ValueError(\"Reference's word number should be greater than 0.\")\n\n    wer = float(edit_distance) / ref_len\n    return wer\n\n\ndef cer(reference, hypothesis, ignore_case=False, remove_space=False):\n    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n                                         remove_space)\n\n    if ref_len == 0:\n        raise ValueError(\"Length of reference should be greater than 0.\")\n\n    cer = float(edit_distance) / ref_len\n    return cer\n\nclass TextTransform:\n    def __init__(self):\n        self.char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n                  \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n                  \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n                  \"я\": 31, \"х\": 32, \" \": 33}\n\n        self.index_map = {}\n        for key, value in self.char_map.items():\n            self.index_map[value] = key\n\n    def text_to_int(self, text):\n        int_sequence = []\n        for c in text:\n            ch = self.char_map[c]\n            int_sequence.append(ch)\n        return int_sequence\n\n    def int_to_text(self, labels):\n        string = []\n        for i in labels:\n            string.append(self.index_map[i])\n        return ''.join(string)\n\n\ntrain_audio_transforms = nn.Sequential(\n    torchaudio.transforms.MFCC(n_mfcc=20)\n)\n\n\nvalid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n\ntext_transform = TextTransform()\n\ndef data_processing(data, data_type=\"train\"):\n    spectrograms = []\n    labels = []\n    input_lengths = []\n    label_lengths = []\n    for (waveform, utterance) in data:\n        if data_type == 'train':\n            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        elif data_type == 'valid':\n            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        else:\n            raise Exception('data_type should be train or valid')\n        spectrograms.append(spec)\n        label = torch.Tensor(text_transform.text_to_int(utterance))\n        labels.append(label)\n        input_lengths.append(spec.shape[0]//3)\n        label_lengths.append(len(label))\n    \n    spectrograms1 = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n            \n    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n\n    return spectrograms1, labels, input_lengths, label_lengths\n\n\ndef GreedyDecoder(output, labels, label_lengths, blank_label=34, collapse_repeated=True):\n    arg_maxes = torch.argmax(output, dim=2)\n    decodes = []\n    targets = []\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n        for j, index in enumerate(args):\n            if index != blank_label:\n                if collapse_repeated and j != 0 and index == args[j -1]:\n                    continue\n                decode.append(index.item())\n        decodes.append(text_transform.int_to_text(decode))\n    return decodes, targets","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:14:17.079140Z","iopub.execute_input":"2024-06-09T04:14:17.079990Z","iopub.status.idle":"2024-06-09T04:14:17.250257Z","shell.execute_reply.started":"2024-06-09T04:14:17.079948Z","shell.execute_reply":"2024-06-09T04:14:17.249189Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"class BidirectionalGRU(nn.Module):\n\n    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n        super(BidirectionalGRU, self).__init__()\n\n        self.BiGRU = nn.GRU(\n            input_size=rnn_dim, hidden_size=hidden_size,\n            num_layers=1, batch_first=batch_first, bidirectional=True)\n        self.layer_norm = nn.LayerNorm(rnn_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        x = F.gelu(x)\n        x, _ = self.BiGRU(x)\n        x = self.dropout(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:14:17.251735Z","iopub.execute_input":"2024-06-09T04:14:17.252142Z","iopub.status.idle":"2024-06-09T04:14:17.260988Z","shell.execute_reply.started":"2024-06-09T04:14:17.252098Z","shell.execute_reply":"2024-06-09T04:14:17.259829Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Поменял там, где происходит загрузка, сохраняется id звукового файла, а потом в excel файле по колонке old_id ищется текст\n#И того звук и текст к нему\n\nimport pandas as pd\nimport librosa\n\n# file = pd.read_excel('/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches v1.xlsx')\n# #y = [sentence for sentence in file['text']]\n# y = []\n# dir_name = \"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"\n# files_in_dir = os.listdir(dir_name)\n\n# X = []\n# i = 1\n\n# for e in os.listdir(\"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"):\n#     file_name = e\n#     for old_id in range(0, 2073):\n#         if file_name.startswith(str(file['old_id'][old_id]) + '.'):\n#             y.extend([''.join(file['text'][old_id])])\n#             sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n#             sampl = sampl[np.newaxis, :]\n#             X.append(torch.Tensor(sampl))\n#             break\n\nfile = pd.read_excel('/kaggle/input/dataset-with-3-speakers/Speeches v1.xlsx')\n#y = [sentence for sentence in file['text']]\ny = []\ndir_name = \"/kaggle/input/dataset-with-3-speakers/Disorder Russian Speech/\"\nfiles_in_dir = os.listdir(dir_name)\n\nX = []\ni = 1\n\nfor e in os.listdir(\"/kaggle/input/dataset-with-3-speakers/Disorder Russian Speech/\"):\n    file_name = e\n    for old_id in range(0, 2073):\n        if file_name.startswith(str(file['old_id'][old_id])[:-1]):\n            y.extend([''.join(file['text'][old_id])])\n            sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n            sampl = sampl[np.newaxis, :]\n            X.append(torch.Tensor(sampl))\n            break","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:14:17.262983Z","iopub.execute_input":"2024-06-09T04:14:17.263292Z","iopub.status.idle":"2024-06-09T04:16:28.876122Z","shell.execute_reply.started":"2024-06-09T04:14:17.263265Z","shell.execute_reply":"2024-06-09T04:16:28.874923Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import random\npairs = list(zip(X, y))\nrandom.Random(20024).shuffle(pairs)\nX, y = zip(*pairs)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.877698Z","iopub.execute_input":"2024-06-09T04:16:28.878311Z","iopub.status.idle":"2024-06-09T04:16:28.891131Z","shell.execute_reply.started":"2024-06-09T04:16:28.878277Z","shell.execute_reply":"2024-06-09T04:16:28.889737Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y[:3]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.892490Z","iopub.execute_input":"2024-06-09T04:16:28.892866Z","iopub.status.idle":"2024-06-09T04:16:28.905952Z","shell.execute_reply.started":"2024-06-09T04:16:28.892837Z","shell.execute_reply":"2024-06-09T04:16:28.905046Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Где то есть куча копий',\n 'Твоя поддержка была для меня невероятно важна',\n 'Купить лекарства от насморка')"},"metadata":{}}]},{"cell_type":"code","source":"X[:3]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T03:40:51.790730Z","iopub.execute_input":"2024-06-09T03:40:51.791682Z","iopub.status.idle":"2024-06-09T03:40:51.818050Z","shell.execute_reply.started":"2024-06-09T03:40:51.791641Z","shell.execute_reply":"2024-06-09T03:40:51.817082Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.3147e-05,\n          -4.8934e-05, -5.3347e-05]]),\n tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0008,  0.0014,  0.0000]]),\n tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0017, 0.0025, 0.0000]]))"},"metadata":{}}]},{"cell_type":"code","source":"torchaudio.save('/kaggle/working/audio.wav', X[540], 16000)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:52:46.826831Z","iopub.execute_input":"2024-04-02T14:52:46.827791Z","iopub.status.idle":"2024-04-02T14:52:46.834792Z","shell.execute_reply.started":"2024-04-02T14:52:46.827746Z","shell.execute_reply":"2024-04-02T14:52:46.833811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = torchaudio.load('/kaggle/working/audio.wav')  # Загрузка аудиофайла\ntorchaudio.play(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:22:15.368540Z","iopub.execute_input":"2024-04-02T07:22:15.368969Z","iopub.status.idle":"2024-04-02T07:22:15.395250Z","shell.execute_reply.started":"2024-04-02T07:22:15.368930Z","shell.execute_reply":"2024-04-02T07:22:15.393666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n            \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n            \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n            \"я\": 31, \"х\": 32, \" \": 33}\n\ndef remove_characters(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.replace('4', 'четыре').replace('Р-220', 'р двести двадцать').replace('6', 'шесть').replace(\"-\", \" \")\n    sentence = ''.join(filter(lambda x: x in char_map, sentence))\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ny = list(map(remove_characters, y))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.908481Z","iopub.execute_input":"2024-06-09T04:16:28.908781Z","iopub.status.idle":"2024-06-09T04:16:28.944841Z","shell.execute_reply.started":"2024-06-09T04:16:28.908754Z","shell.execute_reply":"2024-06-09T04:16:28.943928Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train = X[:2800]\nX_test = X[2800:]\ny_train = y[:2800]\ny_test = y[2800:]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.946100Z","iopub.execute_input":"2024-06-09T04:16:28.946747Z","iopub.status.idle":"2024-06-09T04:16:28.952367Z","shell.execute_reply.started":"2024-06-09T04:16:28.946707Z","shell.execute_reply":"2024-06-09T04:16:28.951357Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass AudioDataset(Dataset):\n    def __init__(self, audio_list, text_list):\n        self.audio_list = audio_list\n        self.text_list = text_list\n        \n    def __len__(self):\n        return len(self.text_list)\n    \n    def __getitem__(self, index):\n        audio = self.audio_list[index]\n        text = self.text_list[index]\n        return audio, text","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.953598Z","iopub.execute_input":"2024-06-09T04:16:28.953882Z","iopub.status.idle":"2024-06-09T04:16:28.962854Z","shell.execute_reply.started":"2024-06-09T04:16:28.953854Z","shell.execute_reply":"2024-06-09T04:16:28.961821Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class SpeechRecognitionModel1(nn.Module):\n    def __init__(self, num_classes):\n        super(SpeechRecognitionModel1, self).__init__()\n        self.conv = nn.Sequential(\n            nn.BatchNorm2d(1),\n            nn.Conv2d(1, 32, kernel_size=(4,4), stride=(3,3), padding=(2,2)),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n            nn.Conv2d(128, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n        )\n        \n        self.fc_1 = nn.Sequential(\n            nn.Linear(896, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n        )\n        \n        self.BiGRU_1 = BidirectionalGRU(270, 270, 0, True)\n        self.BiGRU_2 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_3 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_4 = BidirectionalGRU(540, 270, 0.5, True)\n        \n        self.fc_2 = nn.Sequential(\n            nn.Linear(540, num_classes),\n        )\n        self.softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.view(x.size(0), x.size(1), -1)\n        x = self.fc_1(x)\n        x = self.BiGRU_1(x)\n        x = self.BiGRU_2(x)\n        x = self.BiGRU_3(x)\n        x = self.BiGRU_4(x)\n        x = self.fc_2(x)\n        x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.964163Z","iopub.execute_input":"2024-06-09T04:16:28.964504Z","iopub.status.idle":"2024-06-09T04:16:28.981755Z","shell.execute_reply.started":"2024-06-09T04:16:28.964451Z","shell.execute_reply":"2024-06-09T04:16:28.980660Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Зададим название выбронной модели из хаба\nMODEL_NAME = 'UrukHan/t5-russian-spell'\nMAX_INPUT = 256\n\n# Загрузка модели и токенизатора\ntokenizer = T5TokenizerFast.from_pretrained(MODEL_NAME)\ncorrector = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:52:10.590361Z","iopub.execute_input":"2024-05-25T13:52:10.590760Z","iopub.status.idle":"2024-05-25T13:52:36.615013Z","shell.execute_reply.started":"2024-05-25T13:52:10.590725Z","shell.execute_reply":"2024-05-25T13:52:36.613682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IterMeter(object):\n    def __init__(self):\n        self.val = 0\n\n    def step(self):\n        self.val += 1\n\n    def get(self):\n        return self.val\n\n\ndef train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n    model.train()\n    train_loss = 0\n    train_cer, train_wer = [], []\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data \n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms) \n        output = output.transpose(0, 1)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        train_loss += loss.item() / len(train_loader)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        iter_meter.step()\n        if batch_idx % 20 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n        \"\"\"decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n        for j in range(len(decoded_preds)):\n            train_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n            train_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n    avg_cer = sum(train_cer)/len(train_cer)\n    avg_wer = sum(train_wer)/len(train_wer)\n            \n    print('Train set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(train_loss, avg_cer, avg_wer))\"\"\"\n            \n    \n\ndef test(model, device, test_loader, criterion, epoch, iter_meter):\n    print('\\nevaluating...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data \n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n            \n            output = model(spectrograms)\n            output = output.transpose(0, 1)\n            \n            loss = criterion(output, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n            \n            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n            for j in range(len(decoded_preds)):\n                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n   \n    avg_cer = sum(test_cer)/len(test_cer)\n    avg_wer = sum(test_wer)/len(test_wer)\n\n    median_cer = np.median(np.array(test_cer))\n    median_wer = np.median(np.array(test_wer))\n           \n    print('Test set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(test_loss, avg_cer, avg_wer, median_cer, median_wer))\n    \n\ndef main(learning_rate=5e-4, batch_size=20, epochs=10):\n\n    hparams = {\n        \"learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"epochs\": epochs\n    }\n\n    use_cuda = torch.cuda.is_available()\n    torch.manual_seed(7)\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    train_dataset = AudioDataset(X_train, y_train)\n    test_dataset = AudioDataset(X_test, y_test)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n    train_loader = data.DataLoader(dataset=train_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=True,\n                                collate_fn=lambda x: data_processing(x, 'train'),\n                                **kwargs)\n    test_loader = data.DataLoader(dataset=test_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=False,\n                                collate_fn=lambda x: data_processing(x, 'valid'),\n                                **kwargs)\n\n    model = SpeechRecognitionModel1(35).to(device)\n\n    print(model)\n    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n\n    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n    criterion = nn.CTCLoss(blank=34).to(device)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\n    \n    iter_meter = IterMeter()\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n        test(model, device, test_loader, criterion, epoch, iter_meter)\n        \n    torch.save(model, '/kaggle/working/model_for_correction_test.pt')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:28.983248Z","iopub.execute_input":"2024-06-09T04:16:28.983572Z","iopub.status.idle":"2024-06-09T04:16:29.013302Z","shell.execute_reply.started":"2024-06-09T04:16:28.983530Z","shell.execute_reply":"2024-06-09T04:16:29.012274Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict(model, file_name, device):\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    sampl = librosa.load(file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    print(spectrogram_tensor.size())\n\n    with torch.no_grad():\n        spectrogram_tensor.to(device)\n        output = model(spectrogram_tensor)\n        print(output.size())\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n\n    return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:16:29.014643Z","iopub.execute_input":"2024-06-09T04:16:29.015046Z","iopub.status.idle":"2024-06-09T04:16:29.027739Z","shell.execute_reply.started":"2024-06-09T04:16:29.015007Z","shell.execute_reply":"2024-06-09T04:16:29.026684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict_with_tensor(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    #sampl = librosa.load(file_name, sr=16000)[0]\n    #sampl = sampl[np.newaxis, :]\n    #sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    #print(decodes[0])        \n    input_sequences = decodes[0]\n                \n    task_prefix = \"Spell correct: \"\n\n    if type(input_sequences) != list: input_sequences = [input_sequences]\n    encoded = tokenizer(\n      [task_prefix + sequence for sequence in input_sequences],\n      padding=\"longest\",\n      max_length=MAX_INPUT,\n      truncation=True,\n      return_tensors=\"pt\",\n    )\n\n    predicts = corrector.generate(**encoded.to(needed_device))   # # Прогнозирование\n\n    input_sequences = tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]\n    input_sequences = remove_characters(input_sequences)\n\n    return input_sequences\n\n    #return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:58:04.311976Z","iopub.execute_input":"2024-05-28T11:58:04.312769Z","iopub.status.idle":"2024-05-28T11:58:04.328174Z","shell.execute_reply.started":"2024-05-28T11:58:04.312711Z","shell.execute_reply":"2024-05-28T11:58:04.326851Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import hunspell\nimport os\n\n#пробуем hunspell для исправления ошибок\ndef load_hunspell_russian_dict():\n    dict_path = \"/kaggle/input/dop-test-files\"  \n    \n    ru_dic = os.path.join(dict_path, \"ru_RU_big.dic\")\n    ru_aff = os.path.join(dict_path, \"ru_RU_big.aff\")\n    \n    # Create Hunspell instance for Russian\n    hunspell_instance = hunspell.HunSpell(ru_dic, ru_aff)\n    return hunspell_instance\n\ndef correct_mistakes(text, hunspell_instance):\n    corrected_text = []\n    words = text.split()\n    \n    for word in words:\n        if hunspell_instance.spell(word):\n            corrected_text.append(word)\n        else:\n            suggestions = hunspell_instance.suggest(word)\n            if suggestions:\n                corrected_text.append(suggestions[0])  # Choose the first suggestion\n            else:\n                corrected_text.append(word)  # No suggestion, keep the original word\n    \n    return \" \".join(corrected_text)\n\n# Example usage\nhunspell_instance = load_hunspell_russian_dict()\n#text = \"Привет, как дила?\"\n#corrected_text = correct_mistakes(text, hunspell_instance)\n#print(corrected_text)\n\ndef predict_with_tensor_v2(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    #print(decodes[0])        \n    corrected_output = correct_mistakes(decodes[0], hunspell_instance)\n\n    #return decodes[0]\n    return corrected_output","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:58:04.330590Z","iopub.execute_input":"2024-05-28T11:58:04.331096Z","iopub.status.idle":"2024-05-28T11:58:04.516304Z","shell.execute_reply.started":"2024-05-28T11:58:04.331042Z","shell.execute_reply":"2024-05-28T11:58:04.514989Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!pip install safetensors","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:58:04.517908Z","iopub.execute_input":"2024-05-28T11:58:04.518412Z","iopub.status.idle":"2024-05-28T11:58:20.419403Z","shell.execute_reply.started":"2024-05-28T11:58:04.518360Z","shell.execute_reply":"2024-05-28T11:58:20.417894Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting safetensors\n  Downloading safetensors-0.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: safetensors\nSuccessfully installed safetensors-0.4.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:58:20.420913Z","iopub.execute_input":"2024-05-28T11:58:20.421317Z","iopub.status.idle":"2024-05-28T11:58:48.000457Z","shell.execute_reply.started":"2024-05-28T11:58:20.421279Z","shell.execute_reply":"2024-05-28T11:58:47.999163Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nCollecting transformers\n  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nCollecting huggingface-hub<1.0,>=0.14.1\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.13.3\n    Uninstalling huggingface-hub-0.13.3:\n      Successfully uninstalled huggingface-hub-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.27.4\n    Uninstalling transformers-4.27.4:\n      Successfully uninstalled transformers-4.27.4\nSuccessfully installed huggingface-hub-0.16.4 transformers-4.30.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-28T12:02:14.404069Z","iopub.execute_input":"2024-05-28T12:02:14.404576Z","iopub.status.idle":"2024-05-28T12:02:28.936170Z","shell.execute_reply.started":"2024-05-28T12:02:14.404535Z","shell.execute_reply":"2024-05-28T12:02:28.934415Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.30.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntoken = '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'\n\n# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# # Load the model and tokenizer\n# model = AutoModelForSequenceClassification.from_pretrained(\"<your-username>/<your-model-name>\")\n# tokenizer = AutoTokenizer.from_pretrained(\"<your-username>/<your-model-name>\")\n\n# Use the model for inference\n#os.environ[\"HUGGINGFACE_TOKEN\"] = \"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\"\n\nmodel = T5ForConditionalGeneration.from_pretrained('NickChudo/t5_small_fine_tuned_10_epochs_model', \n                                                   use_auth_token=token, \n                                                   from_tf=False)\ntokenizer = T5Tokenizer.from_pretrained('NickChudo/t5_small_fine_tuned_10_epochs_tokenizer', \n                                                   use_auth_token=token,\n                                                   from_tf=False)\n\ndef correct_mistakes(text, model, tokenizer):\n    input_text = \"correct: \" + text\n    inputs = tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n    \n    outputs = model.generate(inputs, max_length=512, num_beams=5, early_stopping=True)\n    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return corrected_text\n\n\n#corrected_text = correct_mistakes(text, model, tokenizer)\n\ndef predict_with_tensor_v3(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    #print(decodes[0])        \n    corrected_output = correct_mistakes(decodes[0], model, tokenizer)\n\n    #return decodes[0]\n    return corrected_output","metadata":{"execution":{"iopub.status.busy":"2024-05-28T12:02:33.052229Z","iopub.execute_input":"2024-05-28T12:02:33.052757Z","iopub.status.idle":"2024-05-28T12:02:33.249652Z","shell.execute_reply.started":"2024-05-28T12:02:33.052707Z","shell.execute_reply":"2024-05-28T12:02:33.247587Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL_LAYERNORM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_pruneable_heads_and_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_linear_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 49\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mDUMMY_INPUTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'is_optimum_available' from 'transformers.utils' (/opt/conda/lib/python3.7/site-packages/transformers/utils/__init__.py)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/878385006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'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'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from transformers import AutoModelForSequenceClassification, AutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\ncannot import name 'is_optimum_available' from 'transformers.utils' (/opt/conda/lib/python3.7/site-packages/transformers/utils/__init__.py)"],"ename":"RuntimeError","evalue":"Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\ncannot import name 'is_optimum_available' from 'transformers.utils' (/opt/conda/lib/python3.7/site-packages/transformers/utils/__init__.py)","output_type":"error"}]},{"cell_type":"code","source":"%%time\nlearning_rate = 0.003\nbatch_size = 20\nepochs = 100\n\nmain(learning_rate, batch_size, epochs)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-09T04:16:29.029108Z","iopub.execute_input":"2024-06-09T04:16:29.029459Z","iopub.status.idle":"2024-06-09T05:18:53.283782Z","shell.execute_reply.started":"2024-06-09T04:16:29.029429Z","shell.execute_reply":"2024-06-09T05:18:53.282535Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"SpeechRecognitionModel1(\n  (conv): Sequential(\n    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Conv2d(1, 32, kernel_size=(4, 4), stride=(3, 3), padding=(2, 2))\n    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): GELU(approximate='none')\n    (4): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): GELU(approximate='none')\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): GELU(approximate='none')\n  )\n  (fc_1): Sequential(\n    (0): Linear(in_features=896, out_features=270, bias=True)\n    (1): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Linear(in_features=270, out_features=270, bias=True)\n    (4): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (5): GELU(approximate='none')\n    (6): Linear(in_features=270, out_features=270, bias=True)\n    (7): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (8): GELU(approximate='none')\n  )\n  (BiGRU_1): BidirectionalGRU(\n    (BiGRU): GRU(270, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((270,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_2): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_3): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (BiGRU_4): BidirectionalGRU(\n    (BiGRU): GRU(540, 270, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((540,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (fc_2): Sequential(\n    (0): Linear(in_features=540, out_features=35, bias=True)\n  )\n  (softmax): LogSoftmax(dim=2)\n)\nNum Model Parameters 5422923\nTrain Epoch: 1 [0/2800 (0%)]\tLoss: 23.564430\nTrain Epoch: 1 [400/2800 (14%)]\tLoss: 3.822765\nTrain Epoch: 1 [800/2800 (29%)]\tLoss: 3.567959\nTrain Epoch: 1 [1200/2800 (43%)]\tLoss: 3.356940\nTrain Epoch: 1 [1600/2800 (57%)]\tLoss: 3.279544\nTrain Epoch: 1 [2000/2800 (71%)]\tLoss: 3.406415\nTrain Epoch: 1 [2400/2800 (86%)]\tLoss: 3.379938\n\nevaluating...\nTest set:\tAverage loss: 3.3150, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 2 [0/2800 (0%)]\tLoss: 3.300993\nTrain Epoch: 2 [400/2800 (14%)]\tLoss: 3.329247\nTrain Epoch: 2 [800/2800 (29%)]\tLoss: 3.355245\nTrain Epoch: 2 [1200/2800 (43%)]\tLoss: 3.395782\nTrain Epoch: 2 [1600/2800 (57%)]\tLoss: 3.263000\nTrain Epoch: 2 [2000/2800 (71%)]\tLoss: 3.302083\nTrain Epoch: 2 [2400/2800 (86%)]\tLoss: 3.305477\n\nevaluating...\nTest set:\tAverage loss: 3.2839, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 3 [0/2800 (0%)]\tLoss: 3.230539\nTrain Epoch: 3 [400/2800 (14%)]\tLoss: 3.265902\nTrain Epoch: 3 [800/2800 (29%)]\tLoss: 3.196142\nTrain Epoch: 3 [1200/2800 (43%)]\tLoss: 3.280507\nTrain Epoch: 3 [1600/2800 (57%)]\tLoss: 3.264774\nTrain Epoch: 3 [2000/2800 (71%)]\tLoss: 3.156049\nTrain Epoch: 3 [2400/2800 (86%)]\tLoss: 3.104895\n\nevaluating...\nTest set:\tAverage loss: 3.0146, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 4 [0/2800 (0%)]\tLoss: 3.076624\nTrain Epoch: 4 [400/2800 (14%)]\tLoss: 2.733358\nTrain Epoch: 4 [800/2800 (29%)]\tLoss: 2.594416\nTrain Epoch: 4 [1200/2800 (43%)]\tLoss: 2.648022\nTrain Epoch: 4 [1600/2800 (57%)]\tLoss: 2.616189\nTrain Epoch: 4 [2000/2800 (71%)]\tLoss: 2.694511\nTrain Epoch: 4 [2400/2800 (86%)]\tLoss: 2.154540\n\nevaluating...\nTest set:\tAverage loss: 2.3348, Average CER: 0.822640 Average WER: 1.0156\n\nTrain Epoch: 5 [0/2800 (0%)]\tLoss: 2.350218\nTrain Epoch: 5 [400/2800 (14%)]\tLoss: 2.038079\nTrain Epoch: 5 [800/2800 (29%)]\tLoss: 1.893726\nTrain Epoch: 5 [1200/2800 (43%)]\tLoss: 2.052308\nTrain Epoch: 5 [1600/2800 (57%)]\tLoss: 2.566449\nTrain Epoch: 5 [2000/2800 (71%)]\tLoss: 1.736467\nTrain Epoch: 5 [2400/2800 (86%)]\tLoss: 1.885568\n\nevaluating...\nTest set:\tAverage loss: 1.7938, Average CER: 0.542048 Average WER: 0.9812\n\nTrain Epoch: 6 [0/2800 (0%)]\tLoss: 1.779023\nTrain Epoch: 6 [400/2800 (14%)]\tLoss: 1.845018\nTrain Epoch: 6 [800/2800 (29%)]\tLoss: 1.864228\nTrain Epoch: 6 [1200/2800 (43%)]\tLoss: 1.747374\nTrain Epoch: 6 [1600/2800 (57%)]\tLoss: 1.544150\nTrain Epoch: 6 [2000/2800 (71%)]\tLoss: 1.722416\nTrain Epoch: 6 [2400/2800 (86%)]\tLoss: 2.037212\n\nevaluating...\nTest set:\tAverage loss: 1.6501, Average CER: 0.495649 Average WER: 0.9543\n\nTrain Epoch: 7 [0/2800 (0%)]\tLoss: 1.897994\nTrain Epoch: 7 [400/2800 (14%)]\tLoss: 1.355989\nTrain Epoch: 7 [800/2800 (29%)]\tLoss: 1.572313\nTrain Epoch: 7 [1200/2800 (43%)]\tLoss: 0.910617\nTrain Epoch: 7 [1600/2800 (57%)]\tLoss: 1.164997\nTrain Epoch: 7 [2000/2800 (71%)]\tLoss: 1.742467\nTrain Epoch: 7 [2400/2800 (86%)]\tLoss: 1.268629\n\nevaluating...\nTest set:\tAverage loss: 1.5136, Average CER: 0.463757 Average WER: 0.9378\n\nTrain Epoch: 8 [0/2800 (0%)]\tLoss: 1.535657\nTrain Epoch: 8 [400/2800 (14%)]\tLoss: 1.847064\nTrain Epoch: 8 [800/2800 (29%)]\tLoss: 1.377852\nTrain Epoch: 8 [1200/2800 (43%)]\tLoss: 1.315918\nTrain Epoch: 8 [1600/2800 (57%)]\tLoss: 1.037635\nTrain Epoch: 8 [2000/2800 (71%)]\tLoss: 1.053199\nTrain Epoch: 8 [2400/2800 (86%)]\tLoss: 1.412019\n\nevaluating...\nTest set:\tAverage loss: 1.4647, Average CER: 0.445572 Average WER: 0.9173\n\nTrain Epoch: 9 [0/2800 (0%)]\tLoss: 1.540025\nTrain Epoch: 9 [400/2800 (14%)]\tLoss: 1.690897\nTrain Epoch: 9 [800/2800 (29%)]\tLoss: 2.045587\nTrain Epoch: 9 [1200/2800 (43%)]\tLoss: 1.154280\nTrain Epoch: 9 [1600/2800 (57%)]\tLoss: 0.927948\nTrain Epoch: 9 [2000/2800 (71%)]\tLoss: 1.407477\nTrain Epoch: 9 [2400/2800 (86%)]\tLoss: 1.031487\n\nevaluating...\nTest set:\tAverage loss: 1.4231, Average CER: 0.425196 Average WER: 0.9076\n\nTrain Epoch: 10 [0/2800 (0%)]\tLoss: 1.498294\nTrain Epoch: 10 [400/2800 (14%)]\tLoss: 1.140609\nTrain Epoch: 10 [800/2800 (29%)]\tLoss: 1.155078\nTrain Epoch: 10 [1200/2800 (43%)]\tLoss: 1.326320\nTrain Epoch: 10 [1600/2800 (57%)]\tLoss: 1.115821\nTrain Epoch: 10 [2000/2800 (71%)]\tLoss: 1.069027\nTrain Epoch: 10 [2400/2800 (86%)]\tLoss: 1.751109\n\nevaluating...\nTest set:\tAverage loss: 1.3995, Average CER: 0.418815 Average WER: 0.8864\n\nTrain Epoch: 11 [0/2800 (0%)]\tLoss: 1.057006\nTrain Epoch: 11 [400/2800 (14%)]\tLoss: 0.994194\nTrain Epoch: 11 [800/2800 (29%)]\tLoss: 1.096595\nTrain Epoch: 11 [1200/2800 (43%)]\tLoss: 1.208348\nTrain Epoch: 11 [1600/2800 (57%)]\tLoss: 1.127971\nTrain Epoch: 11 [2000/2800 (71%)]\tLoss: 1.373261\nTrain Epoch: 11 [2400/2800 (86%)]\tLoss: 1.354591\n\nevaluating...\nTest set:\tAverage loss: 1.3677, Average CER: 0.412496 Average WER: 0.8897\n\nTrain Epoch: 12 [0/2800 (0%)]\tLoss: 0.796540\nTrain Epoch: 12 [400/2800 (14%)]\tLoss: 0.818653\nTrain Epoch: 12 [800/2800 (29%)]\tLoss: 0.876787\nTrain Epoch: 12 [1200/2800 (43%)]\tLoss: 1.117750\nTrain Epoch: 12 [1600/2800 (57%)]\tLoss: 0.756495\nTrain Epoch: 12 [2000/2800 (71%)]\tLoss: 1.117858\nTrain Epoch: 12 [2400/2800 (86%)]\tLoss: 1.486580\n\nevaluating...\nTest set:\tAverage loss: 1.4158, Average CER: 0.411872 Average WER: 0.8754\n\nTrain Epoch: 13 [0/2800 (0%)]\tLoss: 1.180046\nTrain Epoch: 13 [400/2800 (14%)]\tLoss: 1.046313\nTrain Epoch: 13 [800/2800 (29%)]\tLoss: 0.939651\nTrain Epoch: 13 [1200/2800 (43%)]\tLoss: 0.888192\nTrain Epoch: 13 [1600/2800 (57%)]\tLoss: 1.063718\nTrain Epoch: 13 [2000/2800 (71%)]\tLoss: 1.600858\nTrain Epoch: 13 [2400/2800 (86%)]\tLoss: 1.224155\n\nevaluating...\nTest set:\tAverage loss: 1.4024, Average CER: 0.404974 Average WER: 0.8744\n\nTrain Epoch: 14 [0/2800 (0%)]\tLoss: 1.254657\nTrain Epoch: 14 [400/2800 (14%)]\tLoss: 0.906410\nTrain Epoch: 14 [800/2800 (29%)]\tLoss: 1.333102\nTrain Epoch: 14 [1200/2800 (43%)]\tLoss: 1.025560\nTrain Epoch: 14 [1600/2800 (57%)]\tLoss: 1.240292\nTrain Epoch: 14 [2000/2800 (71%)]\tLoss: 1.005839\nTrain Epoch: 14 [2400/2800 (86%)]\tLoss: 0.858145\n\nevaluating...\nTest set:\tAverage loss: 1.3982, Average CER: 0.401755 Average WER: 0.8598\n\nTrain Epoch: 15 [0/2800 (0%)]\tLoss: 0.769810\nTrain Epoch: 15 [400/2800 (14%)]\tLoss: 0.903734\nTrain Epoch: 15 [800/2800 (29%)]\tLoss: 1.594243\nTrain Epoch: 15 [1200/2800 (43%)]\tLoss: 1.454794\nTrain Epoch: 15 [1600/2800 (57%)]\tLoss: 0.902577\nTrain Epoch: 15 [2000/2800 (71%)]\tLoss: 1.012249\nTrain Epoch: 15 [2400/2800 (86%)]\tLoss: 0.779195\n\nevaluating...\nTest set:\tAverage loss: 1.4295, Average CER: 0.405647 Average WER: 0.9143\n\nTrain Epoch: 16 [0/2800 (0%)]\tLoss: 1.340328\nTrain Epoch: 16 [400/2800 (14%)]\tLoss: 0.546398\nTrain Epoch: 16 [800/2800 (29%)]\tLoss: 1.116759\nTrain Epoch: 16 [1200/2800 (43%)]\tLoss: 0.889841\nTrain Epoch: 16 [1600/2800 (57%)]\tLoss: 1.016395\nTrain Epoch: 16 [2000/2800 (71%)]\tLoss: 1.294860\nTrain Epoch: 16 [2400/2800 (86%)]\tLoss: 0.945925\n\nevaluating...\nTest set:\tAverage loss: 1.4056, Average CER: 0.408246 Average WER: 0.8791\n\nTrain Epoch: 17 [0/2800 (0%)]\tLoss: 1.574768\nTrain Epoch: 17 [400/2800 (14%)]\tLoss: 0.883961\nTrain Epoch: 17 [800/2800 (29%)]\tLoss: 1.263169\nTrain Epoch: 17 [1200/2800 (43%)]\tLoss: 1.028804\nTrain Epoch: 17 [1600/2800 (57%)]\tLoss: 1.164456\nTrain Epoch: 17 [2000/2800 (71%)]\tLoss: 0.503104\nTrain Epoch: 17 [2400/2800 (86%)]\tLoss: 0.731168\n\nevaluating...\nTest set:\tAverage loss: 1.4472, Average CER: 0.415413 Average WER: 0.8805\n\nTrain Epoch: 18 [0/2800 (0%)]\tLoss: 0.905899\nTrain Epoch: 18 [400/2800 (14%)]\tLoss: 1.584237\nTrain Epoch: 18 [800/2800 (29%)]\tLoss: 1.359209\nTrain Epoch: 18 [1200/2800 (43%)]\tLoss: 1.452825\nTrain Epoch: 18 [1600/2800 (57%)]\tLoss: 1.067121\nTrain Epoch: 18 [2000/2800 (71%)]\tLoss: 0.587986\nTrain Epoch: 18 [2400/2800 (86%)]\tLoss: 0.668977\n\nevaluating...\nTest set:\tAverage loss: 1.3903, Average CER: 0.395956 Average WER: 0.8252\n\nTrain Epoch: 19 [0/2800 (0%)]\tLoss: 0.659415\nTrain Epoch: 19 [400/2800 (14%)]\tLoss: 0.799986\nTrain Epoch: 19 [800/2800 (29%)]\tLoss: 1.190823\nTrain Epoch: 19 [1200/2800 (43%)]\tLoss: 1.202985\nTrain Epoch: 19 [1600/2800 (57%)]\tLoss: 0.939680\nTrain Epoch: 19 [2000/2800 (71%)]\tLoss: 1.278693\nTrain Epoch: 19 [2400/2800 (86%)]\tLoss: 0.952227\n\nevaluating...\nTest set:\tAverage loss: 1.3763, Average CER: 0.386386 Average WER: 0.8462\n\nTrain Epoch: 20 [0/2800 (0%)]\tLoss: 1.136091\nTrain Epoch: 20 [400/2800 (14%)]\tLoss: 1.167890\nTrain Epoch: 20 [800/2800 (29%)]\tLoss: 1.276522\nTrain Epoch: 20 [1200/2800 (43%)]\tLoss: 1.637342\nTrain Epoch: 20 [1600/2800 (57%)]\tLoss: 0.948507\nTrain Epoch: 20 [2000/2800 (71%)]\tLoss: 0.732156\nTrain Epoch: 20 [2400/2800 (86%)]\tLoss: 0.900398\n\nevaluating...\nTest set:\tAverage loss: 1.4319, Average CER: 0.405184 Average WER: 0.8657\n\nTrain Epoch: 21 [0/2800 (0%)]\tLoss: 0.738122\nTrain Epoch: 21 [400/2800 (14%)]\tLoss: 0.603839\nTrain Epoch: 21 [800/2800 (29%)]\tLoss: 0.964994\nTrain Epoch: 21 [1200/2800 (43%)]\tLoss: 1.160693\nTrain Epoch: 21 [1600/2800 (57%)]\tLoss: 0.639455\nTrain Epoch: 21 [2000/2800 (71%)]\tLoss: 0.708722\nTrain Epoch: 21 [2400/2800 (86%)]\tLoss: 1.188773\n\nevaluating...\nTest set:\tAverage loss: 1.3875, Average CER: 0.385085 Average WER: 0.8517\n\nTrain Epoch: 22 [0/2800 (0%)]\tLoss: 0.788054\nTrain Epoch: 22 [400/2800 (14%)]\tLoss: 0.849019\nTrain Epoch: 22 [800/2800 (29%)]\tLoss: 1.136021\nTrain Epoch: 22 [1200/2800 (43%)]\tLoss: 0.807531\nTrain Epoch: 22 [1600/2800 (57%)]\tLoss: 0.594219\nTrain Epoch: 22 [2000/2800 (71%)]\tLoss: 1.635202\nTrain Epoch: 22 [2400/2800 (86%)]\tLoss: 1.218627\n\nevaluating...\nTest set:\tAverage loss: 1.3827, Average CER: 0.389611 Average WER: 0.9025\n\nTrain Epoch: 23 [0/2800 (0%)]\tLoss: 1.248749\nTrain Epoch: 23 [400/2800 (14%)]\tLoss: 0.706056\nTrain Epoch: 23 [800/2800 (29%)]\tLoss: 1.153147\nTrain Epoch: 23 [1200/2800 (43%)]\tLoss: 1.334755\nTrain Epoch: 23 [1600/2800 (57%)]\tLoss: 1.253670\nTrain Epoch: 23 [2000/2800 (71%)]\tLoss: 0.604233\nTrain Epoch: 23 [2400/2800 (86%)]\tLoss: 1.347949\n\nevaluating...\nTest set:\tAverage loss: 1.3965, Average CER: 0.389851 Average WER: 0.8536\n\nTrain Epoch: 24 [0/2800 (0%)]\tLoss: 0.531753\nTrain Epoch: 24 [400/2800 (14%)]\tLoss: 1.139032\nTrain Epoch: 24 [800/2800 (29%)]\tLoss: 1.019121\nTrain Epoch: 24 [1200/2800 (43%)]\tLoss: 0.746006\nTrain Epoch: 24 [1600/2800 (57%)]\tLoss: 0.992199\nTrain Epoch: 24 [2000/2800 (71%)]\tLoss: 0.927511\nTrain Epoch: 24 [2400/2800 (86%)]\tLoss: 0.630339\n\nevaluating...\nTest set:\tAverage loss: 1.3746, Average CER: 0.375343 Average WER: 0.8299\n\nTrain Epoch: 25 [0/2800 (0%)]\tLoss: 0.999894\nTrain Epoch: 25 [400/2800 (14%)]\tLoss: 1.334994\nTrain Epoch: 25 [800/2800 (29%)]\tLoss: 0.895977\nTrain Epoch: 25 [1200/2800 (43%)]\tLoss: 1.167597\nTrain Epoch: 25 [1600/2800 (57%)]\tLoss: 0.764733\nTrain Epoch: 25 [2000/2800 (71%)]\tLoss: 0.470884\nTrain Epoch: 25 [2400/2800 (86%)]\tLoss: 0.844710\n\nevaluating...\nTest set:\tAverage loss: 1.3666, Average CER: 0.377621 Average WER: 0.8344\n\nTrain Epoch: 26 [0/2800 (0%)]\tLoss: 0.385934\nTrain Epoch: 26 [400/2800 (14%)]\tLoss: 1.194464\nTrain Epoch: 26 [800/2800 (29%)]\tLoss: 0.572830\nTrain Epoch: 26 [1200/2800 (43%)]\tLoss: 1.047362\nTrain Epoch: 26 [1600/2800 (57%)]\tLoss: 0.737747\nTrain Epoch: 26 [2000/2800 (71%)]\tLoss: 0.519318\nTrain Epoch: 26 [2400/2800 (86%)]\tLoss: 1.163266\n\nevaluating...\nTest set:\tAverage loss: 1.4102, Average CER: 0.380304 Average WER: 0.8818\n\nTrain Epoch: 27 [0/2800 (0%)]\tLoss: 0.908381\nTrain Epoch: 27 [400/2800 (14%)]\tLoss: 1.055621\nTrain Epoch: 27 [800/2800 (29%)]\tLoss: 0.759199\nTrain Epoch: 27 [1200/2800 (43%)]\tLoss: 0.646003\nTrain Epoch: 27 [1600/2800 (57%)]\tLoss: 0.871440\nTrain Epoch: 27 [2000/2800 (71%)]\tLoss: 0.887956\nTrain Epoch: 27 [2400/2800 (86%)]\tLoss: 1.052874\n\nevaluating...\nTest set:\tAverage loss: 1.3932, Average CER: 0.373657 Average WER: 0.8937\n\nTrain Epoch: 28 [0/2800 (0%)]\tLoss: 1.138522\nTrain Epoch: 28 [400/2800 (14%)]\tLoss: 1.017838\nTrain Epoch: 28 [800/2800 (29%)]\tLoss: 1.055776\nTrain Epoch: 28 [1200/2800 (43%)]\tLoss: 1.296922\nTrain Epoch: 28 [1600/2800 (57%)]\tLoss: 1.074090\nTrain Epoch: 28 [2000/2800 (71%)]\tLoss: 1.038942\nTrain Epoch: 28 [2400/2800 (86%)]\tLoss: 1.509931\n\nevaluating...\nTest set:\tAverage loss: 1.4343, Average CER: 0.392820 Average WER: 0.8574\n\nTrain Epoch: 29 [0/2800 (0%)]\tLoss: 1.134616\nTrain Epoch: 29 [400/2800 (14%)]\tLoss: 0.939107\nTrain Epoch: 29 [800/2800 (29%)]\tLoss: 0.884265\nTrain Epoch: 29 [1200/2800 (43%)]\tLoss: 0.796903\nTrain Epoch: 29 [1600/2800 (57%)]\tLoss: 0.934796\nTrain Epoch: 29 [2000/2800 (71%)]\tLoss: 0.916962\nTrain Epoch: 29 [2400/2800 (86%)]\tLoss: 0.984899\n\nevaluating...\nTest set:\tAverage loss: 1.3904, Average CER: 0.386635 Average WER: 0.8479\n\nTrain Epoch: 30 [0/2800 (0%)]\tLoss: 1.212712\nTrain Epoch: 30 [400/2800 (14%)]\tLoss: 1.140494\nTrain Epoch: 30 [800/2800 (29%)]\tLoss: 0.863007\nTrain Epoch: 30 [1200/2800 (43%)]\tLoss: 0.771794\nTrain Epoch: 30 [1600/2800 (57%)]\tLoss: 1.106335\nTrain Epoch: 30 [2000/2800 (71%)]\tLoss: 1.021749\nTrain Epoch: 30 [2400/2800 (86%)]\tLoss: 1.093935\n\nevaluating...\nTest set:\tAverage loss: 1.4177, Average CER: 0.390003 Average WER: 0.8570\n\nTrain Epoch: 31 [0/2800 (0%)]\tLoss: 0.801727\nTrain Epoch: 31 [400/2800 (14%)]\tLoss: 1.149984\nTrain Epoch: 31 [800/2800 (29%)]\tLoss: 1.169374\nTrain Epoch: 31 [1200/2800 (43%)]\tLoss: 0.480936\nTrain Epoch: 31 [1600/2800 (57%)]\tLoss: 1.089859\nTrain Epoch: 31 [2000/2800 (71%)]\tLoss: 1.095493\nTrain Epoch: 31 [2400/2800 (86%)]\tLoss: 1.179794\n\nevaluating...\nTest set:\tAverage loss: 1.3880, Average CER: 0.384734 Average WER: 0.8470\n\nTrain Epoch: 32 [0/2800 (0%)]\tLoss: 0.986363\nTrain Epoch: 32 [400/2800 (14%)]\tLoss: 0.434747\nTrain Epoch: 32 [800/2800 (29%)]\tLoss: 1.277891\nTrain Epoch: 32 [1200/2800 (43%)]\tLoss: 0.888409\nTrain Epoch: 32 [1600/2800 (57%)]\tLoss: 0.955121\nTrain Epoch: 32 [2000/2800 (71%)]\tLoss: 1.166973\nTrain Epoch: 32 [2400/2800 (86%)]\tLoss: 0.633740\n\nevaluating...\nTest set:\tAverage loss: 1.4300, Average CER: 0.397985 Average WER: 0.8432\n\nTrain Epoch: 33 [0/2800 (0%)]\tLoss: 1.288005\nTrain Epoch: 33 [400/2800 (14%)]\tLoss: 0.753820\nTrain Epoch: 33 [800/2800 (29%)]\tLoss: 1.323313\nTrain Epoch: 33 [1200/2800 (43%)]\tLoss: 0.915584\nTrain Epoch: 33 [1600/2800 (57%)]\tLoss: 0.463383\nTrain Epoch: 33 [2000/2800 (71%)]\tLoss: 0.933243\nTrain Epoch: 33 [2400/2800 (86%)]\tLoss: 0.767594\n\nevaluating...\nTest set:\tAverage loss: 1.4125, Average CER: 0.385326 Average WER: 0.8473\n\nTrain Epoch: 34 [0/2800 (0%)]\tLoss: 1.181706\nTrain Epoch: 34 [400/2800 (14%)]\tLoss: 1.550250\nTrain Epoch: 34 [800/2800 (29%)]\tLoss: 0.765762\nTrain Epoch: 34 [1200/2800 (43%)]\tLoss: 1.097585\nTrain Epoch: 34 [1600/2800 (57%)]\tLoss: 1.338243\nTrain Epoch: 34 [2000/2800 (71%)]\tLoss: 1.083871\nTrain Epoch: 34 [2400/2800 (86%)]\tLoss: 0.651722\n\nevaluating...\nTest set:\tAverage loss: 1.4138, Average CER: 0.375221 Average WER: 0.8283\n\nTrain Epoch: 35 [0/2800 (0%)]\tLoss: 1.002941\nTrain Epoch: 35 [400/2800 (14%)]\tLoss: 0.935555\nTrain Epoch: 35 [800/2800 (29%)]\tLoss: 0.693861\nTrain Epoch: 35 [1200/2800 (43%)]\tLoss: 1.012630\nTrain Epoch: 35 [1600/2800 (57%)]\tLoss: 1.092864\nTrain Epoch: 35 [2000/2800 (71%)]\tLoss: 0.903630\nTrain Epoch: 35 [2400/2800 (86%)]\tLoss: 0.884266\n\nevaluating...\nTest set:\tAverage loss: 1.4252, Average CER: 0.391068 Average WER: 0.8268\n\nTrain Epoch: 36 [0/2800 (0%)]\tLoss: 0.905221\nTrain Epoch: 36 [400/2800 (14%)]\tLoss: 0.263689\nTrain Epoch: 36 [800/2800 (29%)]\tLoss: 0.764805\nTrain Epoch: 36 [1200/2800 (43%)]\tLoss: 0.910897\nTrain Epoch: 36 [1600/2800 (57%)]\tLoss: 1.153458\nTrain Epoch: 36 [2000/2800 (71%)]\tLoss: 1.222898\nTrain Epoch: 36 [2400/2800 (86%)]\tLoss: 1.009383\n\nevaluating...\nTest set:\tAverage loss: 1.3757, Average CER: 0.362841 Average WER: 0.8496\n\nTrain Epoch: 37 [0/2800 (0%)]\tLoss: 0.829160\nTrain Epoch: 37 [400/2800 (14%)]\tLoss: 0.705710\nTrain Epoch: 37 [800/2800 (29%)]\tLoss: 1.069809\nTrain Epoch: 37 [1200/2800 (43%)]\tLoss: 0.722429\nTrain Epoch: 37 [1600/2800 (57%)]\tLoss: 1.272234\nTrain Epoch: 37 [2000/2800 (71%)]\tLoss: 1.369504\nTrain Epoch: 37 [2400/2800 (86%)]\tLoss: 0.713153\n\nevaluating...\nTest set:\tAverage loss: 1.3886, Average CER: 0.375284 Average WER: 0.8395\n\nTrain Epoch: 38 [0/2800 (0%)]\tLoss: 1.499582\nTrain Epoch: 38 [400/2800 (14%)]\tLoss: 0.910610\nTrain Epoch: 38 [800/2800 (29%)]\tLoss: 1.066571\nTrain Epoch: 38 [1200/2800 (43%)]\tLoss: 0.508642\nTrain Epoch: 38 [1600/2800 (57%)]\tLoss: 0.582910\nTrain Epoch: 38 [2000/2800 (71%)]\tLoss: 0.968397\nTrain Epoch: 38 [2400/2800 (86%)]\tLoss: 1.095649\n\nevaluating...\nTest set:\tAverage loss: 1.3459, Average CER: 0.369090 Average WER: 0.8210\n\nTrain Epoch: 39 [0/2800 (0%)]\tLoss: 1.080203\nTrain Epoch: 39 [400/2800 (14%)]\tLoss: 1.120400\nTrain Epoch: 39 [800/2800 (29%)]\tLoss: 0.744417\nTrain Epoch: 39 [1200/2800 (43%)]\tLoss: 0.708704\nTrain Epoch: 39 [1600/2800 (57%)]\tLoss: 1.216597\nTrain Epoch: 39 [2000/2800 (71%)]\tLoss: 1.116221\nTrain Epoch: 39 [2400/2800 (86%)]\tLoss: 1.127606\n\nevaluating...\nTest set:\tAverage loss: 1.4318, Average CER: 0.381356 Average WER: 0.8292\n\nTrain Epoch: 40 [0/2800 (0%)]\tLoss: 0.685621\nTrain Epoch: 40 [400/2800 (14%)]\tLoss: 1.337576\nTrain Epoch: 40 [800/2800 (29%)]\tLoss: 0.873075\nTrain Epoch: 40 [1200/2800 (43%)]\tLoss: 0.967463\nTrain Epoch: 40 [1600/2800 (57%)]\tLoss: 0.961317\nTrain Epoch: 40 [2000/2800 (71%)]\tLoss: 0.983437\nTrain Epoch: 40 [2400/2800 (86%)]\tLoss: 1.025338\n\nevaluating...\nTest set:\tAverage loss: 1.3628, Average CER: 0.367863 Average WER: 0.8336\n\nTrain Epoch: 41 [0/2800 (0%)]\tLoss: 0.370806\nTrain Epoch: 41 [400/2800 (14%)]\tLoss: 0.495140\nTrain Epoch: 41 [800/2800 (29%)]\tLoss: 0.867604\nTrain Epoch: 41 [1200/2800 (43%)]\tLoss: 1.121551\nTrain Epoch: 41 [1600/2800 (57%)]\tLoss: 0.556923\nTrain Epoch: 41 [2000/2800 (71%)]\tLoss: 0.785458\nTrain Epoch: 41 [2400/2800 (86%)]\tLoss: 1.300118\n\nevaluating...\nTest set:\tAverage loss: 1.4159, Average CER: 0.372784 Average WER: 0.8414\n\nTrain Epoch: 42 [0/2800 (0%)]\tLoss: 0.877248\nTrain Epoch: 42 [400/2800 (14%)]\tLoss: 0.789422\nTrain Epoch: 42 [800/2800 (29%)]\tLoss: 1.076075\nTrain Epoch: 42 [1200/2800 (43%)]\tLoss: 0.715268\nTrain Epoch: 42 [1600/2800 (57%)]\tLoss: 0.864717\nTrain Epoch: 42 [2000/2800 (71%)]\tLoss: 1.074995\nTrain Epoch: 42 [2400/2800 (86%)]\tLoss: 1.222848\n\nevaluating...\nTest set:\tAverage loss: 1.3788, Average CER: 0.354813 Average WER: 0.8257\n\nTrain Epoch: 43 [0/2800 (0%)]\tLoss: 0.910346\nTrain Epoch: 43 [400/2800 (14%)]\tLoss: 1.222297\nTrain Epoch: 43 [800/2800 (29%)]\tLoss: 0.643107\nTrain Epoch: 43 [1200/2800 (43%)]\tLoss: 0.535661\nTrain Epoch: 43 [1600/2800 (57%)]\tLoss: 0.829184\nTrain Epoch: 43 [2000/2800 (71%)]\tLoss: 1.073979\nTrain Epoch: 43 [2400/2800 (86%)]\tLoss: 1.071357\n\nevaluating...\nTest set:\tAverage loss: 1.4025, Average CER: 0.354193 Average WER: 0.8060\n\nTrain Epoch: 44 [0/2800 (0%)]\tLoss: 1.170326\nTrain Epoch: 44 [400/2800 (14%)]\tLoss: 0.736492\nTrain Epoch: 44 [800/2800 (29%)]\tLoss: 0.712903\nTrain Epoch: 44 [1200/2800 (43%)]\tLoss: 0.925946\nTrain Epoch: 44 [1600/2800 (57%)]\tLoss: 0.458747\nTrain Epoch: 44 [2000/2800 (71%)]\tLoss: 0.908279\nTrain Epoch: 44 [2400/2800 (86%)]\tLoss: 0.522053\n\nevaluating...\nTest set:\tAverage loss: 1.4451, Average CER: 0.361534 Average WER: 0.8131\n\nTrain Epoch: 45 [0/2800 (0%)]\tLoss: 1.042152\nTrain Epoch: 45 [400/2800 (14%)]\tLoss: 0.288168\nTrain Epoch: 45 [800/2800 (29%)]\tLoss: 0.871692\nTrain Epoch: 45 [1200/2800 (43%)]\tLoss: 0.720457\nTrain Epoch: 45 [1600/2800 (57%)]\tLoss: 0.921402\nTrain Epoch: 45 [2000/2800 (71%)]\tLoss: 0.546648\nTrain Epoch: 45 [2400/2800 (86%)]\tLoss: 1.219452\n\nevaluating...\nTest set:\tAverage loss: 1.4268, Average CER: 0.359098 Average WER: 0.8369\n\nTrain Epoch: 46 [0/2800 (0%)]\tLoss: 0.619154\nTrain Epoch: 46 [400/2800 (14%)]\tLoss: 0.797369\nTrain Epoch: 46 [800/2800 (29%)]\tLoss: 0.622907\nTrain Epoch: 46 [1200/2800 (43%)]\tLoss: 0.622902\nTrain Epoch: 46 [1600/2800 (57%)]\tLoss: 0.885004\nTrain Epoch: 46 [2000/2800 (71%)]\tLoss: 0.982117\nTrain Epoch: 46 [2400/2800 (86%)]\tLoss: 0.682855\n\nevaluating...\nTest set:\tAverage loss: 1.3924, Average CER: 0.358012 Average WER: 0.8119\n\nTrain Epoch: 47 [0/2800 (0%)]\tLoss: 0.712104\nTrain Epoch: 47 [400/2800 (14%)]\tLoss: 0.526924\nTrain Epoch: 47 [800/2800 (29%)]\tLoss: 0.978181\nTrain Epoch: 47 [1200/2800 (43%)]\tLoss: 1.049035\nTrain Epoch: 47 [1600/2800 (57%)]\tLoss: 1.412516\nTrain Epoch: 47 [2000/2800 (71%)]\tLoss: 0.939145\nTrain Epoch: 47 [2400/2800 (86%)]\tLoss: 1.004961\n\nevaluating...\nTest set:\tAverage loss: 1.4467, Average CER: 0.368893 Average WER: 0.8458\n\nTrain Epoch: 48 [0/2800 (0%)]\tLoss: 1.144156\nTrain Epoch: 48 [400/2800 (14%)]\tLoss: 0.544068\nTrain Epoch: 48 [800/2800 (29%)]\tLoss: 0.806162\nTrain Epoch: 48 [1200/2800 (43%)]\tLoss: 1.258692\nTrain Epoch: 48 [1600/2800 (57%)]\tLoss: 0.919221\nTrain Epoch: 48 [2000/2800 (71%)]\tLoss: 1.134270\nTrain Epoch: 48 [2400/2800 (86%)]\tLoss: 1.091069\n\nevaluating...\nTest set:\tAverage loss: 1.4698, Average CER: 0.370795 Average WER: 0.8180\n\nTrain Epoch: 49 [0/2800 (0%)]\tLoss: 1.356869\nTrain Epoch: 49 [400/2800 (14%)]\tLoss: 1.103216\nTrain Epoch: 49 [800/2800 (29%)]\tLoss: 0.714457\nTrain Epoch: 49 [1200/2800 (43%)]\tLoss: 0.935024\nTrain Epoch: 49 [1600/2800 (57%)]\tLoss: 0.823209\nTrain Epoch: 49 [2000/2800 (71%)]\tLoss: 0.636147\nTrain Epoch: 49 [2400/2800 (86%)]\tLoss: 0.427025\n\nevaluating...\nTest set:\tAverage loss: 1.3993, Average CER: 0.348729 Average WER: 0.8077\n\nTrain Epoch: 50 [0/2800 (0%)]\tLoss: 0.449917\nTrain Epoch: 50 [400/2800 (14%)]\tLoss: 0.705663\nTrain Epoch: 50 [800/2800 (29%)]\tLoss: 0.558718\nTrain Epoch: 50 [1200/2800 (43%)]\tLoss: 1.140518\nTrain Epoch: 50 [1600/2800 (57%)]\tLoss: 1.304321\nTrain Epoch: 50 [2000/2800 (71%)]\tLoss: 0.996587\nTrain Epoch: 50 [2400/2800 (86%)]\tLoss: 0.724309\n\nevaluating...\nTest set:\tAverage loss: 1.3960, Average CER: 0.345475 Average WER: 0.7763\n\nTrain Epoch: 51 [0/2800 (0%)]\tLoss: 0.765065\nTrain Epoch: 51 [400/2800 (14%)]\tLoss: 0.486000\nTrain Epoch: 51 [800/2800 (29%)]\tLoss: 0.745590\nTrain Epoch: 51 [1200/2800 (43%)]\tLoss: 0.764143\nTrain Epoch: 51 [1600/2800 (57%)]\tLoss: 1.054793\nTrain Epoch: 51 [2000/2800 (71%)]\tLoss: 0.664929\nTrain Epoch: 51 [2400/2800 (86%)]\tLoss: 0.788279\n\nevaluating...\nTest set:\tAverage loss: 1.4230, Average CER: 0.345374 Average WER: 0.7892\n\nTrain Epoch: 52 [0/2800 (0%)]\tLoss: 0.333192\nTrain Epoch: 52 [400/2800 (14%)]\tLoss: 0.700517\nTrain Epoch: 52 [800/2800 (29%)]\tLoss: 1.075275\nTrain Epoch: 52 [1200/2800 (43%)]\tLoss: 0.883501\nTrain Epoch: 52 [1600/2800 (57%)]\tLoss: 0.504545\nTrain Epoch: 52 [2000/2800 (71%)]\tLoss: 0.540329\nTrain Epoch: 52 [2400/2800 (86%)]\tLoss: 0.780536\n\nevaluating...\nTest set:\tAverage loss: 1.4574, Average CER: 0.349555 Average WER: 0.8294\n\nTrain Epoch: 53 [0/2800 (0%)]\tLoss: 0.635176\nTrain Epoch: 53 [400/2800 (14%)]\tLoss: 1.181449\nTrain Epoch: 53 [800/2800 (29%)]\tLoss: 0.284550\nTrain Epoch: 53 [1200/2800 (43%)]\tLoss: 0.886495\nTrain Epoch: 53 [1600/2800 (57%)]\tLoss: 1.256724\nTrain Epoch: 53 [2000/2800 (71%)]\tLoss: 0.745420\nTrain Epoch: 53 [2400/2800 (86%)]\tLoss: 0.683313\n\nevaluating...\nTest set:\tAverage loss: 1.4424, Average CER: 0.355243 Average WER: 0.8254\n\nTrain Epoch: 54 [0/2800 (0%)]\tLoss: 0.517636\nTrain Epoch: 54 [400/2800 (14%)]\tLoss: 0.984917\nTrain Epoch: 54 [800/2800 (29%)]\tLoss: 0.656723\nTrain Epoch: 54 [1200/2800 (43%)]\tLoss: 0.637433\nTrain Epoch: 54 [1600/2800 (57%)]\tLoss: 0.791283\nTrain Epoch: 54 [2000/2800 (71%)]\tLoss: 0.712625\nTrain Epoch: 54 [2400/2800 (86%)]\tLoss: 0.652148\n\nevaluating...\nTest set:\tAverage loss: 1.4372, Average CER: 0.339413 Average WER: 0.7958\n\nTrain Epoch: 55 [0/2800 (0%)]\tLoss: 0.633894\nTrain Epoch: 55 [400/2800 (14%)]\tLoss: 0.643118\nTrain Epoch: 55 [800/2800 (29%)]\tLoss: 1.126264\nTrain Epoch: 55 [1200/2800 (43%)]\tLoss: 0.857955\nTrain Epoch: 55 [1600/2800 (57%)]\tLoss: 0.724715\nTrain Epoch: 55 [2000/2800 (71%)]\tLoss: 0.624469\nTrain Epoch: 55 [2400/2800 (86%)]\tLoss: 0.996372\n\nevaluating...\nTest set:\tAverage loss: 1.4535, Average CER: 0.338831 Average WER: 0.7933\n\nTrain Epoch: 56 [0/2800 (0%)]\tLoss: 0.257634\nTrain Epoch: 56 [400/2800 (14%)]\tLoss: 0.462497\nTrain Epoch: 56 [800/2800 (29%)]\tLoss: 0.602071\nTrain Epoch: 56 [1200/2800 (43%)]\tLoss: 0.223156\nTrain Epoch: 56 [1600/2800 (57%)]\tLoss: 1.164578\nTrain Epoch: 56 [2000/2800 (71%)]\tLoss: 0.670905\nTrain Epoch: 56 [2400/2800 (86%)]\tLoss: 0.996450\n\nevaluating...\nTest set:\tAverage loss: 1.4497, Average CER: 0.343949 Average WER: 0.7856\n\nTrain Epoch: 57 [0/2800 (0%)]\tLoss: 1.000121\nTrain Epoch: 57 [400/2800 (14%)]\tLoss: 0.633841\nTrain Epoch: 57 [800/2800 (29%)]\tLoss: 0.378608\nTrain Epoch: 57 [1200/2800 (43%)]\tLoss: 0.743573\nTrain Epoch: 57 [1600/2800 (57%)]\tLoss: 0.870898\nTrain Epoch: 57 [2000/2800 (71%)]\tLoss: 0.669566\nTrain Epoch: 57 [2400/2800 (86%)]\tLoss: 0.442752\n\nevaluating...\nTest set:\tAverage loss: 1.4949, Average CER: 0.354809 Average WER: 0.8231\n\nTrain Epoch: 58 [0/2800 (0%)]\tLoss: 0.955422\nTrain Epoch: 58 [400/2800 (14%)]\tLoss: 0.924275\nTrain Epoch: 58 [800/2800 (29%)]\tLoss: 0.606967\nTrain Epoch: 58 [1200/2800 (43%)]\tLoss: 0.514741\nTrain Epoch: 58 [1600/2800 (57%)]\tLoss: 1.048826\nTrain Epoch: 58 [2000/2800 (71%)]\tLoss: 0.921739\nTrain Epoch: 58 [2400/2800 (86%)]\tLoss: 1.000365\n\nevaluating...\nTest set:\tAverage loss: 1.4592, Average CER: 0.344989 Average WER: 0.7955\n\nTrain Epoch: 59 [0/2800 (0%)]\tLoss: 0.582824\nTrain Epoch: 59 [400/2800 (14%)]\tLoss: 0.595663\nTrain Epoch: 59 [800/2800 (29%)]\tLoss: 1.004689\nTrain Epoch: 59 [1200/2800 (43%)]\tLoss: 0.684581\nTrain Epoch: 59 [1600/2800 (57%)]\tLoss: 0.754886\nTrain Epoch: 59 [2000/2800 (71%)]\tLoss: 0.761614\nTrain Epoch: 59 [2400/2800 (86%)]\tLoss: 0.430265\n\nevaluating...\nTest set:\tAverage loss: 1.4586, Average CER: 0.335590 Average WER: 0.7995\n\nTrain Epoch: 60 [0/2800 (0%)]\tLoss: 0.565283\nTrain Epoch: 60 [400/2800 (14%)]\tLoss: 0.527737\nTrain Epoch: 60 [800/2800 (29%)]\tLoss: 0.699318\nTrain Epoch: 60 [1200/2800 (43%)]\tLoss: 0.536015\nTrain Epoch: 60 [1600/2800 (57%)]\tLoss: 0.469857\nTrain Epoch: 60 [2000/2800 (71%)]\tLoss: 0.609700\nTrain Epoch: 60 [2400/2800 (86%)]\tLoss: 1.221967\n\nevaluating...\nTest set:\tAverage loss: 1.4754, Average CER: 0.334799 Average WER: 0.7790\n\nTrain Epoch: 61 [0/2800 (0%)]\tLoss: 0.651268\nTrain Epoch: 61 [400/2800 (14%)]\tLoss: 0.789159\nTrain Epoch: 61 [800/2800 (29%)]\tLoss: 0.375570\nTrain Epoch: 61 [1200/2800 (43%)]\tLoss: 0.194371\nTrain Epoch: 61 [1600/2800 (57%)]\tLoss: 0.244483\nTrain Epoch: 61 [2000/2800 (71%)]\tLoss: 0.676694\nTrain Epoch: 61 [2400/2800 (86%)]\tLoss: 0.678916\n\nevaluating...\nTest set:\tAverage loss: 1.4702, Average CER: 0.339346 Average WER: 0.7899\n\nTrain Epoch: 62 [0/2800 (0%)]\tLoss: 0.321382\nTrain Epoch: 62 [400/2800 (14%)]\tLoss: 0.350486\nTrain Epoch: 62 [800/2800 (29%)]\tLoss: 1.001735\nTrain Epoch: 62 [1200/2800 (43%)]\tLoss: 0.447534\nTrain Epoch: 62 [1600/2800 (57%)]\tLoss: 1.348624\nTrain Epoch: 62 [2000/2800 (71%)]\tLoss: 0.824629\nTrain Epoch: 62 [2400/2800 (86%)]\tLoss: 0.257018\n\nevaluating...\nTest set:\tAverage loss: 1.4811, Average CER: 0.331808 Average WER: 0.7771\n\nTrain Epoch: 63 [0/2800 (0%)]\tLoss: 0.711601\nTrain Epoch: 63 [400/2800 (14%)]\tLoss: 0.279722\nTrain Epoch: 63 [800/2800 (29%)]\tLoss: 0.301776\nTrain Epoch: 63 [1200/2800 (43%)]\tLoss: 0.643321\nTrain Epoch: 63 [1600/2800 (57%)]\tLoss: 0.392738\nTrain Epoch: 63 [2000/2800 (71%)]\tLoss: 0.299905\nTrain Epoch: 63 [2400/2800 (86%)]\tLoss: 0.193876\n\nevaluating...\nTest set:\tAverage loss: 1.5275, Average CER: 0.337770 Average WER: 0.8061\n\nTrain Epoch: 64 [0/2800 (0%)]\tLoss: 0.797277\nTrain Epoch: 64 [400/2800 (14%)]\tLoss: 0.496301\nTrain Epoch: 64 [800/2800 (29%)]\tLoss: 0.607320\nTrain Epoch: 64 [1200/2800 (43%)]\tLoss: 0.945998\nTrain Epoch: 64 [1600/2800 (57%)]\tLoss: 0.638292\nTrain Epoch: 64 [2000/2800 (71%)]\tLoss: 1.245752\nTrain Epoch: 64 [2400/2800 (86%)]\tLoss: 0.549102\n\nevaluating...\nTest set:\tAverage loss: 1.5426, Average CER: 0.333818 Average WER: 0.8031\n\nTrain Epoch: 65 [0/2800 (0%)]\tLoss: 0.611933\nTrain Epoch: 65 [400/2800 (14%)]\tLoss: 0.696782\nTrain Epoch: 65 [800/2800 (29%)]\tLoss: 1.169203\nTrain Epoch: 65 [1200/2800 (43%)]\tLoss: 0.865885\nTrain Epoch: 65 [1600/2800 (57%)]\tLoss: 1.068712\nTrain Epoch: 65 [2000/2800 (71%)]\tLoss: 0.429466\nTrain Epoch: 65 [2400/2800 (86%)]\tLoss: 0.801689\n\nevaluating...\nTest set:\tAverage loss: 1.5789, Average CER: 0.337624 Average WER: 0.7791\n\nTrain Epoch: 66 [0/2800 (0%)]\tLoss: 0.063727\nTrain Epoch: 66 [400/2800 (14%)]\tLoss: 0.637144\nTrain Epoch: 66 [800/2800 (29%)]\tLoss: 0.512838\nTrain Epoch: 66 [1200/2800 (43%)]\tLoss: 0.778185\nTrain Epoch: 66 [1600/2800 (57%)]\tLoss: 0.603778\nTrain Epoch: 66 [2000/2800 (71%)]\tLoss: 0.598972\nTrain Epoch: 66 [2400/2800 (86%)]\tLoss: 0.715165\n\nevaluating...\nTest set:\tAverage loss: 1.5628, Average CER: 0.325440 Average WER: 0.7640\n\nTrain Epoch: 67 [0/2800 (0%)]\tLoss: 0.441609\nTrain Epoch: 67 [400/2800 (14%)]\tLoss: 1.318708\nTrain Epoch: 67 [800/2800 (29%)]\tLoss: 0.419607\nTrain Epoch: 67 [1200/2800 (43%)]\tLoss: 0.223768\nTrain Epoch: 67 [1600/2800 (57%)]\tLoss: 0.641928\nTrain Epoch: 67 [2000/2800 (71%)]\tLoss: 0.592306\nTrain Epoch: 67 [2400/2800 (86%)]\tLoss: 0.313794\n\nevaluating...\nTest set:\tAverage loss: 1.6023, Average CER: 0.335063 Average WER: 0.7898\n\nTrain Epoch: 68 [0/2800 (0%)]\tLoss: 0.632456\nTrain Epoch: 68 [400/2800 (14%)]\tLoss: 0.398514\nTrain Epoch: 68 [800/2800 (29%)]\tLoss: 0.432384\nTrain Epoch: 68 [1200/2800 (43%)]\tLoss: 0.360625\nTrain Epoch: 68 [1600/2800 (57%)]\tLoss: 0.813130\nTrain Epoch: 68 [2000/2800 (71%)]\tLoss: 0.227943\nTrain Epoch: 68 [2400/2800 (86%)]\tLoss: 0.441623\n\nevaluating...\nTest set:\tAverage loss: 1.6094, Average CER: 0.326971 Average WER: 0.7581\n\nTrain Epoch: 69 [0/2800 (0%)]\tLoss: 0.753770\nTrain Epoch: 69 [400/2800 (14%)]\tLoss: 0.558079\nTrain Epoch: 69 [800/2800 (29%)]\tLoss: 0.896238\nTrain Epoch: 69 [1200/2800 (43%)]\tLoss: 0.398057\nTrain Epoch: 69 [1600/2800 (57%)]\tLoss: 0.382193\nTrain Epoch: 69 [2000/2800 (71%)]\tLoss: 0.320253\nTrain Epoch: 69 [2400/2800 (86%)]\tLoss: 0.788934\n\nevaluating...\nTest set:\tAverage loss: 1.6161, Average CER: 0.329505 Average WER: 0.7746\n\nTrain Epoch: 70 [0/2800 (0%)]\tLoss: 0.538585\nTrain Epoch: 70 [400/2800 (14%)]\tLoss: 0.506106\nTrain Epoch: 70 [800/2800 (29%)]\tLoss: 0.371223\nTrain Epoch: 70 [1200/2800 (43%)]\tLoss: 0.621370\nTrain Epoch: 70 [1600/2800 (57%)]\tLoss: 0.387278\nTrain Epoch: 70 [2000/2800 (71%)]\tLoss: 0.210572\nTrain Epoch: 70 [2400/2800 (86%)]\tLoss: 0.441275\n\nevaluating...\nTest set:\tAverage loss: 1.7272, Average CER: 0.339590 Average WER: 0.8019\n\nTrain Epoch: 71 [0/2800 (0%)]\tLoss: 0.711800\nTrain Epoch: 71 [400/2800 (14%)]\tLoss: 0.712891\nTrain Epoch: 71 [800/2800 (29%)]\tLoss: 0.613309\nTrain Epoch: 71 [1200/2800 (43%)]\tLoss: 0.397428\nTrain Epoch: 71 [1600/2800 (57%)]\tLoss: 0.122278\nTrain Epoch: 71 [2000/2800 (71%)]\tLoss: 0.056951\nTrain Epoch: 71 [2400/2800 (86%)]\tLoss: 0.551242\n\nevaluating...\nTest set:\tAverage loss: 1.7074, Average CER: 0.335200 Average WER: 0.7886\n\nTrain Epoch: 72 [0/2800 (0%)]\tLoss: 0.139607\nTrain Epoch: 72 [400/2800 (14%)]\tLoss: 0.330121\nTrain Epoch: 72 [800/2800 (29%)]\tLoss: 0.283102\nTrain Epoch: 72 [1200/2800 (43%)]\tLoss: 0.539070\nTrain Epoch: 72 [1600/2800 (57%)]\tLoss: 0.457544\nTrain Epoch: 72 [2000/2800 (71%)]\tLoss: 0.251350\nTrain Epoch: 72 [2400/2800 (86%)]\tLoss: 0.342767\n\nevaluating...\nTest set:\tAverage loss: 1.7067, Average CER: 0.333053 Average WER: 0.7829\n\nTrain Epoch: 73 [0/2800 (0%)]\tLoss: 0.496092\nTrain Epoch: 73 [400/2800 (14%)]\tLoss: 0.513595\nTrain Epoch: 73 [800/2800 (29%)]\tLoss: 0.342402\nTrain Epoch: 73 [1200/2800 (43%)]\tLoss: 0.543890\nTrain Epoch: 73 [1600/2800 (57%)]\tLoss: 0.212693\nTrain Epoch: 73 [2000/2800 (71%)]\tLoss: 0.558785\nTrain Epoch: 73 [2400/2800 (86%)]\tLoss: 0.361510\n\nevaluating...\nTest set:\tAverage loss: 1.7477, Average CER: 0.328727 Average WER: 0.7890\n\nTrain Epoch: 74 [0/2800 (0%)]\tLoss: 0.535557\nTrain Epoch: 74 [400/2800 (14%)]\tLoss: 0.294805\nTrain Epoch: 74 [800/2800 (29%)]\tLoss: 0.224317\nTrain Epoch: 74 [1200/2800 (43%)]\tLoss: 0.374658\nTrain Epoch: 74 [1600/2800 (57%)]\tLoss: 0.175808\nTrain Epoch: 74 [2000/2800 (71%)]\tLoss: 0.509977\nTrain Epoch: 74 [2400/2800 (86%)]\tLoss: 0.288958\n\nevaluating...\nTest set:\tAverage loss: 1.7792, Average CER: 0.328037 Average WER: 0.7701\n\nTrain Epoch: 75 [0/2800 (0%)]\tLoss: 0.222116\nTrain Epoch: 75 [400/2800 (14%)]\tLoss: 0.413393\nTrain Epoch: 75 [800/2800 (29%)]\tLoss: 0.293887\nTrain Epoch: 75 [1200/2800 (43%)]\tLoss: 0.372916\nTrain Epoch: 75 [1600/2800 (57%)]\tLoss: 0.680450\nTrain Epoch: 75 [2000/2800 (71%)]\tLoss: 0.481695\nTrain Epoch: 75 [2400/2800 (86%)]\tLoss: 0.283696\n\nevaluating...\nTest set:\tAverage loss: 1.7961, Average CER: 0.332305 Average WER: 0.7792\n\nTrain Epoch: 76 [0/2800 (0%)]\tLoss: 0.457304\nTrain Epoch: 76 [400/2800 (14%)]\tLoss: 0.101540\nTrain Epoch: 76 [800/2800 (29%)]\tLoss: 0.329426\nTrain Epoch: 76 [1200/2800 (43%)]\tLoss: 0.170974\nTrain Epoch: 76 [1600/2800 (57%)]\tLoss: 0.246787\nTrain Epoch: 76 [2000/2800 (71%)]\tLoss: 0.483327\nTrain Epoch: 76 [2400/2800 (86%)]\tLoss: 0.113238\n\nevaluating...\nTest set:\tAverage loss: 1.8192, Average CER: 0.328280 Average WER: 0.7707\n\nTrain Epoch: 77 [0/2800 (0%)]\tLoss: 0.213316\nTrain Epoch: 77 [400/2800 (14%)]\tLoss: 0.466718\nTrain Epoch: 77 [800/2800 (29%)]\tLoss: 0.689808\nTrain Epoch: 77 [1200/2800 (43%)]\tLoss: 0.341770\nTrain Epoch: 77 [1600/2800 (57%)]\tLoss: 0.470880\nTrain Epoch: 77 [2000/2800 (71%)]\tLoss: 0.134899\nTrain Epoch: 77 [2400/2800 (86%)]\tLoss: 0.192757\n\nevaluating...\nTest set:\tAverage loss: 1.8463, Average CER: 0.332354 Average WER: 0.7947\n\nTrain Epoch: 78 [0/2800 (0%)]\tLoss: 0.136402\nTrain Epoch: 78 [400/2800 (14%)]\tLoss: 0.507788\nTrain Epoch: 78 [800/2800 (29%)]\tLoss: 0.384273\nTrain Epoch: 78 [1200/2800 (43%)]\tLoss: 0.142237\nTrain Epoch: 78 [1600/2800 (57%)]\tLoss: 0.415218\nTrain Epoch: 78 [2000/2800 (71%)]\tLoss: 0.402812\nTrain Epoch: 78 [2400/2800 (86%)]\tLoss: 0.387148\n\nevaluating...\nTest set:\tAverage loss: 1.9234, Average CER: 0.326892 Average WER: 0.7762\n\nTrain Epoch: 79 [0/2800 (0%)]\tLoss: 0.157810\nTrain Epoch: 79 [400/2800 (14%)]\tLoss: 0.562792\nTrain Epoch: 79 [800/2800 (29%)]\tLoss: 0.102587\nTrain Epoch: 79 [1200/2800 (43%)]\tLoss: 0.213302\nTrain Epoch: 79 [1600/2800 (57%)]\tLoss: 0.524031\nTrain Epoch: 79 [2000/2800 (71%)]\tLoss: 0.302798\nTrain Epoch: 79 [2400/2800 (86%)]\tLoss: 0.276285\n\nevaluating...\nTest set:\tAverage loss: 1.9340, Average CER: 0.324158 Average WER: 0.7698\n\nTrain Epoch: 80 [0/2800 (0%)]\tLoss: 0.126706\nTrain Epoch: 80 [400/2800 (14%)]\tLoss: 0.145978\nTrain Epoch: 80 [800/2800 (29%)]\tLoss: 0.202150\nTrain Epoch: 80 [1200/2800 (43%)]\tLoss: 0.218653\nTrain Epoch: 80 [1600/2800 (57%)]\tLoss: 0.118389\nTrain Epoch: 80 [2000/2800 (71%)]\tLoss: 0.356095\nTrain Epoch: 80 [2400/2800 (86%)]\tLoss: 0.256814\n\nevaluating...\nTest set:\tAverage loss: 2.0049, Average CER: 0.327639 Average WER: 0.7805\n\nTrain Epoch: 81 [0/2800 (0%)]\tLoss: 0.223939\nTrain Epoch: 81 [400/2800 (14%)]\tLoss: 0.329805\nTrain Epoch: 81 [800/2800 (29%)]\tLoss: 0.306800\nTrain Epoch: 81 [1200/2800 (43%)]\tLoss: 0.134960\nTrain Epoch: 81 [1600/2800 (57%)]\tLoss: 0.122449\nTrain Epoch: 81 [2000/2800 (71%)]\tLoss: 0.437054\nTrain Epoch: 81 [2400/2800 (86%)]\tLoss: 0.333978\n\nevaluating...\nTest set:\tAverage loss: 2.0296, Average CER: 0.334527 Average WER: 0.7923\n\nTrain Epoch: 82 [0/2800 (0%)]\tLoss: 0.232455\nTrain Epoch: 82 [400/2800 (14%)]\tLoss: 0.418520\nTrain Epoch: 82 [800/2800 (29%)]\tLoss: 0.101613\nTrain Epoch: 82 [1200/2800 (43%)]\tLoss: 0.095153\nTrain Epoch: 82 [1600/2800 (57%)]\tLoss: 0.208061\nTrain Epoch: 82 [2000/2800 (71%)]\tLoss: 0.370350\nTrain Epoch: 82 [2400/2800 (86%)]\tLoss: 0.199117\n\nevaluating...\nTest set:\tAverage loss: 2.0518, Average CER: 0.329905 Average WER: 0.7702\n\nTrain Epoch: 83 [0/2800 (0%)]\tLoss: 0.412163\nTrain Epoch: 83 [400/2800 (14%)]\tLoss: 0.416858\nTrain Epoch: 83 [800/2800 (29%)]\tLoss: 0.184523\nTrain Epoch: 83 [1200/2800 (43%)]\tLoss: 0.472536\nTrain Epoch: 83 [1600/2800 (57%)]\tLoss: 0.135918\nTrain Epoch: 83 [2000/2800 (71%)]\tLoss: 0.393841\nTrain Epoch: 83 [2400/2800 (86%)]\tLoss: 0.359714\n\nevaluating...\nTest set:\tAverage loss: 2.0823, Average CER: 0.332986 Average WER: 0.7805\n\nTrain Epoch: 84 [0/2800 (0%)]\tLoss: 0.155641\nTrain Epoch: 84 [400/2800 (14%)]\tLoss: 0.264746\nTrain Epoch: 84 [800/2800 (29%)]\tLoss: 0.100697\nTrain Epoch: 84 [1200/2800 (43%)]\tLoss: 0.351634\nTrain Epoch: 84 [1600/2800 (57%)]\tLoss: 0.356532\nTrain Epoch: 84 [2000/2800 (71%)]\tLoss: 0.171192\nTrain Epoch: 84 [2400/2800 (86%)]\tLoss: 0.177011\n\nevaluating...\nTest set:\tAverage loss: 2.1367, Average CER: 0.328192 Average WER: 0.7751\n\nTrain Epoch: 85 [0/2800 (0%)]\tLoss: 0.319758\nTrain Epoch: 85 [400/2800 (14%)]\tLoss: 0.223955\nTrain Epoch: 85 [800/2800 (29%)]\tLoss: 0.226954\nTrain Epoch: 85 [1200/2800 (43%)]\tLoss: 0.059575\nTrain Epoch: 85 [1600/2800 (57%)]\tLoss: 0.099565\nTrain Epoch: 85 [2000/2800 (71%)]\tLoss: 0.247642\nTrain Epoch: 85 [2400/2800 (86%)]\tLoss: 0.288926\n\nevaluating...\nTest set:\tAverage loss: 2.2042, Average CER: 0.334216 Average WER: 0.7741\n\nTrain Epoch: 86 [0/2800 (0%)]\tLoss: 0.189611\nTrain Epoch: 86 [400/2800 (14%)]\tLoss: 0.083409\nTrain Epoch: 86 [800/2800 (29%)]\tLoss: 0.183826\nTrain Epoch: 86 [1200/2800 (43%)]\tLoss: 0.245393\nTrain Epoch: 86 [1600/2800 (57%)]\tLoss: 0.148612\nTrain Epoch: 86 [2000/2800 (71%)]\tLoss: 0.081409\nTrain Epoch: 86 [2400/2800 (86%)]\tLoss: 0.204046\n\nevaluating...\nTest set:\tAverage loss: 2.2346, Average CER: 0.337731 Average WER: 0.7922\n\nTrain Epoch: 87 [0/2800 (0%)]\tLoss: 0.147545\nTrain Epoch: 87 [400/2800 (14%)]\tLoss: 0.109519\nTrain Epoch: 87 [800/2800 (29%)]\tLoss: 0.042214\nTrain Epoch: 87 [1200/2800 (43%)]\tLoss: 0.086982\nTrain Epoch: 87 [1600/2800 (57%)]\tLoss: 0.340199\nTrain Epoch: 87 [2000/2800 (71%)]\tLoss: 0.166690\nTrain Epoch: 87 [2400/2800 (86%)]\tLoss: 0.241382\n\nevaluating...\nTest set:\tAverage loss: 2.2618, Average CER: 0.337016 Average WER: 0.7934\n\nTrain Epoch: 88 [0/2800 (0%)]\tLoss: 0.039157\nTrain Epoch: 88 [400/2800 (14%)]\tLoss: 0.105873\nTrain Epoch: 88 [800/2800 (29%)]\tLoss: 0.161451\nTrain Epoch: 88 [1200/2800 (43%)]\tLoss: 0.102736\nTrain Epoch: 88 [1600/2800 (57%)]\tLoss: 0.043083\nTrain Epoch: 88 [2000/2800 (71%)]\tLoss: 0.064601\nTrain Epoch: 88 [2400/2800 (86%)]\tLoss: 0.216987\n\nevaluating...\nTest set:\tAverage loss: 2.3061, Average CER: 0.338312 Average WER: 0.7872\n\nTrain Epoch: 89 [0/2800 (0%)]\tLoss: 0.155178\nTrain Epoch: 89 [400/2800 (14%)]\tLoss: 0.163120\nTrain Epoch: 89 [800/2800 (29%)]\tLoss: 0.153430\nTrain Epoch: 89 [1200/2800 (43%)]\tLoss: 0.005767\nTrain Epoch: 89 [1600/2800 (57%)]\tLoss: 0.212834\nTrain Epoch: 89 [2000/2800 (71%)]\tLoss: 0.306730\nTrain Epoch: 89 [2400/2800 (86%)]\tLoss: 0.036612\n\nevaluating...\nTest set:\tAverage loss: 2.3707, Average CER: 0.337040 Average WER: 0.8029\n\nTrain Epoch: 90 [0/2800 (0%)]\tLoss: 0.066382\nTrain Epoch: 90 [400/2800 (14%)]\tLoss: 0.079689\nTrain Epoch: 90 [800/2800 (29%)]\tLoss: 0.118513\nTrain Epoch: 90 [1200/2800 (43%)]\tLoss: 0.007181\nTrain Epoch: 90 [1600/2800 (57%)]\tLoss: 0.041516\nTrain Epoch: 90 [2000/2800 (71%)]\tLoss: 0.103297\nTrain Epoch: 90 [2400/2800 (86%)]\tLoss: 0.120052\n\nevaluating...\nTest set:\tAverage loss: 2.3982, Average CER: 0.337190 Average WER: 0.7869\n\nTrain Epoch: 91 [0/2800 (0%)]\tLoss: 0.032062\nTrain Epoch: 91 [400/2800 (14%)]\tLoss: 0.071448\nTrain Epoch: 91 [800/2800 (29%)]\tLoss: 0.137039\nTrain Epoch: 91 [1200/2800 (43%)]\tLoss: 0.023596\nTrain Epoch: 91 [1600/2800 (57%)]\tLoss: 0.068206\nTrain Epoch: 91 [2000/2800 (71%)]\tLoss: 0.162677\nTrain Epoch: 91 [2400/2800 (86%)]\tLoss: 0.080801\n\nevaluating...\nTest set:\tAverage loss: 2.4396, Average CER: 0.335639 Average WER: 0.8017\n\nTrain Epoch: 92 [0/2800 (0%)]\tLoss: 0.161306\nTrain Epoch: 92 [400/2800 (14%)]\tLoss: 0.049276\nTrain Epoch: 92 [800/2800 (29%)]\tLoss: 0.147123\nTrain Epoch: 92 [1200/2800 (43%)]\tLoss: 0.035202\nTrain Epoch: 92 [1600/2800 (57%)]\tLoss: 0.011088\nTrain Epoch: 92 [2000/2800 (71%)]\tLoss: 0.069234\nTrain Epoch: 92 [2400/2800 (86%)]\tLoss: 0.159409\n\nevaluating...\nTest set:\tAverage loss: 2.4658, Average CER: 0.337286 Average WER: 0.7871\n\nTrain Epoch: 93 [0/2800 (0%)]\tLoss: 0.027481\nTrain Epoch: 93 [400/2800 (14%)]\tLoss: 0.076610\nTrain Epoch: 93 [800/2800 (29%)]\tLoss: 0.142732\nTrain Epoch: 93 [1200/2800 (43%)]\tLoss: 0.165277\nTrain Epoch: 93 [1600/2800 (57%)]\tLoss: 0.096282\nTrain Epoch: 93 [2000/2800 (71%)]\tLoss: 0.044079\nTrain Epoch: 93 [2400/2800 (86%)]\tLoss: 0.198963\n\nevaluating...\nTest set:\tAverage loss: 2.5078, Average CER: 0.333669 Average WER: 0.7793\n\nTrain Epoch: 94 [0/2800 (0%)]\tLoss: 0.102099\nTrain Epoch: 94 [400/2800 (14%)]\tLoss: 0.019100\nTrain Epoch: 94 [800/2800 (29%)]\tLoss: 0.095348\nTrain Epoch: 94 [1200/2800 (43%)]\tLoss: 0.044691\nTrain Epoch: 94 [1600/2800 (57%)]\tLoss: 0.035139\nTrain Epoch: 94 [2000/2800 (71%)]\tLoss: 0.141141\nTrain Epoch: 94 [2400/2800 (86%)]\tLoss: 0.124376\n\nevaluating...\nTest set:\tAverage loss: 2.4886, Average CER: 0.337725 Average WER: 0.7892\n\nTrain Epoch: 95 [0/2800 (0%)]\tLoss: 0.146727\nTrain Epoch: 95 [400/2800 (14%)]\tLoss: 0.079721\nTrain Epoch: 95 [800/2800 (29%)]\tLoss: 0.040021\nTrain Epoch: 95 [1200/2800 (43%)]\tLoss: 0.021327\nTrain Epoch: 95 [1600/2800 (57%)]\tLoss: 0.085819\nTrain Epoch: 95 [2000/2800 (71%)]\tLoss: 0.036811\nTrain Epoch: 95 [2400/2800 (86%)]\tLoss: 0.073977\n\nevaluating...\nTest set:\tAverage loss: 2.5299, Average CER: 0.339973 Average WER: 0.8024\n\nTrain Epoch: 96 [0/2800 (0%)]\tLoss: 0.115659\nTrain Epoch: 96 [400/2800 (14%)]\tLoss: 0.064204\nTrain Epoch: 96 [800/2800 (29%)]\tLoss: 0.003925\nTrain Epoch: 96 [1200/2800 (43%)]\tLoss: 0.153699\nTrain Epoch: 96 [1600/2800 (57%)]\tLoss: 0.054344\nTrain Epoch: 96 [2000/2800 (71%)]\tLoss: 0.022717\nTrain Epoch: 96 [2400/2800 (86%)]\tLoss: 0.042274\n\nevaluating...\nTest set:\tAverage loss: 2.5607, Average CER: 0.342328 Average WER: 0.8008\n\nTrain Epoch: 97 [0/2800 (0%)]\tLoss: 0.066347\nTrain Epoch: 97 [400/2800 (14%)]\tLoss: 0.042464\nTrain Epoch: 97 [800/2800 (29%)]\tLoss: 0.052521\nTrain Epoch: 97 [1200/2800 (43%)]\tLoss: 0.084132\nTrain Epoch: 97 [1600/2800 (57%)]\tLoss: 0.028544\nTrain Epoch: 97 [2000/2800 (71%)]\tLoss: 0.027027\nTrain Epoch: 97 [2400/2800 (86%)]\tLoss: 0.097025\n\nevaluating...\nTest set:\tAverage loss: 2.5946, Average CER: 0.339719 Average WER: 0.7959\n\nTrain Epoch: 98 [0/2800 (0%)]\tLoss: 0.086152\nTrain Epoch: 98 [400/2800 (14%)]\tLoss: 0.016128\nTrain Epoch: 98 [800/2800 (29%)]\tLoss: 0.115416\nTrain Epoch: 98 [1200/2800 (43%)]\tLoss: 0.083746\nTrain Epoch: 98 [1600/2800 (57%)]\tLoss: 0.003589\nTrain Epoch: 98 [2000/2800 (71%)]\tLoss: 0.096065\nTrain Epoch: 98 [2400/2800 (86%)]\tLoss: 0.041521\n\nevaluating...\nTest set:\tAverage loss: 2.6025, Average CER: 0.338652 Average WER: 0.7981\n\nTrain Epoch: 99 [0/2800 (0%)]\tLoss: 0.016622\nTrain Epoch: 99 [400/2800 (14%)]\tLoss: 0.048168\nTrain Epoch: 99 [800/2800 (29%)]\tLoss: 0.016188\nTrain Epoch: 99 [1200/2800 (43%)]\tLoss: 0.162717\nTrain Epoch: 99 [1600/2800 (57%)]\tLoss: 0.013725\nTrain Epoch: 99 [2000/2800 (71%)]\tLoss: 0.077264\nTrain Epoch: 99 [2400/2800 (86%)]\tLoss: 0.043585\n\nevaluating...\nTest set:\tAverage loss: 2.6063, Average CER: 0.338180 Average WER: 0.8005\n\nTrain Epoch: 100 [0/2800 (0%)]\tLoss: 0.091270\nTrain Epoch: 100 [400/2800 (14%)]\tLoss: 0.025423\nTrain Epoch: 100 [800/2800 (29%)]\tLoss: 0.024067\nTrain Epoch: 100 [1200/2800 (43%)]\tLoss: 0.086462\nTrain Epoch: 100 [1600/2800 (57%)]\tLoss: 0.025096\nTrain Epoch: 100 [2000/2800 (71%)]\tLoss: 0.031908\nTrain Epoch: 100 [2400/2800 (86%)]\tLoss: 0.020288\n\nevaluating...\nTest set:\tAverage loss: 2.6118, Average CER: 0.337433 Average WER: 0.7896\n\nCPU times: user 59min 44s, sys: 2min 47s, total: 1h 2min 31s\nWall time: 1h 2min 24s\n","output_type":"stream"}]},{"cell_type":"code","source":"#use_cuda = torch.cuda.is_available()\n#device = torch.device(\"cpu\")\nneeded_device = torch.device(\"cpu\")\nmodel = torch.load('/kaggle/input/dop-test-files/model_for_making_dataset_v6(20024).pt', map_location=torch.device('cpu'))\n\n#1543 1882 1372\n\nmodel.to(needed_device)\nprint(needed_device)\n#predict(model, '/kaggle/input/upd-speech/mono_voice/1964.wav', device)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.742766Z","iopub.execute_input":"2024-05-26T04:17:41.743182Z","iopub.status.idle":"2024-05-26T04:17:41.996611Z","shell.execute_reply.started":"2024-05-26T04:17:41.743142Z","shell.execute_reply":"2024-05-26T04:17:41.994992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = {'X_test': X_test, 'label': y_test}\ndf_test = pd.DataFrame(data=d)\ndf_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.998094Z","iopub.execute_input":"2024-05-26T04:17:41.998687Z","iopub.status.idle":"2024-05-26T04:17:51.083467Z","shell.execute_reply.started":"2024-05-26T04:17:41.998647Z","shell.execute_reply":"2024-05-26T04:17:51.082064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T18:41:40.097420Z","iopub.execute_input":"2024-05-30T18:41:40.098506Z","iopub.status.idle":"2024-05-30T18:41:40.106244Z","shell.execute_reply.started":"2024-05-30T18:41:40.098458Z","shell.execute_reply":"2024-05-30T18:41:40.105107Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['написать письмо другу',\n 'сходи в аптеку и купи лекарства',\n 'тарелка из под тарталеток',\n 'деревья покрыты инеем',\n 'список']"},"metadata":{}}]},{"cell_type":"code","source":"def count_test_cer(row, model):\n    prediction = predict_with_tensor_v3(model, row['X_test'])\n    return cer(row['label'], prediction)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.099695Z","iopub.execute_input":"2024-05-26T04:17:51.100268Z","iopub.status.idle":"2024-05-26T04:17:51.106727Z","shell.execute_reply.started":"2024-05-26T04:17:51.100225Z","shell.execute_reply":"2024-05-26T04:17:51.105456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_test_wer(row, model):\n    prediction = predict_with_tensor_v3(model, row['X_test'])\n    return wer(row['label'], prediction)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.108189Z","iopub.execute_input":"2024-05-26T04:17:51.108568Z","iopub.status.idle":"2024-05-26T04:17:51.120213Z","shell.execute_reply.started":"2024-05-26T04:17:51.108530Z","shell.execute_reply":"2024-05-26T04:17:51.118791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_preds(row, model):\n    return predict_with_tensor_v3(model, row['X_test'])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.121480Z","iopub.execute_input":"2024-05-26T04:17:51.121846Z","iopub.status.idle":"2024-05-26T04:17:51.133747Z","shell.execute_reply.started":"2024-05-26T04:17:51.121800Z","shell.execute_reply":"2024-05-26T04:17:51.132140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['CER'] = df_test.apply(count_test_cer, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.135252Z","iopub.execute_input":"2024-05-26T04:17:51.135630Z","iopub.status.idle":"2024-05-26T04:20:18.237700Z","shell.execute_reply.started":"2024-05-26T04:17:51.135592Z","shell.execute_reply":"2024-05-26T04:20:18.235582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['WER'] = df_test.apply(count_test_wer, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:20:18.240879Z","iopub.execute_input":"2024-05-26T04:20:18.241567Z","iopub.status.idle":"2024-05-26T04:22:37.380675Z","shell.execute_reply.started":"2024-05-26T04:20:18.241502Z","shell.execute_reply":"2024-05-26T04:22:37.379257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['preds'] = df_test.apply(write_preds, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:22:37.382399Z","iopub.execute_input":"2024-05-26T04:22:37.382791Z","iopub.status.idle":"2024-05-26T04:24:56.562000Z","shell.execute_reply.started":"2024-05-26T04:22:37.382752Z","shell.execute_reply":"2024-05-26T04:24:56.560548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.loc[df_test['CER'] > 0]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:24:56.564034Z","iopub.execute_input":"2024-05-26T04:24:56.564688Z","iopub.status.idle":"2024-05-26T04:25:07.553845Z","shell.execute_reply.started":"2024-05-26T04:24:56.564626Z","shell.execute_reply":"2024-05-26T04:25:07.552232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Проверяем затюненый корректор t5 (на 10 эпохах)","metadata":{}},{"cell_type":"code","source":"print('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ИСПОЛЬЗОВАЛ МАЛЫЙ СЛОВАРЬ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model(3024_seed_data).pt with hunspell. WITHOUT HUNSPELL: CER = Average CER: 0.166791 Average WER: 0.6451","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['CER'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:04:49.056490Z","iopub.execute_input":"2024-05-25T16:04:49.057082Z","iopub.status.idle":"2024-05-25T16:04:49.065840Z","shell.execute_reply.started":"2024-05-25T16:04:49.057036Z","shell.execute_reply":"2024-05-25T16:04:49.064572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['WER'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:04:51.749217Z","iopub.execute_input":"2024-05-25T16:04:51.750349Z","iopub.status.idle":"2024-05-25T16:04:51.757655Z","shell.execute_reply.started":"2024-05-25T16:04:51.750300Z","shell.execute_reply":"2024-05-25T16:04:51.756495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v4(1242).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:19:41.442613Z","iopub.execute_input":"2024-05-25T16:19:41.443296Z","iopub.status.idle":"2024-05-25T16:19:41.455403Z","shell.execute_reply.started":"2024-05-25T16:19:41.443235Z","shell.execute_reply":"2024-05-25T16:19:41.452786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v5(2204).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:37:13.375118Z","iopub.execute_input":"2024-05-25T16:37:13.375680Z","iopub.status.idle":"2024-05-25T16:37:13.386340Z","shell.execute_reply.started":"2024-05-25T16:37:13.375629Z","shell.execute_reply":"2024-05-25T16:37:13.384681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v6(20024).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:49:05.441566Z","iopub.execute_input":"2024-05-25T16:49:05.442097Z","iopub.status.idle":"2024-05-25T16:49:05.451177Z","shell.execute_reply.started":"2024-05-25T16:49:05.442048Z","shell.execute_reply":"2024-05-25T16:49:05.449638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v7(3016).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:59:36.002854Z","iopub.execute_input":"2024-05-25T16:59:36.004626Z","iopub.status.idle":"2024-05-25T16:59:36.014691Z","shell.execute_reply.started":"2024-05-25T16:59:36.004549Z","shell.execute_reply":"2024-05-25T16:59:36.012949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ДАЛЕЕ ИСПОЛЬЗУЕТСЯ БОЛЬШИЙ СЛОВАРЬ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v4(1242).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:22:32.461589Z","iopub.execute_input":"2024-05-25T17:22:32.462082Z","iopub.status.idle":"2024-05-25T17:22:32.471480Z","shell.execute_reply.started":"2024-05-25T17:22:32.462038Z","shell.execute_reply":"2024-05-25T17:22:32.469970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v5(2204).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:03:18.899437Z","iopub.execute_input":"2024-05-26T04:03:18.900728Z","iopub.status.idle":"2024-05-26T04:03:18.909759Z","shell.execute_reply.started":"2024-05-26T04:03:18.900673Z","shell.execute_reply":"2024-05-26T04:03:18.908456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v6(20024).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:14:20.150015Z","iopub.execute_input":"2024-05-26T04:14:20.150512Z","iopub.status.idle":"2024-05-26T04:14:20.160144Z","shell.execute_reply.started":"2024-05-26T04:14:20.150466Z","shell.execute_reply":"2024-05-26T04:14:20.158071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v7(3016).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:25:27.601745Z","iopub.execute_input":"2024-05-26T04:25:27.602257Z","iopub.status.idle":"2024-05-26T04:25:27.611942Z","shell.execute_reply.started":"2024-05-26T04:25:27.602207Z","shell.execute_reply":"2024-05-26T04:25:27.610181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2023-05-24T10:26:24.339488Z","iopub.execute_input":"2023-05-24T10:26:24.340405Z","iopub.status.idle":"2023-05-24T10:26:24.350954Z","shell.execute_reply.started":"2023-05-24T10:26:24.340364Z","shell.execute_reply":"2023-05-24T10:26:24.349831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:16:11.401175Z","iopub.execute_input":"2023-05-13T16:16:11.401879Z","iopub.status.idle":"2023-05-13T16:16:11.430020Z","shell.execute_reply.started":"2023-05-13T16:16:11.401838Z","shell.execute_reply":"2023-05-13T16:16:11.428960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(directory):\n    total_duration = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            filepath = os.path.join(directory, filename)\n            with wave.open(filepath, 'r') as wav_file:\n                frames = wav_file.getnframes()\n                rate = wav_file.getframerate()\n                duration = frames / float(rate)\n                total_duration += duration\n    return total_duration\n\ndirectory = '/kaggle/input/upd-speech/mono_voice'\ntotal_duration = get_wav_duration(directory)\nprint('Total duration of WAV files:', total_duration, 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:15.415086Z","iopub.execute_input":"2023-07-05T10:09:15.415876Z","iopub.status.idle":"2023-07-05T10:09:18.755936Z","shell.execute_reply.started":"2023-07-05T10:09:15.415836Z","shell.execute_reply":"2023-07-05T10:09:18.754693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))\nseconds = 3661\nformatted_time = format_time(total_duration)\nprint(formatted_time)  # Output: '01:01:01'","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:23.353548Z","iopub.execute_input":"2023-07-05T10:09:23.354296Z","iopub.status.idle":"2023-07-05T10:09:23.361628Z","shell.execute_reply.started":"2023-07-05T10:09:23.354254Z","shell.execute_reply":"2023-07-05T10:09:23.360431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}