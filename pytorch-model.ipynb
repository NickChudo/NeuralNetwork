{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5321255,"sourceType":"datasetVersion","datasetId":3091651},{"sourceId":5618710,"sourceType":"datasetVersion","datasetId":3230790},{"sourceId":5677279,"sourceType":"datasetVersion","datasetId":2989949},{"sourceId":5677449,"sourceType":"datasetVersion","datasetId":3071831},{"sourceId":5760288,"sourceType":"datasetVersion","datasetId":3311237},{"sourceId":8003942,"sourceType":"datasetVersion","datasetId":4230886},{"sourceId":8515857,"sourceType":"datasetVersion","datasetId":3213578}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np \nimport matplotlib\nfrom transformers import AutoModelForSeq2SeqLM, T5TokenizerFast\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:15:17.751878Z","iopub.execute_input":"2024-05-26T04:15:17.753334Z","iopub.status.idle":"2024-05-26T04:15:23.585005Z","shell.execute_reply.started":"2024-05-26T04:15:17.753269Z","shell.execute_reply":"2024-05-26T04:15:23.583446Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def avg_wer(wer_scores, combined_ref_len):\n    return float(sum(wer_scores)) / float(combined_ref_len)\n\n\ndef _levenshtein_distance(ref, hyp):\n    m = len(ref)\n    n = len(hyp)\n\n    # special case\n    if ref == hyp:\n        return 0\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n\n    if m < n:\n        ref, hyp = hyp, ref\n        m, n = n, m\n\n    distance = np.zeros((2, n + 1), dtype=np.int32)\n\n    for j in range(0,n + 1):\n        distance[0][j] = j\n\n    for i in range(1, m + 1):\n        prev_row_idx = (i - 1) % 2\n        cur_row_idx = i % 2\n        distance[cur_row_idx][0] = i\n        for j in range(1, n + 1):\n            if ref[i - 1] == hyp[j - 1]:\n                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n            else:\n                s_num = distance[prev_row_idx][j - 1] + 1\n                i_num = distance[cur_row_idx][j - 1] + 1\n                d_num = distance[prev_row_idx][j] + 1\n                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n\n    return distance[m % 2][n]\n\n\ndef word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    ref_words = reference.split(delimiter)\n    hyp_words = hypothesis.split(delimiter)\n\n    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n    return float(edit_distance), len(ref_words)\n\n\ndef char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    join_char = ' '\n    if remove_space == True:\n        join_char = ''\n\n    reference = join_char.join(filter(None, reference.split(' ')))\n    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n\n    edit_distance = _levenshtein_distance(reference, hypothesis)\n    return float(edit_distance), len(reference)\n\n\ndef wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n                                         delimiter)\n\n    if ref_len == 0:\n        raise ValueError(\"Reference's word number should be greater than 0.\")\n\n    wer = float(edit_distance) / ref_len\n    return wer\n\n\ndef cer(reference, hypothesis, ignore_case=False, remove_space=False):\n    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n                                         remove_space)\n\n    if ref_len == 0:\n        raise ValueError(\"Length of reference should be greater than 0.\")\n\n    cer = float(edit_distance) / ref_len\n    return cer\n\nclass TextTransform:\n    def __init__(self):\n        self.char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n                  \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n                  \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n                  \"я\": 31, \"х\": 32, \" \": 33}\n\n        self.index_map = {}\n        for key, value in self.char_map.items():\n            self.index_map[value] = key\n\n    def text_to_int(self, text):\n        int_sequence = []\n        for c in text:\n            ch = self.char_map[c]\n            int_sequence.append(ch)\n        return int_sequence\n\n    def int_to_text(self, labels):\n        string = []\n        for i in labels:\n            string.append(self.index_map[i])\n        return ''.join(string)\n\n\ntrain_audio_transforms = nn.Sequential(\n    torchaudio.transforms.MFCC(n_mfcc=20)\n)\n\n\nvalid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n\ntext_transform = TextTransform()\n\ndef data_processing(data, data_type=\"train\"):\n    spectrograms = []\n    labels = []\n    input_lengths = []\n    label_lengths = []\n    for (waveform, utterance) in data:\n        if data_type == 'train':\n            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        elif data_type == 'valid':\n            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        else:\n            raise Exception('data_type should be train or valid')\n        spectrograms.append(spec)\n        label = torch.Tensor(text_transform.text_to_int(utterance))\n        labels.append(label)\n        input_lengths.append(spec.shape[0]//3)\n        label_lengths.append(len(label))\n    \n    spectrograms1 = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n            \n    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n\n    return spectrograms1, labels, input_lengths, label_lengths\n\n\ndef GreedyDecoder(output, labels, label_lengths, blank_label=34, collapse_repeated=True):\n    arg_maxes = torch.argmax(output, dim=2)\n    decodes = []\n    targets = []\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n        for j, index in enumerate(args):\n            if index != blank_label:\n                if collapse_repeated and j != 0 and index == args[j -1]:\n                    continue\n                decode.append(index.item())\n        decodes.append(text_transform.int_to_text(decode))\n    return decodes, targets","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:15:23.589550Z","iopub.execute_input":"2024-05-26T04:15:23.590564Z","iopub.status.idle":"2024-05-26T04:15:23.751895Z","shell.execute_reply.started":"2024-05-26T04:15:23.590518Z","shell.execute_reply":"2024-05-26T04:15:23.750441Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"class BidirectionalGRU(nn.Module):\n\n    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n        super(BidirectionalGRU, self).__init__()\n\n        self.BiGRU = nn.GRU(\n            input_size=rnn_dim, hidden_size=hidden_size,\n            num_layers=1, batch_first=batch_first, bidirectional=True)\n        self.layer_norm = nn.LayerNorm(rnn_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        x = F.gelu(x)\n        x, _ = self.BiGRU(x)\n        x = self.dropout(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:15:23.753687Z","iopub.execute_input":"2024-05-26T04:15:23.754091Z","iopub.status.idle":"2024-05-26T04:15:23.766152Z","shell.execute_reply.started":"2024-05-26T04:15:23.754052Z","shell.execute_reply":"2024-05-26T04:15:23.764488Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Поменял там, где происходит загрузка, сохраняется id звукового файла, а потом в excel файле по колонке old_id ищется текст\n#И того звук и текст к нему\n\nimport pandas as pd\nimport librosa\n\nfile = pd.read_excel('/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches v1.xlsx')\n#y = [sentence for sentence in file['text']]\ny = []\ndir_name = \"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"\nfiles_in_dir = os.listdir(dir_name)\n\nX = []\ni = 1\n\nfor e in os.listdir(\"/kaggle/input/2700-audio/OneDrive-2023-12-25/Speeches/\"):\n    file_name = e\n    for old_id in range(0, 2073):\n        if file_name.startswith(str(file['old_id'][old_id]) + '.'):\n            y.extend([''.join(file['text'][old_id])])\n            sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n            sampl = sampl[np.newaxis, :]\n            X.append(torch.Tensor(sampl))\n            break","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:15:23.769353Z","iopub.execute_input":"2024-05-26T04:15:23.770011Z","iopub.status.idle":"2024-05-26T04:17:41.285241Z","shell.execute_reply.started":"2024-05-26T04:15:23.769967Z","shell.execute_reply":"2024-05-26T04:17:41.283611Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import random\npairs = list(zip(X, y))\nrandom.Random(3016).shuffle(pairs)\nX, y = zip(*pairs)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.287328Z","iopub.execute_input":"2024-05-26T04:17:41.288386Z","iopub.status.idle":"2024-05-26T04:17:41.303251Z","shell.execute_reply.started":"2024-05-26T04:17:41.288323Z","shell.execute_reply":"2024-05-26T04:17:41.301411Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y[:3]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.305794Z","iopub.execute_input":"2024-05-26T04:17:41.306395Z","iopub.status.idle":"2024-05-26T04:17:41.320851Z","shell.execute_reply.started":"2024-05-26T04:17:41.306333Z","shell.execute_reply":"2024-05-26T04:17:41.319064Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Разнообразие кухонных блюд', 'Секс', 'Жаркое лето вызывает жажду')"},"metadata":{}}]},{"cell_type":"code","source":"X[:3]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.323367Z","iopub.execute_input":"2024-05-26T04:17:41.323877Z","iopub.status.idle":"2024-05-26T04:17:41.357533Z","shell.execute_reply.started":"2024-05-26T04:17:41.323821Z","shell.execute_reply":"2024-05-26T04:17:41.356187Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 5.5877e-09,  1.6280e-09, -1.3302e-10,  ..., -2.2728e-05,\n          -2.2285e-05,  0.0000e+00]]),\n tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0042,  0.0015,  0.0000]]),\n tensor([[-5.1168e-06,  5.6805e-06, -2.0654e-05,  ...,  1.8661e-05,\n           9.8214e-06,  1.7692e-05]]))"},"metadata":{}}]},{"cell_type":"code","source":"torchaudio.save('/kaggle/working/audio.wav', X[540], 16000)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:52:46.826831Z","iopub.execute_input":"2024-04-02T14:52:46.827791Z","iopub.status.idle":"2024-04-02T14:52:46.834792Z","shell.execute_reply.started":"2024-04-02T14:52:46.827746Z","shell.execute_reply":"2024-04-02T14:52:46.833811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform, sample_rate = torchaudio.load('/kaggle/working/audio.wav')  # Загрузка аудиофайла\ntorchaudio.play(waveform, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:22:15.368540Z","iopub.execute_input":"2024-04-02T07:22:15.368969Z","iopub.status.idle":"2024-04-02T07:22:15.395250Z","shell.execute_reply.started":"2024-04-02T07:22:15.368930Z","shell.execute_reply":"2024-04-02T07:22:15.393666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n            \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n            \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n            \"я\": 31, \"х\": 32, \" \": 33}\n\ndef remove_characters(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.replace('4', 'четыре').replace('Р-220', 'р двести двадцать').replace('6', 'шесть').replace(\"-\", \" \")\n    sentence = ''.join(filter(lambda x: x in char_map, sentence))\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ny = list(map(remove_characters, y))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.362565Z","iopub.execute_input":"2024-05-26T04:17:41.363102Z","iopub.status.idle":"2024-05-26T04:17:41.404195Z","shell.execute_reply.started":"2024-05-26T04:17:41.363048Z","shell.execute_reply":"2024-05-26T04:17:41.402759Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = X[:2200]\nX_test = X[2200:]\ny_train = y[:2200]\ny_test = y[2200:]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.408324Z","iopub.execute_input":"2024-05-26T04:17:41.408817Z","iopub.status.idle":"2024-05-26T04:17:41.415458Z","shell.execute_reply.started":"2024-05-26T04:17:41.408772Z","shell.execute_reply":"2024-05-26T04:17:41.413999Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass AudioDataset(Dataset):\n    def __init__(self, audio_list, text_list):\n        self.audio_list = audio_list\n        self.text_list = text_list\n        \n    def __len__(self):\n        return len(self.text_list)\n    \n    def __getitem__(self, index):\n        audio = self.audio_list[index]\n        text = self.text_list[index]\n        return audio, text","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.417738Z","iopub.execute_input":"2024-05-26T04:17:41.418246Z","iopub.status.idle":"2024-05-26T04:17:41.428637Z","shell.execute_reply.started":"2024-05-26T04:17:41.418195Z","shell.execute_reply":"2024-05-26T04:17:41.427030Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class SpeechRecognitionModel1(nn.Module):\n    def __init__(self, num_classes):\n        super(SpeechRecognitionModel1, self).__init__()\n        self.conv = nn.Sequential(\n            nn.BatchNorm2d(1),\n            nn.Conv2d(1, 32, kernel_size=(4,4), stride=(3,3), padding=(2,2)),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n            nn.Conv2d(128, 128, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.GELU(),\n        )\n        \n        self.fc_1 = nn.Sequential(\n            nn.Linear(896, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n            nn.Linear(270, 270),\n            nn.LayerNorm(270),\n            nn.GELU(),\n        )\n        \n        self.BiGRU_1 = BidirectionalGRU(270, 270, 0, True)\n        self.BiGRU_2 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_3 = BidirectionalGRU(540, 270, 0, True)\n        self.BiGRU_4 = BidirectionalGRU(540, 270, 0.5, True)\n        \n        self.fc_2 = nn.Sequential(\n            nn.Linear(540, num_classes),\n        )\n        self.softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.view(x.size(0), x.size(1), -1)\n        x = self.fc_1(x)\n        x = self.BiGRU_1(x)\n        x = self.BiGRU_2(x)\n        x = self.BiGRU_3(x)\n        x = self.BiGRU_4(x)\n        x = self.fc_2(x)\n        x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.430501Z","iopub.execute_input":"2024-05-26T04:17:41.431546Z","iopub.status.idle":"2024-05-26T04:17:41.454002Z","shell.execute_reply.started":"2024-05-26T04:17:41.431427Z","shell.execute_reply":"2024-05-26T04:17:41.452499Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Зададим название выбронной модели из хаба\nMODEL_NAME = 'UrukHan/t5-russian-spell'\nMAX_INPUT = 256\n\n# Загрузка модели и токенизатора\ntokenizer = T5TokenizerFast.from_pretrained(MODEL_NAME)\ncorrector = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T13:52:10.590361Z","iopub.execute_input":"2024-05-25T13:52:10.590760Z","iopub.status.idle":"2024-05-25T13:52:36.615013Z","shell.execute_reply.started":"2024-05-25T13:52:10.590725Z","shell.execute_reply":"2024-05-25T13:52:36.613682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IterMeter(object):\n    def __init__(self):\n        self.val = 0\n\n    def step(self):\n        self.val += 1\n\n    def get(self):\n        return self.val\n\n\ndef train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n    model.train()\n    train_loss = 0\n    train_cer, train_wer = [], []\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data \n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms) \n        output = output.transpose(0, 1)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        train_loss += loss.item() / len(train_loader)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        iter_meter.step()\n        if batch_idx % 20 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n        \"\"\"decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n        for j in range(len(decoded_preds)):\n            train_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n            train_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n    avg_cer = sum(train_cer)/len(train_cer)\n    avg_wer = sum(train_wer)/len(train_wer)\n            \n    print('Train set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(train_loss, avg_cer, avg_wer))\"\"\"\n            \n    \n\ndef test(model, device, test_loader, criterion, epoch, iter_meter):\n    print('\\nevaluating...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data \n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n            \n            output = model(spectrograms)\n            output = output.transpose(0, 1)\n            \n            loss = criterion(output, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n            \n            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n            for j in range(len(decoded_preds)):\n                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n    \n   \n    avg_cer = sum(test_cer)/len(test_cer)\n    avg_wer = sum(test_wer)/len(test_wer)\n\n    median_cer = np.median(np.array(test_cer))\n    median_wer = np.median(np.array(test_wer))\n           \n    print('Test set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(test_loss, avg_cer, avg_wer, median_cer, median_wer))\n    \n\ndef main(learning_rate=5e-4, batch_size=20, epochs=10):\n\n    hparams = {\n        \"learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"epochs\": epochs\n    }\n\n    use_cuda = torch.cuda.is_available()\n    torch.manual_seed(7)\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    train_dataset = AudioDataset(X_train, y_train)\n    test_dataset = AudioDataset(X_test, y_test)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n    train_loader = data.DataLoader(dataset=train_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=True,\n                                collate_fn=lambda x: data_processing(x, 'train'),\n                                **kwargs)\n    test_loader = data.DataLoader(dataset=test_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=False,\n                                collate_fn=lambda x: data_processing(x, 'valid'),\n                                **kwargs)\n\n    model = SpeechRecognitionModel1(35).to(device)\n\n    print(model)\n    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n\n    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n    criterion = nn.CTCLoss(blank=34).to(device)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\n    \n    iter_meter = IterMeter()\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n        test(model, device, test_loader, criterion, epoch, iter_meter)\n        \n    torch.save(model, '/kaggle/working/model_for_correction_test.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.458737Z","iopub.execute_input":"2024-05-26T04:17:41.459158Z","iopub.status.idle":"2024-05-26T04:17:41.500996Z","shell.execute_reply.started":"2024-05-26T04:17:41.459117Z","shell.execute_reply":"2024-05-26T04:17:41.499236Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict(model, file_name, device):\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    sampl = librosa.load(file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    print(spectrogram_tensor.size())\n\n    with torch.no_grad():\n        spectrogram_tensor.to(device)\n        output = model(spectrogram_tensor)\n        print(output.size())\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n\n    return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.503506Z","iopub.execute_input":"2024-05-26T04:17:41.504085Z","iopub.status.idle":"2024-05-26T04:17:41.521630Z","shell.execute_reply.started":"2024-05-26T04:17:41.504024Z","shell.execute_reply":"2024-05-26T04:17:41.520066Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#накрутить сюда корректор ошибок, обучение без него\ndef predict_with_tensor(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    #sampl = librosa.load(file_name, sr=16000)[0]\n    #sampl = sampl[np.newaxis, :]\n    #sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    #print(decodes[0])        \n    input_sequences = decodes[0]\n                \n    task_prefix = \"Spell correct: \"\n\n    if type(input_sequences) != list: input_sequences = [input_sequences]\n    encoded = tokenizer(\n      [task_prefix + sequence for sequence in input_sequences],\n      padding=\"longest\",\n      max_length=MAX_INPUT,\n      truncation=True,\n      return_tensors=\"pt\",\n    )\n\n    predicts = corrector.generate(**encoded.to(needed_device))   # # Прогнозирование\n\n    input_sequences = tokenizer.batch_decode(predicts, skip_special_tokens=True)[0]\n    input_sequences = remove_characters(input_sequences)\n\n    return input_sequences\n\n    #return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.526273Z","iopub.execute_input":"2024-05-26T04:17:41.526696Z","iopub.status.idle":"2024-05-26T04:17:41.542630Z","shell.execute_reply.started":"2024-05-26T04:17:41.526653Z","shell.execute_reply":"2024-05-26T04:17:41.541047Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import hunspell\nimport os\n\n#пробуем hunspell для исправления ошибок\ndef load_hunspell_russian_dict():\n    dict_path = \"/kaggle/input/dop-test-files\"  \n    \n    ru_dic = os.path.join(dict_path, \"ru_RU_big.dic\")\n    ru_aff = os.path.join(dict_path, \"ru_RU_big.aff\")\n    \n    # Create Hunspell instance for Russian\n    hunspell_instance = hunspell.HunSpell(ru_dic, ru_aff)\n    return hunspell_instance\n\ndef correct_mistakes(text, hunspell_instance):\n    corrected_text = []\n    words = text.split()\n    \n    for word in words:\n        if hunspell_instance.spell(word):\n            corrected_text.append(word)\n        else:\n            suggestions = hunspell_instance.suggest(word)\n            if suggestions:\n                corrected_text.append(suggestions[0])  # Choose the first suggestion\n            else:\n                corrected_text.append(word)  # No suggestion, keep the original word\n    \n    return \" \".join(corrected_text)\n\n# Example usage\nhunspell_instance = load_hunspell_russian_dict()\n#text = \"Привет, как дила?\"\n#corrected_text = correct_mistakes(text, hunspell_instance)\n#print(corrected_text)\n\ndef predict_with_tensor_v2(model, sampl):\n    needed_device = torch.device(\"cpu\")\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    with torch.no_grad():\n        spectrogram_tensor.to(needed_device)\n        output = model(spectrogram_tensor)\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n            \n    #print(decodes[0])        \n    corrected_output = correct_mistakes(decodes[0], hunspell_instance)\n\n    #return decodes[0]\n    return corrected_output","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.545188Z","iopub.execute_input":"2024-05-26T04:17:41.545715Z","iopub.status.idle":"2024-05-26T04:17:41.741169Z","shell.execute_reply.started":"2024-05-26T04:17:41.545662Z","shell.execute_reply":"2024-05-26T04:17:41.740055Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%time \nlearning_rate = 0.002\nbatch_size = 20\nepochs = 160\n\nmain(learning_rate, batch_size, epochs)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-25T13:52:43.227009Z","iopub.execute_input":"2024-05-25T13:52:43.228156Z","iopub.status.idle":"2024-05-25T15:23:54.890018Z","shell.execute_reply.started":"2024-05-25T13:52:43.228083Z","shell.execute_reply":"2024-05-25T15:23:54.888635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use_cuda = torch.cuda.is_available()\n#device = torch.device(\"cpu\")\nneeded_device = torch.device(\"cpu\")\nmodel = torch.load('/kaggle/input/dop-test-files/model_for_making_dataset_v7(3016).pt', map_location=torch.device('cpu'))\n\n#1543 1882 1372\n\nmodel.to(needed_device)\nprint(needed_device)\n#predict(model, '/kaggle/input/upd-speech/mono_voice/1964.wav', device)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.742766Z","iopub.execute_input":"2024-05-26T04:17:41.743182Z","iopub.status.idle":"2024-05-26T04:17:41.996611Z","shell.execute_reply.started":"2024-05-26T04:17:41.743142Z","shell.execute_reply":"2024-05-26T04:17:41.994992Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"d = {'X_test': X_test, 'label': y_test}\ndf_test = pd.DataFrame(data=d)\ndf_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:41.998094Z","iopub.execute_input":"2024-05-26T04:17:41.998687Z","iopub.status.idle":"2024-05-26T04:17:51.083467Z","shell.execute_reply.started":"2024-05-26T04:17:41.998647Z","shell.execute_reply":"2024-05-26T04:17:51.082064Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                              X_test  \\\n0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n1  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n2  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n3  [[tensor(2.0789e-06), tensor(-3.5355e-06), ten...   \n4  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n\n                                label  \n0                            отмечать  \n1   тапки не стоит оставлять на улице  \n2                              зверёк  \n3                    любовь к природе  \n4  вселенная бесконечна действительно  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_test</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>отмечать</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>тапки не стоит оставлять на улице</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>зверёк</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[tensor(2.0789e-06), tensor(-3.5355e-06), ten...</td>\n      <td>любовь к природе</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>вселенная бесконечна действительно</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.085635Z","iopub.execute_input":"2024-05-26T04:17:51.086168Z","iopub.status.idle":"2024-05-26T04:17:51.094498Z","shell.execute_reply.started":"2024-05-26T04:17:51.086116Z","shell.execute_reply":"2024-05-26T04:17:51.093194Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['отмечать',\n 'тапки не стоит оставлять на улице',\n 'зверёк',\n 'любовь к природе',\n 'вселенная бесконечна действительно']"},"metadata":{}}]},{"cell_type":"code","source":"def count_test_cer(row, model):\n    prediction = predict_with_tensor_v2(model, row['X_test'])\n    return cer(row['label'], prediction)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.099695Z","iopub.execute_input":"2024-05-26T04:17:51.100268Z","iopub.status.idle":"2024-05-26T04:17:51.106727Z","shell.execute_reply.started":"2024-05-26T04:17:51.100225Z","shell.execute_reply":"2024-05-26T04:17:51.105456Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def count_test_wer(row, model):\n    prediction = predict_with_tensor_v2(model, row['X_test'])\n    return wer(row['label'], prediction)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.108189Z","iopub.execute_input":"2024-05-26T04:17:51.108568Z","iopub.status.idle":"2024-05-26T04:17:51.120213Z","shell.execute_reply.started":"2024-05-26T04:17:51.108530Z","shell.execute_reply":"2024-05-26T04:17:51.118791Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def write_preds(row, model):\n    return predict_with_tensor_v2(model, row['X_test'])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.121480Z","iopub.execute_input":"2024-05-26T04:17:51.121846Z","iopub.status.idle":"2024-05-26T04:17:51.133747Z","shell.execute_reply.started":"2024-05-26T04:17:51.121800Z","shell.execute_reply":"2024-05-26T04:17:51.132140Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_test['CER'] = df_test.apply(count_test_cer, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:17:51.135252Z","iopub.execute_input":"2024-05-26T04:17:51.135630Z","iopub.status.idle":"2024-05-26T04:20:18.237700Z","shell.execute_reply.started":"2024-05-26T04:17:51.135592Z","shell.execute_reply":"2024-05-26T04:20:18.235582Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:572: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test['WER'] = df_test.apply(count_test_wer, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:20:18.240879Z","iopub.execute_input":"2024-05-26T04:20:18.241567Z","iopub.status.idle":"2024-05-26T04:22:37.380675Z","shell.execute_reply.started":"2024-05-26T04:20:18.241502Z","shell.execute_reply":"2024-05-26T04:22:37.379257Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_test['preds'] = df_test.apply(write_preds, axis=1, model = model)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:22:37.382399Z","iopub.execute_input":"2024-05-26T04:22:37.382791Z","iopub.status.idle":"2024-05-26T04:24:56.562000Z","shell.execute_reply.started":"2024-05-26T04:22:37.382752Z","shell.execute_reply":"2024-05-26T04:24:56.560548Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_test.loc[df_test['CER'] > 0]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:24:56.564034Z","iopub.execute_input":"2024-05-26T04:24:56.564688Z","iopub.status.idle":"2024-05-26T04:25:07.553845Z","shell.execute_reply.started":"2024-05-26T04:24:56.564626Z","shell.execute_reply":"2024-05-26T04:25:07.552232Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                                X_test  \\\n1    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n2    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n3    [[tensor(2.0789e-06), tensor(-3.5355e-06), ten...   \n4    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n5    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n..                                                 ...   \n592  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n593  [[tensor(4.6664e-06), tensor(-2.2184e-05), ten...   \n594  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n595  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n596  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n\n                                      label       CER       WER  \\\n1         тапки не стоит оставлять на улице  0.151515  0.500000   \n2                                    зверёк  0.166667  1.000000   \n3                          любовь к природе  0.312500  0.666667   \n4        вселенная бесконечна действительно  0.029412  0.333333   \n5               поворот к парку развлечений  0.222222  0.500000   \n..                                      ...       ...       ...   \n592       там начальство всё время меняется  0.030303  0.200000   \n593  улыбка залог успеха в любых начинаниях  0.526316  1.000000   \n594                  тонкие линии на бумаге  0.090909  0.750000   \n595  по коже и волосам видно всё о человеке  0.157895  0.625000   \n596                          темная комната  0.071429  0.500000   \n\n                                   preds  \n1       тапке не соти оставлять на улицы  \n2                                 зверок  \n3                         любовь периоды  \n4     вселенная бесконечно действительно  \n5              повадка парку развлечений  \n..                                   ...  \n592    там начальство все время меняется  \n593        лыка зелу узка нахлобучивания  \n594                тонкие лини на б маге  \n595  покое и волосам видно все чело веке  \n596                       томная комната  \n\n[479 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_test</th>\n      <th>label</th>\n      <th>CER</th>\n      <th>WER</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>тапки не стоит оставлять на улице</td>\n      <td>0.151515</td>\n      <td>0.500000</td>\n      <td>тапке не соти оставлять на улицы</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>зверёк</td>\n      <td>0.166667</td>\n      <td>1.000000</td>\n      <td>зверок</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[tensor(2.0789e-06), tensor(-3.5355e-06), ten...</td>\n      <td>любовь к природе</td>\n      <td>0.312500</td>\n      <td>0.666667</td>\n      <td>любовь периоды</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>вселенная бесконечна действительно</td>\n      <td>0.029412</td>\n      <td>0.333333</td>\n      <td>вселенная бесконечно действительно</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>поворот к парку развлечений</td>\n      <td>0.222222</td>\n      <td>0.500000</td>\n      <td>повадка парку развлечений</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>там начальство всё время меняется</td>\n      <td>0.030303</td>\n      <td>0.200000</td>\n      <td>там начальство все время меняется</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>[[tensor(4.6664e-06), tensor(-2.2184e-05), ten...</td>\n      <td>улыбка залог успеха в любых начинаниях</td>\n      <td>0.526316</td>\n      <td>1.000000</td>\n      <td>лыка зелу узка нахлобучивания</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>тонкие линии на бумаге</td>\n      <td>0.090909</td>\n      <td>0.750000</td>\n      <td>тонкие лини на б маге</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>по коже и волосам видно всё о человеке</td>\n      <td>0.157895</td>\n      <td>0.625000</td>\n      <td>покое и волосам видно все чело веке</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>темная комната</td>\n      <td>0.071429</td>\n      <td>0.500000</td>\n      <td>томная комната</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:02:33.631301Z","iopub.execute_input":"2024-05-26T04:02:33.631663Z","iopub.status.idle":"2024-05-26T04:02:43.652722Z","shell.execute_reply.started":"2024-05-26T04:02:33.631628Z","shell.execute_reply":"2024-05-26T04:02:43.651458Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                X_test  \\\n0    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n1    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n2    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n3    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n4    [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n..                                                 ...   \n592  [[tensor(-7.3563e-07), tensor(-7.0477e-07), te...   \n593  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n594  [[tensor(-8.3037e-10), tensor(-9.6717e-10), te...   \n595  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n596  [[tensor(1.1508e-06), tensor(-5.9944e-07), ten...   \n\n                                         label       CER    WER  \\\n0             незабываемое путешествие на море  0.031250  0.500   \n1                   красивый закат над океаном  0.038462  0.250   \n2                                    водоросли  0.666667  1.000   \n3    картина человека с отслеживающими глазами  0.341463  0.800   \n4     тело то здорово а что делать с остальным  0.125000  0.375   \n..                                         ...       ...    ...   \n592                                      успех  0.600000  1.000   \n593                           дорога перекрыта  0.000000  0.000   \n594                  на улице бессмысленно все  0.040000  0.250   \n595                 путь наш лежит за горизонт  0.038462  0.200   \n596                               серый костюм  0.250000  1.000   \n\n                                        preds  \n0           не забываемое путешествие на море  \n1                  красивый закат нал океаном  \n2                              водораспыление  \n3    карт человеко-час оттесывая щеми глазами  \n4        тела то здорово что дела с остальным  \n..                                        ...  \n592                                    пустее  \n593                          дорога перекрыта  \n594                 на улице бессмысленно вся  \n595                 пут наш лежит за горизонт  \n596                             серый кос туб  \n\n[597 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_test</th>\n      <th>label</th>\n      <th>CER</th>\n      <th>WER</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>незабываемое путешествие на море</td>\n      <td>0.031250</td>\n      <td>0.500</td>\n      <td>не забываемое путешествие на море</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>красивый закат над океаном</td>\n      <td>0.038462</td>\n      <td>0.250</td>\n      <td>красивый закат нал океаном</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>водоросли</td>\n      <td>0.666667</td>\n      <td>1.000</td>\n      <td>водораспыление</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>картина человека с отслеживающими глазами</td>\n      <td>0.341463</td>\n      <td>0.800</td>\n      <td>карт человеко-час оттесывая щеми глазами</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>тело то здорово а что делать с остальным</td>\n      <td>0.125000</td>\n      <td>0.375</td>\n      <td>тела то здорово что дела с остальным</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>[[tensor(-7.3563e-07), tensor(-7.0477e-07), te...</td>\n      <td>успех</td>\n      <td>0.600000</td>\n      <td>1.000</td>\n      <td>пустее</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>дорога перекрыта</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>дорога перекрыта</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>[[tensor(-8.3037e-10), tensor(-9.6717e-10), te...</td>\n      <td>на улице бессмысленно все</td>\n      <td>0.040000</td>\n      <td>0.250</td>\n      <td>на улице бессмысленно вся</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n      <td>путь наш лежит за горизонт</td>\n      <td>0.038462</td>\n      <td>0.200</td>\n      <td>пут наш лежит за горизонт</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>[[tensor(1.1508e-06), tensor(-5.9944e-07), ten...</td>\n      <td>серый костюм</td>\n      <td>0.250000</td>\n      <td>1.000</td>\n      <td>серый кос туб</td>\n    </tr>\n  </tbody>\n</table>\n<p>597 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ИСПОЛЬЗОВАЛ МАЛЫЙ СЛОВАРЬ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model(3024_seed_data).pt with hunspell. WITHOUT HUNSPELL: CER = Average CER: 0.166791 Average WER: 0.6451","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['CER'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:04:49.056490Z","iopub.execute_input":"2024-05-25T16:04:49.057082Z","iopub.status.idle":"2024-05-25T16:04:49.065840Z","shell.execute_reply.started":"2024-05-25T16:04:49.057036Z","shell.execute_reply":"2024-05-25T16:04:49.064572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['WER'].mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:04:51.749217Z","iopub.execute_input":"2024-05-25T16:04:51.750349Z","iopub.status.idle":"2024-05-25T16:04:51.757655Z","shell.execute_reply.started":"2024-05-25T16:04:51.750300Z","shell.execute_reply":"2024-05-25T16:04:51.756495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v4(1242).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:19:41.442613Z","iopub.execute_input":"2024-05-25T16:19:41.443296Z","iopub.status.idle":"2024-05-25T16:19:41.455403Z","shell.execute_reply.started":"2024-05-25T16:19:41.443235Z","shell.execute_reply":"2024-05-25T16:19:41.452786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v5(2204).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:37:13.375118Z","iopub.execute_input":"2024-05-25T16:37:13.375680Z","iopub.status.idle":"2024-05-25T16:37:13.386340Z","shell.execute_reply.started":"2024-05-25T16:37:13.375629Z","shell.execute_reply":"2024-05-25T16:37:13.384681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v6(20024).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:49:05.441566Z","iopub.execute_input":"2024-05-25T16:49:05.442097Z","iopub.status.idle":"2024-05-25T16:49:05.451177Z","shell.execute_reply.started":"2024-05-25T16:49:05.442048Z","shell.execute_reply":"2024-05-25T16:49:05.449638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v7(3016).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:59:36.002854Z","iopub.execute_input":"2024-05-25T16:59:36.004626Z","iopub.status.idle":"2024-05-25T16:59:36.014691Z","shell.execute_reply.started":"2024-05-25T16:59:36.004549Z","shell.execute_reply":"2024-05-25T16:59:36.012949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ДАЛЕЕ ИСПОЛЬЗУЕТСЯ БОЛЬШИЙ СЛОВАРЬ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v4(1242).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-25T17:22:32.461589Z","iopub.execute_input":"2024-05-25T17:22:32.462082Z","iopub.status.idle":"2024-05-25T17:22:32.471480Z","shell.execute_reply.started":"2024-05-25T17:22:32.462038Z","shell.execute_reply":"2024-05-25T17:22:32.469970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using model_for_making_dataset_v5(2204).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:03:18.899437Z","iopub.execute_input":"2024-05-26T04:03:18.900728Z","iopub.status.idle":"2024-05-26T04:03:18.909759Z","shell.execute_reply.started":"2024-05-26T04:03:18.900673Z","shell.execute_reply":"2024-05-26T04:03:18.908456Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"CER:  0.22032562029369046\nWER:  0.5630099753215332\n","output_type":"stream"}]},{"cell_type":"code","source":"#using model_for_making_dataset_v6(20024).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:14:20.150015Z","iopub.execute_input":"2024-05-26T04:14:20.150512Z","iopub.status.idle":"2024-05-26T04:14:20.160144Z","shell.execute_reply.started":"2024-05-26T04:14:20.150466Z","shell.execute_reply":"2024-05-26T04:14:20.158071Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CER:  0.2183401687348701\nWER:  0.5742835565699888\n","output_type":"stream"}]},{"cell_type":"code","source":"#using model_for_making_dataset_v7(3016).pt with hunspell. WITHOUT HUNSPELL: Average CER ~ 0.16 Average WER ~ 0.64\nprint('CER: ', df_test['CER'].mean())\nprint('WER: ', df_test['WER'].mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:25:27.601745Z","iopub.execute_input":"2024-05-26T04:25:27.602257Z","iopub.status.idle":"2024-05-26T04:25:27.611942Z","shell.execute_reply.started":"2024-05-26T04:25:27.602207Z","shell.execute_reply":"2024-05-26T04:25:27.610181Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CER:  0.20849510905259327\nWER:  0.5569558349709104\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2023-05-24T10:26:24.339488Z","iopub.execute_input":"2023-05-24T10:26:24.340405Z","iopub.status.idle":"2023-05-24T10:26:24.350954Z","shell.execute_reply.started":"2023-05-24T10:26:24.340364Z","shell.execute_reply":"2023-05-24T10:26:24.349831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:16:11.401175Z","iopub.execute_input":"2023-05-13T16:16:11.401879Z","iopub.status.idle":"2023-05-13T16:16:11.430020Z","shell.execute_reply.started":"2023-05-13T16:16:11.401838Z","shell.execute_reply":"2023-05-13T16:16:11.428960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(directory):\n    total_duration = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            filepath = os.path.join(directory, filename)\n            with wave.open(filepath, 'r') as wav_file:\n                frames = wav_file.getnframes()\n                rate = wav_file.getframerate()\n                duration = frames / float(rate)\n                total_duration += duration\n    return total_duration\n\ndirectory = '/kaggle/input/upd-speech/mono_voice'\ntotal_duration = get_wav_duration(directory)\nprint('Total duration of WAV files:', total_duration, 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:15.415086Z","iopub.execute_input":"2023-07-05T10:09:15.415876Z","iopub.status.idle":"2023-07-05T10:09:18.755936Z","shell.execute_reply.started":"2023-07-05T10:09:15.415836Z","shell.execute_reply":"2023-07-05T10:09:18.754693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))\nseconds = 3661\nformatted_time = format_time(total_duration)\nprint(formatted_time)  # Output: '01:01:01'","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:23.353548Z","iopub.execute_input":"2023-07-05T10:09:23.354296Z","iopub.status.idle":"2023-07-05T10:09:23.361628Z","shell.execute_reply.started":"2023-07-05T10:09:23.354254Z","shell.execute_reply":"2023-07-05T10:09:23.360431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}