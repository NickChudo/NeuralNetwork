{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np \nimport matplotlib","metadata":{"execution":{"iopub.status.busy":"2023-07-03T14:07:07.812300Z","iopub.execute_input":"2023-07-03T14:07:07.813176Z","iopub.status.idle":"2023-07-03T14:07:13.012269Z","shell.execute_reply.started":"2023-07-03T14:07:07.813131Z","shell.execute_reply":"2023-07-03T14:07:13.010733Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def avg_wer(wer_scores, combined_ref_len):\n    return float(sum(wer_scores)) / float(combined_ref_len)\n\n\ndef _levenshtein_distance(ref, hyp):\n    m = len(ref)\n    n = len(hyp)\n\n    # special case\n    if ref == hyp:\n        return 0\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n\n    if m < n:\n        ref, hyp = hyp, ref\n        m, n = n, m\n\n    distance = np.zeros((2, n + 1), dtype=np.int32)\n\n    for j in range(0,n + 1):\n        distance[0][j] = j\n\n    for i in range(1, m + 1):\n        prev_row_idx = (i - 1) % 2\n        cur_row_idx = i % 2\n        distance[cur_row_idx][0] = i\n        for j in range(1, n + 1):\n            if ref[i - 1] == hyp[j - 1]:\n                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n            else:\n                s_num = distance[prev_row_idx][j - 1] + 1\n                i_num = distance[cur_row_idx][j - 1] + 1\n                d_num = distance[prev_row_idx][j] + 1\n                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n\n    return distance[m % 2][n]\n\n\ndef word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    ref_words = reference.split(delimiter)\n    hyp_words = hypothesis.split(delimiter)\n\n    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n    return float(edit_distance), len(ref_words)\n\n\ndef char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n    if ignore_case == True:\n        reference = reference.lower()\n        hypothesis = hypothesis.lower()\n\n    join_char = ' '\n    if remove_space == True:\n        join_char = ''\n\n    reference = join_char.join(filter(None, reference.split(' ')))\n    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n\n    edit_distance = _levenshtein_distance(reference, hypothesis)\n    return float(edit_distance), len(reference)\n\n\ndef wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n                                         delimiter)\n\n    if ref_len == 0:\n        raise ValueError(\"Reference's word number should be greater than 0.\")\n\n    wer = float(edit_distance) / ref_len\n    return wer\n\n\ndef cer(reference, hypothesis, ignore_case=False, remove_space=False):\n    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n                                         remove_space)\n\n    if ref_len == 0:\n        raise ValueError(\"Length of reference should be greater than 0.\")\n\n    cer = float(edit_distance) / ref_len\n    return cer\n\nclass TextTransform:\n    def __init__(self):\n        self.char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n                  \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n                  \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n                  \"я\": 31, \"х\": 32, \" \": 33}\n\n        self.index_map = {}\n        for key, value in self.char_map.items():\n            self.index_map[value] = key\n\n    def text_to_int(self, text):\n        int_sequence = []\n        for c in text:\n            ch = self.char_map[c]\n            int_sequence.append(ch)\n        return int_sequence\n\n    def int_to_text(self, labels):\n        string = []\n        for i in labels:\n            string.append(self.index_map[i])\n        return ''.join(string)\n\n\ntrain_audio_transforms = nn.Sequential(\n    torchaudio.transforms.MFCC(n_mfcc=20)\n)\n\nvalid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n\ntext_transform = TextTransform()\n\ndef data_processing(data, data_type=\"train\"):\n    spectrograms = []\n    labels = []\n    input_lengths = []\n    label_lengths = []\n    for (waveform, utterance) in data:\n        if data_type == 'train':\n            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        elif data_type == 'valid':\n            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n        else:\n            raise Exception('data_type should be train or valid')\n        spectrograms.append(spec)\n        label = torch.Tensor(text_transform.text_to_int(utterance))\n        labels.append(label)\n        input_lengths.append(spec.shape[0]//3)\n        label_lengths.append(len(label))\n    \n    spectrograms1 = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n            \n    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n\n    return spectrograms1, labels, input_lengths, label_lengths\n\n\ndef GreedyDecoder(output, labels, label_lengths, blank_label=34, collapse_repeated=True):\n    arg_maxes = torch.argmax(output, dim=2)\n    decodes = []\n    targets = []\n    for i, args in enumerate(arg_maxes):\n        decode = []\n        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n        for j, index in enumerate(args):\n            if index != blank_label:\n                if collapse_repeated and j != 0 and index == args[j -1]:\n                    continue\n                decode.append(index.item())\n        decodes.append(text_transform.int_to_text(decode))\n    return decodes, targets","metadata":{"execution":{"iopub.status.busy":"2023-07-03T16:02:53.951384Z","iopub.execute_input":"2023-07-03T16:02:53.951827Z","iopub.status.idle":"2023-07-03T16:02:53.998146Z","shell.execute_reply.started":"2023-07-03T16:02:53.951786Z","shell.execute_reply":"2023-07-03T16:02:53.996854Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"class BidirectionalGRU(nn.Module):\n\n    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n        super(BidirectionalGRU, self).__init__()\n\n        self.BiGRU = nn.GRU(\n            input_size=rnn_dim, hidden_size=hidden_size,\n            num_layers=1, batch_first=batch_first, bidirectional=True)\n        self.layer_norm = nn.LayerNorm(rnn_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.layer_norm(x)\n        x = F.gelu(x)\n        x, _ = self.BiGRU(x)\n        x = self.dropout(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:05.794932Z","iopub.execute_input":"2023-07-03T15:00:05.795372Z","iopub.status.idle":"2023-07-03T15:00:05.804988Z","shell.execute_reply.started":"2023-07-03T15:00:05.795331Z","shell.execute_reply":"2023-07-03T15:00:05.803543Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport librosa\n\nfile = pd.read_excel('/kaggle/input/rus-speech/Speeches.xlsx')\ny = [sentence for sentence in file['Русская речь']]\n\ndir_name = \"/kaggle/input/upd-speech/mono_voice/\"\nfiles_in_dir = os.listdir(dir_name)\n\nX = []\ni = 1\n\nfor e in range(1, 2001):\n    file_name = f'{e}.wav'\n    sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    X.append(torch.Tensor(sampl))\n    if i % 100 == 0:\n        print(i)\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:10.481853Z","iopub.execute_input":"2023-07-03T15:00:10.482480Z","iopub.status.idle":"2023-07-03T15:00:18.150369Z","shell.execute_reply.started":"2023-07-03T15:00:10.482437Z","shell.execute_reply":"2023-07-03T15:00:18.149002Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n","output_type":"stream"}]},{"cell_type":"code","source":"X[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:18.153364Z","iopub.execute_input":"2023-07-03T15:00:18.154249Z","iopub.status.idle":"2023-07-03T15:00:18.163191Z","shell.execute_reply.started":"2023-07-03T15:00:18.154202Z","shell.execute_reply":"2023-07-03T15:00:18.161886Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 79872])"},"metadata":{}}]},{"cell_type":"code","source":"char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n            \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n            \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n            \"я\": 31, \"х\": 32, \" \": 33}\n\ndef remove_characters(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.replace('4', 'четыре').replace('Р-220', 'р двести двадцать').replace('6', 'шесть').replace(\"-\", \" \")\n    sentence = ''.join(filter(lambda x: x in char_map, sentence))\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ny = list(map(remove_characters, y))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:20.607881Z","iopub.execute_input":"2023-07-03T15:00:20.608747Z","iopub.status.idle":"2023-07-03T15:00:20.637399Z","shell.execute_reply.started":"2023-07-03T15:00:20.608698Z","shell.execute_reply":"2023-07-03T15:00:20.636332Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nX_train = X[:1800]\nX_test = X[1800:]\ny_train = y[:1800]\ny_test = y[1800:]","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:21.244411Z","iopub.execute_input":"2023-07-03T15:00:21.244827Z","iopub.status.idle":"2023-07-03T15:00:21.250946Z","shell.execute_reply.started":"2023-07-03T15:00:21.244789Z","shell.execute_reply":"2023-07-03T15:00:21.249719Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass AudioDataset(Dataset):\n    def __init__(self, audio_list, text_list):\n        self.audio_list = audio_list\n        self.text_list = text_list\n        \n    def __len__(self):\n        return len(self.text_list)\n    \n    def __getitem__(self, index):\n        audio = self.audio_list[index]\n        text = self.text_list[index]\n        return audio, text","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:00:23.021239Z","iopub.execute_input":"2023-07-03T15:00:23.022228Z","iopub.status.idle":"2023-07-03T15:00:23.030274Z","shell.execute_reply.started":"2023-07-03T15:00:23.022172Z","shell.execute_reply":"2023-07-03T15:00:23.029001Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class SpeechRecognitionModel1(nn.Module):\n    def __init__(self, num_classes):\n        super(SpeechRecognitionModel1, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=(4,4), stride=(3,3), padding=(2,2)),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(64),\n            nn.GELU(),\n            nn.Conv2d(64, 32, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n        )\n        \n        self.BiGRU_1 = BidirectionalGRU(224, 400, 0.5, True)\n        self.BiGRU_2 = BidirectionalGRU(800, 400, 0.5, True)\n        self.BiGRU_3 = BidirectionalGRU(800, 400, 0.5, True)\n        \n        self.fc = nn.Sequential(\n            nn.Linear(800, num_classes),\n        )\n        self.softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.permute(0, 3, 1, 2)\n        x = x.view(x.size(0), x.size(1), -1)\n        x = self.BiGRU_1(x)\n        x = self.BiGRU_2(x)\n        x = self.BiGRU_3(x)\n        x = self.fc(x)\n        x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-03T16:15:53.415389Z","iopub.execute_input":"2023-07-03T16:15:53.415841Z","iopub.status.idle":"2023-07-03T16:15:53.432317Z","shell.execute_reply.started":"2023-07-03T16:15:53.415800Z","shell.execute_reply":"2023-07-03T16:15:53.430684Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"class IterMeter(object):\n    def __init__(self):\n        self.val = 0\n\n    def step(self):\n        self.val += 1\n\n    def get(self):\n        return self.val\n\n\ndef train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n    model.train()\n    train_loss = 0\n    train_cer, train_wer = [], []\n    data_len = len(train_loader.dataset)\n    for batch_idx, _data in enumerate(train_loader):\n        spectrograms, labels, input_lengths, label_lengths = _data \n        spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(spectrograms) \n        output = output.transpose(0, 1)\n\n        loss = criterion(output, labels, input_lengths, label_lengths)\n        train_loss += loss.item() / len(train_loader)\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()\n        iter_meter.step()\n        if batch_idx % 20 == 0 or batch_idx == data_len:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(spectrograms), data_len,\n                100. * batch_idx / len(train_loader), loss.item()))\n            \n        #decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n        \"\"\"for j in range(len(decoded_preds)):\n            train_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n            train_wer.append(wer(decoded_targets[j], decoded_preds[j]))\"\"\"\n    \n    #avg_cer = sum(train_cer)/len(train_cer)\n    #avg_wer = sum(train_wer)/len(train_wer)\n    \n    \n            \n    #print('Train set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          #.format(train_loss, avg_cer, avg_wer, median_cer, median_wer))\n            \n    \n\ndef test(model, device, test_loader, criterion, epoch, iter_meter):\n    print('\\nevaluating...')\n    model.eval()\n    test_loss = 0\n    test_cer, test_wer = [], []\n    with torch.no_grad():\n        for i, _data in enumerate(test_loader):\n            spectrograms, labels, input_lengths, label_lengths = _data \n            spectrograms, labels = spectrograms.to(device), labels.to(device)\n\n            output = model(spectrograms)\n            output = output.transpose(0, 1)\n\n            loss = criterion(output, labels, input_lengths, label_lengths)\n            test_loss += loss.item() / len(test_loader)\n\n            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n            for j in range(len(decoded_preds)):\n                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n\n\n    avg_cer = sum(test_cer)/len(test_cer)\n    avg_wer = sum(test_wer)/len(test_wer)\n\n    median_cer = np.median(np.array(test_cer))\n    median_wer = np.median(np.array(test_wer))\n           \n    print('Test set:\\tAverage loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'\n          .format(test_loss, avg_cer, avg_wer, median_cer, median_wer))\n    \n\ndef main(learning_rate=5e-4, batch_size=20, epochs=10):\n\n    hparams = {\n        \"learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"epochs\": epochs\n    }\n\n    use_cuda = torch.cuda.is_available()\n    torch.manual_seed(7)\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    train_dataset = AudioDataset(X_train, y_train)\n    test_dataset = AudioDataset(X_test, y_test)\n\n    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n    train_loader = data.DataLoader(dataset=train_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=True,\n                                collate_fn=lambda x: data_processing(x, 'train'),\n                                **kwargs)\n    test_loader = data.DataLoader(dataset=test_dataset,\n                                batch_size=hparams['batch_size'],\n                                shuffle=False,\n                                collate_fn=lambda x: data_processing(x, 'valid'),\n                                **kwargs)\n\n    model = SpeechRecognitionModel1(35).to(device)\n\n    print(model)\n    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n\n    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n    criterion = nn.CTCLoss(blank=34).to(device)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n                                            steps_per_epoch=int(len(train_loader)),\n                                            epochs=hparams['epochs'],\n                                            anneal_strategy='linear')\n    \n    iter_meter = IterMeter()\n    for epoch in range(1, epochs + 1):\n        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n        test(model, device, test_loader, criterion, epoch, iter_meter)\n        \n    torch.save(model, '/kaggle/working/model.pt')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:41:20.679337Z","iopub.execute_input":"2023-07-03T15:41:20.679832Z","iopub.status.idle":"2023-07-03T15:41:20.714925Z","shell.execute_reply.started":"2023-07-03T15:41:20.679788Z","shell.execute_reply":"2023-07-03T15:41:20.713729Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def predict(model, file_name, device):\n    model.eval()\n    spectro = []\n    valid_audio_transforms = torchaudio.transforms.MFCC(n_mfcc=20)\n    \n    sampl = librosa.load(file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    sampl = torch.Tensor(sampl)\n    spectr = valid_audio_transforms(sampl).squeeze(0)\n    spectrogram_tensor = spectr.unsqueeze(0).unsqueeze(0)\n    \n    print(spectrogram_tensor.size())\n\n    with torch.no_grad():\n        spectrogram_tensor.to(device)\n        output = model(spectrogram_tensor)\n        print(output.size())\n        \n        arg_maxes = torch.argmax(output, dim=2)\n        decodes = []\n        for i, args in enumerate(arg_maxes):\n            decode = []\n            for j, index in enumerate(args):\n                if index != 34:\n                    if True and j != 0 and index == args[j -1]:\n                        continue\n                    decode.append(index.item())\n            decodes.append(text_transform.int_to_text(decode))\n\n    return decodes[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-03T15:41:21.239452Z","iopub.execute_input":"2023-07-03T15:41:21.239858Z","iopub.status.idle":"2023-07-03T15:41:21.253192Z","shell.execute_reply.started":"2023-07-03T15:41:21.239819Z","shell.execute_reply":"2023-07-03T15:41:21.251856Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"%%time \nlearning_rate = 0.0005\nbatch_size = 5\nepochs = 25\n\nmain(learning_rate, batch_size, epochs)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-07-03T16:25:30.531797Z","iopub.execute_input":"2023-07-03T16:25:30.532334Z","iopub.status.idle":"2023-07-03T16:36:04.545959Z","shell.execute_reply.started":"2023-07-03T16:25:30.532275Z","shell.execute_reply":"2023-07-03T16:36:04.543448Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"SpeechRecognitionModel1(\n  (conv): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(3, 3), padding=(2, 2))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): GELU(approximate='none')\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): GELU(approximate='none')\n    (6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): GELU(approximate='none')\n  )\n  (BiGRU_1): BidirectionalGRU(\n    (BiGRU): GRU(224, 400, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((224,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (BiGRU_2): BidirectionalGRU(\n    (BiGRU): GRU(800, 400, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (BiGRU_3): BidirectionalGRU(\n    (BiGRU): GRU(800, 400, batch_first=True, bidirectional=True)\n    (layer_norm): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=800, out_features=35, bias=True)\n  )\n  (softmax): LogSoftmax(dim=2)\n)\nNum Model Parameters 7341443\nTrain Epoch: 1 [0/1800 (0%)]\tLoss: 16.529266\nTrain Epoch: 1 [100/1800 (6%)]\tLoss: 6.750296\nTrain Epoch: 1 [200/1800 (11%)]\tLoss: 3.598542\nTrain Epoch: 1 [300/1800 (17%)]\tLoss: 3.702916\nTrain Epoch: 1 [400/1800 (22%)]\tLoss: 3.435916\nTrain Epoch: 1 [500/1800 (28%)]\tLoss: 3.365805\nTrain Epoch: 1 [600/1800 (33%)]\tLoss: 3.290148\nTrain Epoch: 1 [700/1800 (39%)]\tLoss: 3.254955\nTrain Epoch: 1 [800/1800 (44%)]\tLoss: 3.249683\nTrain Epoch: 1 [900/1800 (50%)]\tLoss: 3.354744\nTrain Epoch: 1 [1000/1800 (56%)]\tLoss: 3.362105\nTrain Epoch: 1 [1100/1800 (61%)]\tLoss: 3.290210\nTrain Epoch: 1 [1200/1800 (67%)]\tLoss: 3.333832\nTrain Epoch: 1 [1300/1800 (72%)]\tLoss: 3.214354\nTrain Epoch: 1 [1400/1800 (78%)]\tLoss: 3.254989\nTrain Epoch: 1 [1500/1800 (83%)]\tLoss: 3.220034\nTrain Epoch: 1 [1600/1800 (89%)]\tLoss: 3.320939\nTrain Epoch: 1 [1700/1800 (94%)]\tLoss: 3.300586\n\nevaluating...\nTest set:\tAverage loss: 3.7672, Average CER: 1.000000 Average WER: 1.0000\n\nTrain Epoch: 2 [0/1800 (0%)]\tLoss: 3.234864\nTrain Epoch: 2 [100/1800 (6%)]\tLoss: 3.303632\nTrain Epoch: 2 [200/1800 (11%)]\tLoss: 3.144413\nTrain Epoch: 2 [300/1800 (17%)]\tLoss: 3.384673\nTrain Epoch: 2 [400/1800 (22%)]\tLoss: 3.077040\nTrain Epoch: 2 [500/1800 (28%)]\tLoss: 3.014291\nTrain Epoch: 2 [600/1800 (33%)]\tLoss: 3.053581\nTrain Epoch: 2 [700/1800 (39%)]\tLoss: 2.993259\nTrain Epoch: 2 [800/1800 (44%)]\tLoss: 3.124403\nTrain Epoch: 2 [900/1800 (50%)]\tLoss: 2.699241\nTrain Epoch: 2 [1000/1800 (56%)]\tLoss: 2.745481\nTrain Epoch: 2 [1100/1800 (61%)]\tLoss: 2.681031\nTrain Epoch: 2 [1200/1800 (67%)]\tLoss: 2.735644\nTrain Epoch: 2 [1300/1800 (72%)]\tLoss: 2.576098\nTrain Epoch: 2 [1400/1800 (78%)]\tLoss: 2.533069\nTrain Epoch: 2 [1500/1800 (83%)]\tLoss: 2.433016\nTrain Epoch: 2 [1600/1800 (89%)]\tLoss: 2.422595\nTrain Epoch: 2 [1700/1800 (94%)]\tLoss: 2.422581\n\nevaluating...\nTest set:\tAverage loss: 2.2135, Average CER: 0.871101 Average WER: 0.9983\n\nTrain Epoch: 3 [0/1800 (0%)]\tLoss: 2.339451\nTrain Epoch: 3 [100/1800 (6%)]\tLoss: 2.529718\nTrain Epoch: 3 [200/1800 (11%)]\tLoss: 2.185813\nTrain Epoch: 3 [300/1800 (17%)]\tLoss: 2.244458\nTrain Epoch: 3 [400/1800 (22%)]\tLoss: 2.147595\nTrain Epoch: 3 [500/1800 (28%)]\tLoss: 1.914286\nTrain Epoch: 3 [600/1800 (33%)]\tLoss: 1.920491\nTrain Epoch: 3 [700/1800 (39%)]\tLoss: 1.916846\nTrain Epoch: 3 [800/1800 (44%)]\tLoss: 1.651013\nTrain Epoch: 3 [900/1800 (50%)]\tLoss: 1.771412\nTrain Epoch: 3 [1000/1800 (56%)]\tLoss: 1.553654\nTrain Epoch: 3 [1100/1800 (61%)]\tLoss: 1.575917\nTrain Epoch: 3 [1200/1800 (67%)]\tLoss: 1.560424\nTrain Epoch: 3 [1300/1800 (72%)]\tLoss: 1.587821\nTrain Epoch: 3 [1400/1800 (78%)]\tLoss: 1.470871\nTrain Epoch: 3 [1500/1800 (83%)]\tLoss: 1.517681\nTrain Epoch: 3 [1600/1800 (89%)]\tLoss: 1.399744\nTrain Epoch: 3 [1700/1800 (94%)]\tLoss: 1.375563\n\nevaluating...\nTest set:\tAverage loss: 1.3718, Average CER: 0.402070 Average WER: 0.9756\n\nTrain Epoch: 4 [0/1800 (0%)]\tLoss: 1.125908\nTrain Epoch: 4 [100/1800 (6%)]\tLoss: 1.288545\nTrain Epoch: 4 [200/1800 (11%)]\tLoss: 1.494293\nTrain Epoch: 4 [300/1800 (17%)]\tLoss: 1.138135\nTrain Epoch: 4 [400/1800 (22%)]\tLoss: 1.436408\nTrain Epoch: 4 [500/1800 (28%)]\tLoss: 1.304707\nTrain Epoch: 4 [600/1800 (33%)]\tLoss: 1.052992\nTrain Epoch: 4 [700/1800 (39%)]\tLoss: 1.410830\nTrain Epoch: 4 [800/1800 (44%)]\tLoss: 1.002594\nTrain Epoch: 4 [900/1800 (50%)]\tLoss: 1.131111\nTrain Epoch: 4 [1000/1800 (56%)]\tLoss: 1.056361\nTrain Epoch: 4 [1100/1800 (61%)]\tLoss: 1.054446\nTrain Epoch: 4 [1200/1800 (67%)]\tLoss: 1.030498\nTrain Epoch: 4 [1300/1800 (72%)]\tLoss: 1.278119\nTrain Epoch: 4 [1400/1800 (78%)]\tLoss: 1.160332\nTrain Epoch: 4 [1500/1800 (83%)]\tLoss: 1.076357\nTrain Epoch: 4 [1600/1800 (89%)]\tLoss: 1.104627\nTrain Epoch: 4 [1700/1800 (94%)]\tLoss: 1.403916\n\nevaluating...\nTest set:\tAverage loss: 1.1447, Average CER: 0.336440 Average WER: 0.9607\n\nTrain Epoch: 5 [0/1800 (0%)]\tLoss: 0.861375\nTrain Epoch: 5 [100/1800 (6%)]\tLoss: 1.102228\nTrain Epoch: 5 [200/1800 (11%)]\tLoss: 0.723627\nTrain Epoch: 5 [300/1800 (17%)]\tLoss: 0.942124\nTrain Epoch: 5 [400/1800 (22%)]\tLoss: 1.222096\nTrain Epoch: 5 [500/1800 (28%)]\tLoss: 0.786526\nTrain Epoch: 5 [600/1800 (33%)]\tLoss: 0.910807\nTrain Epoch: 5 [700/1800 (39%)]\tLoss: 1.028475\nTrain Epoch: 5 [800/1800 (44%)]\tLoss: 1.044341\nTrain Epoch: 5 [900/1800 (50%)]\tLoss: 1.137220\nTrain Epoch: 5 [1000/1800 (56%)]\tLoss: 0.852582\nTrain Epoch: 5 [1100/1800 (61%)]\tLoss: 1.179870\nTrain Epoch: 5 [1200/1800 (67%)]\tLoss: 0.795749\nTrain Epoch: 5 [1300/1800 (72%)]\tLoss: 0.779955\nTrain Epoch: 5 [1400/1800 (78%)]\tLoss: 2.071734\nTrain Epoch: 5 [1500/1800 (83%)]\tLoss: 0.991695\nTrain Epoch: 5 [1600/1800 (89%)]\tLoss: 2.018586\nTrain Epoch: 5 [1700/1800 (94%)]\tLoss: 1.309072\n\nevaluating...\nTest set:\tAverage loss: 0.9971, Average CER: 0.304683 Average WER: 0.9324\n\nTrain Epoch: 6 [0/1800 (0%)]\tLoss: 1.212829\nTrain Epoch: 6 [100/1800 (6%)]\tLoss: 0.700099\nTrain Epoch: 6 [200/1800 (11%)]\tLoss: 0.947230\nTrain Epoch: 6 [300/1800 (17%)]\tLoss: 0.950782\nTrain Epoch: 6 [400/1800 (22%)]\tLoss: 0.715249\nTrain Epoch: 6 [500/1800 (28%)]\tLoss: 0.636496\nTrain Epoch: 6 [600/1800 (33%)]\tLoss: 1.413644\nTrain Epoch: 6 [700/1800 (39%)]\tLoss: 0.822786\nTrain Epoch: 6 [800/1800 (44%)]\tLoss: 0.670694\nTrain Epoch: 6 [900/1800 (50%)]\tLoss: 1.093417\nTrain Epoch: 6 [1000/1800 (56%)]\tLoss: 0.685150\nTrain Epoch: 6 [1100/1800 (61%)]\tLoss: 0.798405\nTrain Epoch: 6 [1200/1800 (67%)]\tLoss: 0.992722\nTrain Epoch: 6 [1300/1800 (72%)]\tLoss: 0.822495\nTrain Epoch: 6 [1400/1800 (78%)]\tLoss: 0.605499\nTrain Epoch: 6 [1500/1800 (83%)]\tLoss: 0.706177\nTrain Epoch: 6 [1600/1800 (89%)]\tLoss: 0.884023\nTrain Epoch: 6 [1700/1800 (94%)]\tLoss: 0.752614\n\nevaluating...\nTest set:\tAverage loss: 0.9086, Average CER: 0.284176 Average WER: 0.9012\n\nTrain Epoch: 7 [0/1800 (0%)]\tLoss: 0.951706\nTrain Epoch: 7 [100/1800 (6%)]\tLoss: 0.566606\nTrain Epoch: 7 [200/1800 (11%)]\tLoss: 0.647553\nTrain Epoch: 7 [300/1800 (17%)]\tLoss: 0.718644\nTrain Epoch: 7 [400/1800 (22%)]\tLoss: 0.632351\nTrain Epoch: 7 [500/1800 (28%)]\tLoss: 2.060444\nTrain Epoch: 7 [600/1800 (33%)]\tLoss: 0.486491\nTrain Epoch: 7 [700/1800 (39%)]\tLoss: 0.868368\nTrain Epoch: 7 [800/1800 (44%)]\tLoss: 0.665843\nTrain Epoch: 7 [900/1800 (50%)]\tLoss: 0.729482\nTrain Epoch: 7 [1000/1800 (56%)]\tLoss: 0.672563\nTrain Epoch: 7 [1100/1800 (61%)]\tLoss: 0.930365\nTrain Epoch: 7 [1200/1800 (67%)]\tLoss: 0.487149\nTrain Epoch: 7 [1300/1800 (72%)]\tLoss: 0.703206\nTrain Epoch: 7 [1400/1800 (78%)]\tLoss: 0.584041\nTrain Epoch: 7 [1500/1800 (83%)]\tLoss: 0.913346\nTrain Epoch: 7 [1600/1800 (89%)]\tLoss: 0.783682\nTrain Epoch: 7 [1700/1800 (94%)]\tLoss: 0.665908\n\nevaluating...\nTest set:\tAverage loss: 0.8574, Average CER: 0.262087 Average WER: 0.9034\n\nTrain Epoch: 8 [0/1800 (0%)]\tLoss: 0.868360\nTrain Epoch: 8 [100/1800 (6%)]\tLoss: 1.769977\nTrain Epoch: 8 [200/1800 (11%)]\tLoss: 0.474196\nTrain Epoch: 8 [300/1800 (17%)]\tLoss: 0.572392\nTrain Epoch: 8 [400/1800 (22%)]\tLoss: 0.595290\nTrain Epoch: 8 [500/1800 (28%)]\tLoss: 0.644319\nTrain Epoch: 8 [600/1800 (33%)]\tLoss: 0.667304\nTrain Epoch: 8 [700/1800 (39%)]\tLoss: 0.809397\nTrain Epoch: 8 [800/1800 (44%)]\tLoss: 0.545345\nTrain Epoch: 8 [900/1800 (50%)]\tLoss: 0.819173\nTrain Epoch: 8 [1000/1800 (56%)]\tLoss: 0.442046\nTrain Epoch: 8 [1100/1800 (61%)]\tLoss: 0.721676\nTrain Epoch: 8 [1200/1800 (67%)]\tLoss: 0.725652\nTrain Epoch: 8 [1300/1800 (72%)]\tLoss: 0.550549\nTrain Epoch: 8 [1400/1800 (78%)]\tLoss: 0.637281\nTrain Epoch: 8 [1500/1800 (83%)]\tLoss: 0.436181\nTrain Epoch: 8 [1600/1800 (89%)]\tLoss: 0.598397\nTrain Epoch: 8 [1700/1800 (94%)]\tLoss: 0.634559\n\nevaluating...\nTest set:\tAverage loss: 0.7842, Average CER: 0.241781 Average WER: 0.8601\n\nTrain Epoch: 9 [0/1800 (0%)]\tLoss: 0.664615\nTrain Epoch: 9 [100/1800 (6%)]\tLoss: 0.489316\nTrain Epoch: 9 [200/1800 (11%)]\tLoss: 1.564620\nTrain Epoch: 9 [300/1800 (17%)]\tLoss: 1.767225\nTrain Epoch: 9 [400/1800 (22%)]\tLoss: 0.273079\nTrain Epoch: 9 [500/1800 (28%)]\tLoss: 0.492542\nTrain Epoch: 9 [600/1800 (33%)]\tLoss: 0.448759\nTrain Epoch: 9 [700/1800 (39%)]\tLoss: 0.640588\nTrain Epoch: 9 [800/1800 (44%)]\tLoss: 0.394769\nTrain Epoch: 9 [900/1800 (50%)]\tLoss: 0.444865\nTrain Epoch: 9 [1000/1800 (56%)]\tLoss: 0.436501\nTrain Epoch: 9 [1100/1800 (61%)]\tLoss: 0.503029\nTrain Epoch: 9 [1200/1800 (67%)]\tLoss: 0.528064\nTrain Epoch: 9 [1300/1800 (72%)]\tLoss: 0.437875\nTrain Epoch: 9 [1400/1800 (78%)]\tLoss: 0.603747\nTrain Epoch: 9 [1500/1800 (83%)]\tLoss: 0.638536\nTrain Epoch: 9 [1600/1800 (89%)]\tLoss: 0.416598\nTrain Epoch: 9 [1700/1800 (94%)]\tLoss: 0.795337\n\nevaluating...\nTest set:\tAverage loss: 0.7454, Average CER: 0.219829 Average WER: 0.8376\n\nTrain Epoch: 10 [0/1800 (0%)]\tLoss: 0.434676\nTrain Epoch: 10 [100/1800 (6%)]\tLoss: 0.528567\nTrain Epoch: 10 [200/1800 (11%)]\tLoss: 0.554134\nTrain Epoch: 10 [300/1800 (17%)]\tLoss: 0.443495\nTrain Epoch: 10 [400/1800 (22%)]\tLoss: 0.437023\nTrain Epoch: 10 [500/1800 (28%)]\tLoss: 0.420775\nTrain Epoch: 10 [600/1800 (33%)]\tLoss: 0.400181\nTrain Epoch: 10 [700/1800 (39%)]\tLoss: 0.418759\nTrain Epoch: 10 [800/1800 (44%)]\tLoss: 0.606073\nTrain Epoch: 10 [900/1800 (50%)]\tLoss: 0.402315\nTrain Epoch: 10 [1000/1800 (56%)]\tLoss: 0.489831\nTrain Epoch: 10 [1100/1800 (61%)]\tLoss: 0.361848\nTrain Epoch: 10 [1200/1800 (67%)]\tLoss: 0.605918\nTrain Epoch: 10 [1300/1800 (72%)]\tLoss: 0.454689\nTrain Epoch: 10 [1400/1800 (78%)]\tLoss: 0.469949\nTrain Epoch: 10 [1500/1800 (83%)]\tLoss: 0.879787\nTrain Epoch: 10 [1600/1800 (89%)]\tLoss: 1.509588\nTrain Epoch: 10 [1700/1800 (94%)]\tLoss: 0.592352\n\nevaluating...\nTest set:\tAverage loss: 0.7416, Average CER: 0.212998 Average WER: 0.8101\n\nTrain Epoch: 11 [0/1800 (0%)]\tLoss: 0.471287\nTrain Epoch: 11 [100/1800 (6%)]\tLoss: 0.344460\nTrain Epoch: 11 [200/1800 (11%)]\tLoss: 0.294852\nTrain Epoch: 11 [300/1800 (17%)]\tLoss: 0.427197\nTrain Epoch: 11 [400/1800 (22%)]\tLoss: 0.392314\nTrain Epoch: 11 [500/1800 (28%)]\tLoss: 0.278184\nTrain Epoch: 11 [600/1800 (33%)]\tLoss: 0.206320\nTrain Epoch: 11 [700/1800 (39%)]\tLoss: 0.347870\nTrain Epoch: 11 [800/1800 (44%)]\tLoss: 0.597187\nTrain Epoch: 11 [900/1800 (50%)]\tLoss: 0.791527\nTrain Epoch: 11 [1000/1800 (56%)]\tLoss: 0.382999\nTrain Epoch: 11 [1100/1800 (61%)]\tLoss: 0.370056\nTrain Epoch: 11 [1200/1800 (67%)]\tLoss: 0.639544\nTrain Epoch: 11 [1300/1800 (72%)]\tLoss: 0.505351\nTrain Epoch: 11 [1400/1800 (78%)]\tLoss: 0.204638\nTrain Epoch: 11 [1500/1800 (83%)]\tLoss: 0.395354\nTrain Epoch: 11 [1600/1800 (89%)]\tLoss: 0.547010\nTrain Epoch: 11 [1700/1800 (94%)]\tLoss: 0.349613\n\nevaluating...\nTest set:\tAverage loss: 0.7361, Average CER: 0.208258 Average WER: 0.8003\n\nTrain Epoch: 12 [0/1800 (0%)]\tLoss: 0.336626\nTrain Epoch: 12 [100/1800 (6%)]\tLoss: 0.389401\nTrain Epoch: 12 [200/1800 (11%)]\tLoss: 0.200633\nTrain Epoch: 12 [300/1800 (17%)]\tLoss: 0.230590\nTrain Epoch: 12 [400/1800 (22%)]\tLoss: 0.345969\nTrain Epoch: 12 [500/1800 (28%)]\tLoss: 0.298912\nTrain Epoch: 12 [600/1800 (33%)]\tLoss: 0.451607\nTrain Epoch: 12 [700/1800 (39%)]\tLoss: 0.284863\nTrain Epoch: 12 [800/1800 (44%)]\tLoss: 0.382842\nTrain Epoch: 12 [900/1800 (50%)]\tLoss: 0.275656\nTrain Epoch: 12 [1000/1800 (56%)]\tLoss: 0.287129\nTrain Epoch: 12 [1100/1800 (61%)]\tLoss: 0.495757\nTrain Epoch: 12 [1200/1800 (67%)]\tLoss: 0.236547\nTrain Epoch: 12 [1300/1800 (72%)]\tLoss: 0.419233\nTrain Epoch: 12 [1400/1800 (78%)]\tLoss: 0.284677\nTrain Epoch: 12 [1500/1800 (83%)]\tLoss: 0.279479\nTrain Epoch: 12 [1600/1800 (89%)]\tLoss: 0.243455\nTrain Epoch: 12 [1700/1800 (94%)]\tLoss: 0.292572\n\nevaluating...\nTest set:\tAverage loss: 0.7354, Average CER: 0.203399 Average WER: 0.7823\n\nTrain Epoch: 13 [0/1800 (0%)]\tLoss: 0.283680\nTrain Epoch: 13 [100/1800 (6%)]\tLoss: 0.188485\nTrain Epoch: 13 [200/1800 (11%)]\tLoss: 0.208194\nTrain Epoch: 13 [300/1800 (17%)]\tLoss: 0.475428\nTrain Epoch: 13 [400/1800 (22%)]\tLoss: 0.369021\nTrain Epoch: 13 [500/1800 (28%)]\tLoss: 1.198257\nTrain Epoch: 13 [600/1800 (33%)]\tLoss: 0.248958\nTrain Epoch: 13 [700/1800 (39%)]\tLoss: 0.170047\nTrain Epoch: 13 [800/1800 (44%)]\tLoss: 1.649493\nTrain Epoch: 13 [900/1800 (50%)]\tLoss: 0.341816\nTrain Epoch: 13 [1000/1800 (56%)]\tLoss: 0.238313\nTrain Epoch: 13 [1100/1800 (61%)]\tLoss: 0.269603\nTrain Epoch: 13 [1200/1800 (67%)]\tLoss: 0.282650\nTrain Epoch: 13 [1300/1800 (72%)]\tLoss: 0.199947\nTrain Epoch: 13 [1400/1800 (78%)]\tLoss: 0.366718\nTrain Epoch: 13 [1500/1800 (83%)]\tLoss: 0.207855\nTrain Epoch: 13 [1600/1800 (89%)]\tLoss: 0.389355\nTrain Epoch: 13 [1700/1800 (94%)]\tLoss: 0.366011\n\nevaluating...\nTest set:\tAverage loss: 0.7613, Average CER: 0.205480 Average WER: 0.7687\n\nTrain Epoch: 14 [0/1800 (0%)]\tLoss: 0.185146\nTrain Epoch: 14 [100/1800 (6%)]\tLoss: 0.888456\nTrain Epoch: 14 [200/1800 (11%)]\tLoss: 0.287391\nTrain Epoch: 14 [300/1800 (17%)]\tLoss: 0.227890\nTrain Epoch: 14 [400/1800 (22%)]\tLoss: 0.216050\nTrain Epoch: 14 [500/1800 (28%)]\tLoss: 0.165837\nTrain Epoch: 14 [600/1800 (33%)]\tLoss: 0.283599\nTrain Epoch: 14 [700/1800 (39%)]\tLoss: 0.189570\nTrain Epoch: 14 [800/1800 (44%)]\tLoss: 0.167624\nTrain Epoch: 14 [900/1800 (50%)]\tLoss: 0.251564\nTrain Epoch: 14 [1000/1800 (56%)]\tLoss: 0.150482\nTrain Epoch: 14 [1100/1800 (61%)]\tLoss: 0.192984\nTrain Epoch: 14 [1200/1800 (67%)]\tLoss: 0.250778\nTrain Epoch: 14 [1300/1800 (72%)]\tLoss: 0.254316\nTrain Epoch: 14 [1400/1800 (78%)]\tLoss: 0.262407\nTrain Epoch: 14 [1500/1800 (83%)]\tLoss: 0.390320\nTrain Epoch: 14 [1600/1800 (89%)]\tLoss: 0.158565\nTrain Epoch: 14 [1700/1800 (94%)]\tLoss: 0.532134\n\nevaluating...\nTest set:\tAverage loss: 0.7758, Average CER: 0.200041 Average WER: 0.7671\n\nTrain Epoch: 15 [0/1800 (0%)]\tLoss: 0.335964\nTrain Epoch: 15 [100/1800 (6%)]\tLoss: 1.357463\nTrain Epoch: 15 [200/1800 (11%)]\tLoss: 0.187533\nTrain Epoch: 15 [300/1800 (17%)]\tLoss: 0.204645\nTrain Epoch: 15 [400/1800 (22%)]\tLoss: 0.149005\nTrain Epoch: 15 [500/1800 (28%)]\tLoss: 0.275384\nTrain Epoch: 15 [600/1800 (33%)]\tLoss: 0.261275\nTrain Epoch: 15 [700/1800 (39%)]\tLoss: 0.169052\nTrain Epoch: 15 [800/1800 (44%)]\tLoss: 0.268904\nTrain Epoch: 15 [900/1800 (50%)]\tLoss: 0.185677\nTrain Epoch: 15 [1000/1800 (56%)]\tLoss: 0.082123\nTrain Epoch: 15 [1100/1800 (61%)]\tLoss: 0.239712\nTrain Epoch: 15 [1200/1800 (67%)]\tLoss: 0.227234\nTrain Epoch: 15 [1300/1800 (72%)]\tLoss: 0.206443\nTrain Epoch: 15 [1400/1800 (78%)]\tLoss: 0.171062\nTrain Epoch: 15 [1500/1800 (83%)]\tLoss: 0.265564\nTrain Epoch: 15 [1600/1800 (89%)]\tLoss: 0.226701\nTrain Epoch: 15 [1700/1800 (94%)]\tLoss: 0.273529\n\nevaluating...\nTest set:\tAverage loss: 0.7877, Average CER: 0.192673 Average WER: 0.7486\n\nTrain Epoch: 16 [0/1800 (0%)]\tLoss: 0.221141\nTrain Epoch: 16 [100/1800 (6%)]\tLoss: 0.160902\nTrain Epoch: 16 [200/1800 (11%)]\tLoss: 0.149084\nTrain Epoch: 16 [300/1800 (17%)]\tLoss: 0.513855\nTrain Epoch: 16 [400/1800 (22%)]\tLoss: 0.138995\nTrain Epoch: 16 [500/1800 (28%)]\tLoss: 0.120154\nTrain Epoch: 16 [600/1800 (33%)]\tLoss: 0.088943\nTrain Epoch: 16 [700/1800 (39%)]\tLoss: 0.132223\nTrain Epoch: 16 [800/1800 (44%)]\tLoss: 0.219982\nTrain Epoch: 16 [900/1800 (50%)]\tLoss: 0.284650\nTrain Epoch: 16 [1000/1800 (56%)]\tLoss: 0.429944\nTrain Epoch: 16 [1100/1800 (61%)]\tLoss: 0.151476\nTrain Epoch: 16 [1200/1800 (67%)]\tLoss: 0.193628\nTrain Epoch: 16 [1300/1800 (72%)]\tLoss: 0.113748\nTrain Epoch: 16 [1400/1800 (78%)]\tLoss: 0.079272\nTrain Epoch: 16 [1500/1800 (83%)]\tLoss: 0.141805\nTrain Epoch: 16 [1600/1800 (89%)]\tLoss: 0.171829\nTrain Epoch: 16 [1700/1800 (94%)]\tLoss: 0.174459\n\nevaluating...\nTest set:\tAverage loss: 0.7506, Average CER: 0.182421 Average WER: 0.7441\n\nTrain Epoch: 17 [0/1800 (0%)]\tLoss: 0.179781\nTrain Epoch: 17 [100/1800 (6%)]\tLoss: 0.166492\nTrain Epoch: 17 [200/1800 (11%)]\tLoss: 0.185964\nTrain Epoch: 17 [300/1800 (17%)]\tLoss: 0.102840\nTrain Epoch: 17 [400/1800 (22%)]\tLoss: 0.118613\nTrain Epoch: 17 [500/1800 (28%)]\tLoss: 0.202589\nTrain Epoch: 17 [600/1800 (33%)]\tLoss: 0.089745\nTrain Epoch: 17 [700/1800 (39%)]\tLoss: 0.119368\nTrain Epoch: 17 [800/1800 (44%)]\tLoss: 0.062098\nTrain Epoch: 17 [900/1800 (50%)]\tLoss: 0.113937\nTrain Epoch: 17 [1000/1800 (56%)]\tLoss: 0.231617\nTrain Epoch: 17 [1100/1800 (61%)]\tLoss: 0.208912\nTrain Epoch: 17 [1200/1800 (67%)]\tLoss: 0.123926\nTrain Epoch: 17 [1300/1800 (72%)]\tLoss: 0.059817\nTrain Epoch: 17 [1400/1800 (78%)]\tLoss: 0.133362\nTrain Epoch: 17 [1500/1800 (83%)]\tLoss: 0.117994\nTrain Epoch: 17 [1600/1800 (89%)]\tLoss: 0.097085\nTrain Epoch: 17 [1700/1800 (94%)]\tLoss: 0.206246\n\nevaluating...\nTest set:\tAverage loss: 0.8106, Average CER: 0.188004 Average WER: 0.7332\n\nTrain Epoch: 18 [0/1800 (0%)]\tLoss: 0.922080\nTrain Epoch: 18 [100/1800 (6%)]\tLoss: 0.150261\nTrain Epoch: 18 [200/1800 (11%)]\tLoss: 0.141350\nTrain Epoch: 18 [300/1800 (17%)]\tLoss: 0.118926\nTrain Epoch: 18 [400/1800 (22%)]\tLoss: 0.281934\nTrain Epoch: 18 [500/1800 (28%)]\tLoss: 0.094856\nTrain Epoch: 18 [600/1800 (33%)]\tLoss: 0.046241\nTrain Epoch: 18 [700/1800 (39%)]\tLoss: 0.051267\nTrain Epoch: 18 [800/1800 (44%)]\tLoss: 0.130112\nTrain Epoch: 18 [900/1800 (50%)]\tLoss: 0.027132\nTrain Epoch: 18 [1000/1800 (56%)]\tLoss: 0.059273\nTrain Epoch: 18 [1100/1800 (61%)]\tLoss: 0.195624\nTrain Epoch: 18 [1200/1800 (67%)]\tLoss: 0.114155\nTrain Epoch: 18 [1300/1800 (72%)]\tLoss: 0.052307\nTrain Epoch: 18 [1400/1800 (78%)]\tLoss: 0.051669\nTrain Epoch: 18 [1500/1800 (83%)]\tLoss: 0.107695\nTrain Epoch: 18 [1600/1800 (89%)]\tLoss: 0.084030\nTrain Epoch: 18 [1700/1800 (94%)]\tLoss: 0.122550\n\nevaluating...\nTest set:\tAverage loss: 0.7544, Average CER: 0.167567 Average WER: 0.7089\n\nTrain Epoch: 19 [0/1800 (0%)]\tLoss: 0.062017\nTrain Epoch: 19 [100/1800 (6%)]\tLoss: 0.062789\nTrain Epoch: 19 [200/1800 (11%)]\tLoss: 0.090936\nTrain Epoch: 19 [300/1800 (17%)]\tLoss: 0.047092\nTrain Epoch: 19 [400/1800 (22%)]\tLoss: 0.035078\nTrain Epoch: 19 [500/1800 (28%)]\tLoss: 0.112665\nTrain Epoch: 19 [600/1800 (33%)]\tLoss: 0.044598\nTrain Epoch: 19 [700/1800 (39%)]\tLoss: 0.185524\nTrain Epoch: 19 [800/1800 (44%)]\tLoss: 0.149375\nTrain Epoch: 19 [900/1800 (50%)]\tLoss: 0.072416\nTrain Epoch: 19 [1000/1800 (56%)]\tLoss: 0.127611\nTrain Epoch: 19 [1100/1800 (61%)]\tLoss: 0.078285\nTrain Epoch: 19 [1200/1800 (67%)]\tLoss: 0.044833\nTrain Epoch: 19 [1300/1800 (72%)]\tLoss: 0.138861\nTrain Epoch: 19 [1400/1800 (78%)]\tLoss: 0.089055\nTrain Epoch: 19 [1500/1800 (83%)]\tLoss: 0.097423\nTrain Epoch: 19 [1600/1800 (89%)]\tLoss: 0.068720\nTrain Epoch: 19 [1700/1800 (94%)]\tLoss: 0.047047\n\nevaluating...\nTest set:\tAverage loss: 0.8142, Average CER: 0.185954 Average WER: 0.7572\n\nTrain Epoch: 20 [0/1800 (0%)]\tLoss: 0.057048\nTrain Epoch: 20 [100/1800 (6%)]\tLoss: 0.060001\nTrain Epoch: 20 [200/1800 (11%)]\tLoss: 0.108747\nTrain Epoch: 20 [300/1800 (17%)]\tLoss: 0.096710\nTrain Epoch: 20 [400/1800 (22%)]\tLoss: 0.057694\nTrain Epoch: 20 [500/1800 (28%)]\tLoss: 0.030752\nTrain Epoch: 20 [600/1800 (33%)]\tLoss: 0.028773\nTrain Epoch: 20 [700/1800 (39%)]\tLoss: 0.056246\nTrain Epoch: 20 [800/1800 (44%)]\tLoss: 0.207386\nTrain Epoch: 20 [900/1800 (50%)]\tLoss: 0.877050\nTrain Epoch: 20 [1000/1800 (56%)]\tLoss: 0.110057\nTrain Epoch: 20 [1100/1800 (61%)]\tLoss: 0.138312\nTrain Epoch: 20 [1200/1800 (67%)]\tLoss: 0.036022\nTrain Epoch: 20 [1300/1800 (72%)]\tLoss: 0.050519\nTrain Epoch: 20 [1400/1800 (78%)]\tLoss: 0.085919\nTrain Epoch: 20 [1500/1800 (83%)]\tLoss: 0.207369\nTrain Epoch: 20 [1600/1800 (89%)]\tLoss: 0.037712\nTrain Epoch: 20 [1700/1800 (94%)]\tLoss: 0.024825\n\nevaluating...\nTest set:\tAverage loss: 0.8318, Average CER: 0.172036 Average WER: 0.7019\n\nTrain Epoch: 21 [0/1800 (0%)]\tLoss: 0.068891\nTrain Epoch: 21 [100/1800 (6%)]\tLoss: 0.071245\nTrain Epoch: 21 [200/1800 (11%)]\tLoss: 0.046926\nTrain Epoch: 21 [300/1800 (17%)]\tLoss: 0.195765\nTrain Epoch: 21 [400/1800 (22%)]\tLoss: 0.074110\nTrain Epoch: 21 [500/1800 (28%)]\tLoss: 0.029796\nTrain Epoch: 21 [600/1800 (33%)]\tLoss: 0.064904\nTrain Epoch: 21 [700/1800 (39%)]\tLoss: 0.114400\nTrain Epoch: 21 [800/1800 (44%)]\tLoss: 0.077614\nTrain Epoch: 21 [900/1800 (50%)]\tLoss: 0.034892\nTrain Epoch: 21 [1000/1800 (56%)]\tLoss: 0.058924\nTrain Epoch: 21 [1100/1800 (61%)]\tLoss: 0.656359\nTrain Epoch: 21 [1200/1800 (67%)]\tLoss: 0.064778\nTrain Epoch: 21 [1300/1800 (72%)]\tLoss: 0.117998\nTrain Epoch: 21 [1400/1800 (78%)]\tLoss: 0.364334\nTrain Epoch: 21 [1500/1800 (83%)]\tLoss: 0.082108\nTrain Epoch: 21 [1600/1800 (89%)]\tLoss: 0.072355\nTrain Epoch: 21 [1700/1800 (94%)]\tLoss: 0.068033\n\nevaluating...\nTest set:\tAverage loss: 0.8456, Average CER: 0.173001 Average WER: 0.7037\n\nTrain Epoch: 22 [0/1800 (0%)]\tLoss: 0.241894\nTrain Epoch: 22 [100/1800 (6%)]\tLoss: 0.048467\nTrain Epoch: 22 [200/1800 (11%)]\tLoss: 0.028670\nTrain Epoch: 22 [300/1800 (17%)]\tLoss: 0.070579\nTrain Epoch: 22 [400/1800 (22%)]\tLoss: 0.025123\nTrain Epoch: 22 [500/1800 (28%)]\tLoss: 0.045673\nTrain Epoch: 22 [600/1800 (33%)]\tLoss: 0.040759\nTrain Epoch: 22 [700/1800 (39%)]\tLoss: 0.098043\nTrain Epoch: 22 [800/1800 (44%)]\tLoss: 0.268514\nTrain Epoch: 22 [900/1800 (50%)]\tLoss: 0.075407\nTrain Epoch: 22 [1000/1800 (56%)]\tLoss: 0.035401\nTrain Epoch: 22 [1100/1800 (61%)]\tLoss: 0.117684\nTrain Epoch: 22 [1200/1800 (67%)]\tLoss: 0.061464\nTrain Epoch: 22 [1300/1800 (72%)]\tLoss: 0.091614\nTrain Epoch: 22 [1400/1800 (78%)]\tLoss: 0.060387\nTrain Epoch: 22 [1500/1800 (83%)]\tLoss: 0.024133\nTrain Epoch: 22 [1600/1800 (89%)]\tLoss: 0.262488\nTrain Epoch: 22 [1700/1800 (94%)]\tLoss: 0.039672\n\nevaluating...\nTest set:\tAverage loss: 0.8628, Average CER: 0.172011 Average WER: 0.6983\n\nTrain Epoch: 23 [0/1800 (0%)]\tLoss: 0.015924\nTrain Epoch: 23 [100/1800 (6%)]\tLoss: 0.232531\nTrain Epoch: 23 [200/1800 (11%)]\tLoss: 0.035685\nTrain Epoch: 23 [300/1800 (17%)]\tLoss: 0.031069\nTrain Epoch: 23 [400/1800 (22%)]\tLoss: 0.019020\nTrain Epoch: 23 [500/1800 (28%)]\tLoss: 0.029136\nTrain Epoch: 23 [600/1800 (33%)]\tLoss: 0.026632\nTrain Epoch: 23 [700/1800 (39%)]\tLoss: 0.025871\nTrain Epoch: 23 [800/1800 (44%)]\tLoss: 0.010206\nTrain Epoch: 23 [900/1800 (50%)]\tLoss: 0.127897\nTrain Epoch: 23 [1000/1800 (56%)]\tLoss: 0.572659\nTrain Epoch: 23 [1100/1800 (61%)]\tLoss: 0.056647\nTrain Epoch: 23 [1200/1800 (67%)]\tLoss: 0.023343\nTrain Epoch: 23 [1300/1800 (72%)]\tLoss: 0.046590\nTrain Epoch: 23 [1400/1800 (78%)]\tLoss: 0.028750\nTrain Epoch: 23 [1500/1800 (83%)]\tLoss: 0.017045\nTrain Epoch: 23 [1600/1800 (89%)]\tLoss: 0.027482\nTrain Epoch: 23 [1700/1800 (94%)]\tLoss: 0.023848\n\nevaluating...\nTest set:\tAverage loss: 0.8748, Average CER: 0.171439 Average WER: 0.7016\n\nTrain Epoch: 24 [0/1800 (0%)]\tLoss: 0.095457\nTrain Epoch: 24 [100/1800 (6%)]\tLoss: 0.045772\nTrain Epoch: 24 [200/1800 (11%)]\tLoss: 0.019751\nTrain Epoch: 24 [300/1800 (17%)]\tLoss: 0.485219\nTrain Epoch: 24 [400/1800 (22%)]\tLoss: 0.059216\nTrain Epoch: 24 [500/1800 (28%)]\tLoss: 0.056027\nTrain Epoch: 24 [600/1800 (33%)]\tLoss: 0.059598\nTrain Epoch: 24 [700/1800 (39%)]\tLoss: 0.219119\nTrain Epoch: 24 [800/1800 (44%)]\tLoss: 0.120850\nTrain Epoch: 24 [900/1800 (50%)]\tLoss: 0.054109\nTrain Epoch: 24 [1000/1800 (56%)]\tLoss: 0.041403\nTrain Epoch: 24 [1100/1800 (61%)]\tLoss: 0.040793\nTrain Epoch: 24 [1200/1800 (67%)]\tLoss: 0.024636\nTrain Epoch: 24 [1300/1800 (72%)]\tLoss: 0.024159\nTrain Epoch: 24 [1400/1800 (78%)]\tLoss: 0.015082\nTrain Epoch: 24 [1500/1800 (83%)]\tLoss: 0.043321\nTrain Epoch: 24 [1600/1800 (89%)]\tLoss: 0.041238\nTrain Epoch: 24 [1700/1800 (94%)]\tLoss: 0.021334\n\nevaluating...\nTest set:\tAverage loss: 0.8546, Average CER: 0.166330 Average WER: 0.6944\n\nTrain Epoch: 25 [0/1800 (0%)]\tLoss: 0.080462\nTrain Epoch: 25 [100/1800 (6%)]\tLoss: 0.096553\nTrain Epoch: 25 [200/1800 (11%)]\tLoss: 0.015202\nTrain Epoch: 25 [300/1800 (17%)]\tLoss: 0.090907\nTrain Epoch: 25 [400/1800 (22%)]\tLoss: 0.022823\nTrain Epoch: 25 [500/1800 (28%)]\tLoss: 0.050822\nTrain Epoch: 25 [600/1800 (33%)]\tLoss: 0.533391\nTrain Epoch: 25 [700/1800 (39%)]\tLoss: 0.011379\nTrain Epoch: 25 [800/1800 (44%)]\tLoss: 0.022007\nTrain Epoch: 25 [900/1800 (50%)]\tLoss: 0.024788\nTrain Epoch: 25 [1000/1800 (56%)]\tLoss: 0.043938\nTrain Epoch: 25 [1100/1800 (61%)]\tLoss: 0.062565\nTrain Epoch: 25 [1200/1800 (67%)]\tLoss: 0.013885\nTrain Epoch: 25 [1300/1800 (72%)]\tLoss: 0.012509\nTrain Epoch: 25 [1400/1800 (78%)]\tLoss: 0.016341\nTrain Epoch: 25 [1500/1800 (83%)]\tLoss: 0.225134\nTrain Epoch: 25 [1600/1800 (89%)]\tLoss: 0.040633\nTrain Epoch: 25 [1700/1800 (94%)]\tLoss: 0.015264\n\nevaluating...\nTest set:\tAverage loss: 0.8842, Average CER: 0.172273 Average WER: 0.7084\n\nCPU times: user 10min 17s, sys: 13.2 s, total: 10min 31s\nWall time: 10min 33s\n","output_type":"stream"}]},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cpu\")\n\nmodel = torch.load('/kaggle/working/model.pt')\n\n#1543 1882 1372\n\nmodel.to(device)\npredict(model, '/kaggle/input/upd-speech/mono_voice/1807.wav', device)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T16:38:41.368993Z","iopub.execute_input":"2023-07-03T16:38:41.369698Z","iopub.status.idle":"2023-07-03T16:38:41.754077Z","shell.execute_reply.started":"2023-07-03T16:38:41.369624Z","shell.execute_reply":"2023-07-03T16:38:41.752146Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 20, 903])\ntorch.Size([1, 302, 35])\n","output_type":"stream"},{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"'всемирная пондемия из менела всё наше трастесание'"},"metadata":{}}]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2023-05-24T10:26:24.339488Z","iopub.execute_input":"2023-05-24T10:26:24.340405Z","iopub.status.idle":"2023-05-24T10:26:24.350954Z","shell.execute_reply.started":"2023-05-24T10:26:24.340364Z","shell.execute_reply":"2023-05-24T10:26:24.349831Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['там начальство всё время меняется',\n 'какие новости произошли за последнее время',\n 'твои новые штаны выглядят здорово',\n 'дружба превыше всего',\n 'делайте то что вам нравится',\n 'общение с интересными людьми',\n 'белый песок',\n 'не совершай ошибок',\n 'время лечит все раны но не забывайте прошлое',\n 'последствие непогоды',\n 'вата',\n 'здесь в глубине слышу твое имя снова',\n 'может быть мы найдем решение',\n 'оптимизм не дает гарантий но падение маловероятно',\n 'субстрат',\n 'обрюзгший жир',\n 'двигатель внутреннего сгорания',\n 'интересное занятие',\n 'бесшумный полет',\n 'о молитве',\n 'жизнь полна неожиданностей',\n 'крепкий запах древесины',\n 'мобилизация',\n 'холодный ветер',\n 'там очень красивый закат',\n 'извините',\n 'туристический поход',\n 'посмотреть сериал вечером',\n 'ничего особенного',\n 'важная бумага',\n 'я не могу дышать',\n 'пахнущий аромат свежей выпечки',\n 'рецепт мяса пофранцузски',\n 'это место свободно',\n 'для производства необходима сталь',\n 'тарелка из под тарталеток',\n 'хочешь выпить чашку кофе',\n 'радужный ковер',\n 'любовь к природе',\n 'где ближайший супермаркет',\n 'одноклассники',\n 'густой сироп',\n 'мощный порыв',\n 'эта работа занимает все мою свободное время',\n 'завтра будет жарко или холодно',\n 'такое чувство будто жизнь проходит мимо',\n 'удобный шлем',\n 'дом',\n 'заполненый холодильник',\n 'окно в кабинете математики',\n 'просторная светлая комната',\n 'один шаг за другим к успеху',\n 'безмятежный закат',\n 'умейте слушаться внутренний голос перед принятием решений',\n 'наушники застряли на проводах',\n 'устав от поднятой веком пыли',\n 'легкий бриз',\n 'встреча делигации настольных игр',\n 'приятное общение с коллегами на работе',\n 'темный лес полон тайн и загадок',\n 'фотографии запрещены в этом месте',\n 'синий океан',\n 'начни сначала это не работает',\n 'ночная жизнь',\n 'понимаешь что я имею в виду',\n 'огненная лисичка мой любимый браузер',\n 'а что если чтонибудь случится',\n 'цветущий сад наполняет ароматом',\n 'увлечение охотой',\n 'прекрати',\n 'отпечаток пальца',\n 'вы говорите поанглийски',\n 'паспорт гражданина российской федерации',\n 'миска с молоком',\n 'обязательство',\n 'читать интереснее если ты это разделяешь с кемто другим',\n 'теплое одеяло',\n 'испечь пирог',\n 'сколько стоит билет на кино',\n 'румяный от мороза',\n 'без царя в голове',\n 'двуличный',\n 'острые ножницы',\n 'на столе лежит книга с изорванными страницами',\n 'трасса',\n 'бросать предметы в людей не самая лучшая затея',\n 'певучая речь',\n 'творческий подход к решению этой задачи',\n 'уставший студент',\n 'жаркий песок',\n 'ктонибудь здесь говорит порусски',\n 'ручка вращалась как волчок',\n 'медленный интернет',\n 'тестировщик',\n 'приятный запах кофе',\n 'мечты становятся реальностью только при наличии целеустремленности и терпения',\n 'чистая вода',\n 'тихая ночь под лунным светом',\n 'холодный взгляд',\n 'вызовите мне такси пожалуйста',\n 'сможешь ли ты забрать меня после работы',\n 'мокрый асфальт',\n 'запинка',\n 'хотелось бы увеличить рейтинг',\n 'побывал в чёрной дыре',\n 'твердый орех',\n 'мягкая кровать',\n 'старайтесь увидеть хорошее в людях',\n 'бегать по утрам полезно',\n 'ты можешь подарить ей цветы от моего имени',\n 'уроки скрипки бывает очень сложными',\n 'никогда не переставай учиться новому',\n 'розовые облака на закате',\n 'длинная дорога',\n 'время карьеры',\n 'рекомендую начать с самых классических книг',\n 'свежая роса за окном',\n 'я любил немногих',\n 'семья',\n 'конечно',\n 'кто бы знал о чем я думаю',\n 'пятница',\n 'принтер струйный',\n 'высокий забор',\n 'ласковый прикосновение рук',\n 'мир начинается с головы',\n 'свежий арбуз',\n 'отправить посылку',\n 'это было невероятно интересное путешествие',\n 'погода испортила наши планы',\n 'ваш любимый вид спорта',\n 'кафе семейное',\n 'глубокий вдох',\n 'расскажи чем занимаешься',\n 'здоровый дух залог здорового тела',\n 'здоровый образ жизни важен для долголетия',\n 'я не хочу вставать',\n 'средняя школа',\n 'я покушал',\n 'живите так чтобы не было жаль потраченного времени',\n 'быстрый темп',\n 'готовить',\n 'мягкий диван',\n 'бить грушу весело если ты кушаешь яблоки',\n 'жизнь проходит быстро наслаждайтесь ей каждый день',\n 'цветущие поля весной',\n 'кататься на лыжах',\n 'красивый закат',\n 'спектакль уже начался',\n 'утренняя зарядка',\n 'у меня возникли проблемы',\n 'мороженное закончилось',\n 'после дождя',\n 'официант на полставки',\n 'дай денег',\n 'яркая реклама на табло',\n 'это проходит со временем',\n 'нам следует идти пешком чтобы не пропустить все достопримечательности',\n 'адрес',\n 'нам нужно еще пару продуктов для ужина',\n 'тихий шепот',\n 'стеклянный кристалл',\n 'армия животных завоевала скотный двор',\n 'я был счатлив здесь',\n 'большинство',\n 'владелец автомобиля',\n 'готовишь уже обед или нет',\n 'заботиться о других лучший способ накопления счастья',\n 'кулер охлаждения центрального процессора',\n 'мне приходится работать каждый выходной',\n 'свет солнца согревает раненую кицунэ',\n 'любовь всегда находит путь',\n 'контакты отпали',\n 'солнце садилось за горизонт',\n 'греки придумали салат',\n 'пить вишневый компот',\n 'образование',\n 'каменный пол не был отоплён',\n 'горячий шоколад в холодную погоду',\n 'важно быть благодарным за то что имеешь',\n 'забудем об этом и начнем все заново',\n 'кофе с печеньем идеальная пара',\n 'глобус порежет империя',\n 'истинно счастливый человек видет благо во всем',\n 'очки с салфеткой',\n 'спидометр',\n 'самбо это случайно не вид боевого искусства',\n 'сделать то что скажешь лучший способ уважаться',\n 'поддержка друзей важна в трудные времена',\n 'кошка лежит на окне и мурлычет',\n 'мы бы хотели позавтракать',\n 'подстричь ногти',\n 'кот мурлыкает',\n 'сигареты детям не игрушка',\n 'твоя поддержка была для меня невероятно важна',\n 'беседуем с друзьями',\n 'маленький шаг может привести к большому успеху',\n 'грабили святыни',\n 'ты ездишь на работу на машине',\n 'пачка денег']"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T16:16:11.401175Z","iopub.execute_input":"2023-05-13T16:16:11.401879Z","iopub.status.idle":"2023-05-13T16:16:11.430020Z","shell.execute_reply.started":"2023-05-13T16:16:11.401838Z","shell.execute_reply":"2023-05-13T16:16:11.428960Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(directory):\n    total_duration = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            filepath = os.path.join(directory, filename)\n            with wave.open(filepath, 'r') as wav_file:\n                frames = wav_file.getnframes()\n                rate = wav_file.getframerate()\n                duration = frames / float(rate)\n                total_duration += duration\n    return total_duration\n\ndirectory = '/kaggle/input/upd-speech/mono_voice'\ntotal_duration = get_wav_duration(directory)\nprint('Total duration of WAV files:', total_duration, 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T15:43:23.346284Z","iopub.execute_input":"2023-05-13T15:43:23.347419Z","iopub.status.idle":"2023-05-13T15:43:31.279931Z","shell.execute_reply.started":"2023-05-13T15:43:23.347352Z","shell.execute_reply":"2023-05-13T15:43:31.278798Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Total duration of WAV files: 9206.333562499987 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"def format_time(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))\nseconds = 3661\nformatted_time = format_time(total_duration)\nprint(formatted_time)  # Output: '01:01:01'","metadata":{"execution":{"iopub.status.busy":"2023-05-13T15:43:31.283914Z","iopub.execute_input":"2023-05-13T15:43:31.284246Z","iopub.status.idle":"2023-05-13T15:43:31.293799Z","shell.execute_reply.started":"2023-05-13T15:43:31.284213Z","shell.execute_reply":"2023-05-13T15:43:31.292466Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"02:33:26\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}