{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5321255,"sourceType":"datasetVersion","datasetId":3091651},{"sourceId":5618710,"sourceType":"datasetVersion","datasetId":3230790},{"sourceId":5677279,"sourceType":"datasetVersion","datasetId":2989949,"isSourceIdPinned":false},{"sourceId":5677298,"sourceType":"datasetVersion","datasetId":3213578,"isSourceIdPinned":false},{"sourceId":5677449,"sourceType":"datasetVersion","datasetId":3071831,"isSourceIdPinned":false},{"sourceId":5760288,"sourceType":"datasetVersion","datasetId":3311237}],"dockerImageVersionId":30461,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np\nimport matplotlib","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:16.809768Z","iopub.execute_input":"2023-11-17T14:20:16.810537Z","iopub.status.idle":"2023-11-17T14:20:19.484290Z","shell.execute_reply.started":"2023-11-17T14:20:16.810495Z","shell.execute_reply":"2023-11-17T14:20:19.482783Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport librosa\n\nfile = pd.read_excel('/kaggle/input/rus-speech/Speeches.xlsx')\ny = [sentence for sentence in file['Русская речь']]\n\ndir_name = \"/kaggle/input/upd-speech/mono_voice/\"\nfiles_in_dir = os.listdir(dir_name)\n\nX = []\ni = 1\n\nfor e in range(1, 2001):\n    file_name = f'{e}.wav'\n    sampl = librosa.load(dir_name + file_name, sr=16000)[0]\n    sampl = sampl[np.newaxis, :]\n    X.append(torch.Tensor(sampl))\n    if i % 100 == 0:\n        print(i)\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:19.486701Z","iopub.execute_input":"2023-11-17T14:20:19.487532Z","iopub.status.idle":"2023-11-17T14:20:50.451958Z","shell.execute_reply.started":"2023-11-17T14:20:19.487488Z","shell.execute_reply":"2023-11-17T14:20:50.450566Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n","output_type":"stream"}]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.453655Z","iopub.execute_input":"2023-11-17T14:20:50.454541Z","iopub.status.idle":"2023-11-17T14:20:50.534694Z","shell.execute_reply.started":"2023-11-17T14:20:50.454474Z","shell.execute_reply":"2023-11-17T14:20:50.533489Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0012, 0.0009, 0.0007]])"},"metadata":{}}]},{"cell_type":"code","source":"char_map = {\"а\": 0, \"б\": 1, \"в\": 2, \"г\": 3, \"д\": 4, \"е\": 5, \"ё\": 6, \"ж\": 7, \"з\": 8, \"и\": 9, \"й\": 10,\n            \"к\": 11, \"л\": 12, \"м\": 13, \"н\": 14, \"о\": 15, \"п\": 16, \"р\": 17, \"с\": 18, \"т\": 19, \"у\": 20,\n            \"ф\": 21, \"ч\": 22, \"ц\": 23, \"ш\": 24, \"щ\": 25, \"ъ\": 26, \"ы\": 27, \"ь\": 28, \"э\": 29, \"ю\": 30,\n            \"я\": 31, \"х\": 32, \" \": 33}\n\ndef remove_characters(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.replace('4', 'четыре').replace('Р-220', 'р двести двадцать').replace('6', 'шесть').replace(\"-\", \" \")\n    sentence = ''.join(filter(lambda x: x in char_map, sentence))\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ny = list(map(remove_characters, y))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.537478Z","iopub.execute_input":"2023-11-17T14:20:50.537829Z","iopub.status.idle":"2023-11-17T14:20:50.569831Z","shell.execute_reply.started":"2023-11-17T14:20:50.537796Z","shell.execute_reply":"2023-11-17T14:20:50.568599Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.model_selection import train_test_split\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nX_train = X[:1800]\nX_test = X[1800:]\ny_train = y[:1800]\ny_test = y[1800:]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.571116Z","iopub.execute_input":"2023-11-17T14:20:50.571443Z","iopub.status.idle":"2023-11-17T14:20:50.578603Z","shell.execute_reply.started":"2023-11-17T14:20:50.571411Z","shell.execute_reply":"2023-11-17T14:20:50.577484Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'from sklearn.model_selection import train_test_split\\n\\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\\nX_train = X[:1800]\\nX_test = X[1800:]\\ny_train = y[:1800]\\ny_test = y[1800:]'"},"metadata":{}}]},{"cell_type":"code","source":"X_train = X\nX = []","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.580201Z","iopub.execute_input":"2023-11-17T14:20:50.581020Z","iopub.status.idle":"2023-11-17T14:20:50.587509Z","shell.execute_reply.started":"2023-11-17T14:20:50.580977Z","shell.execute_reply":"2023-11-17T14:20:50.586299Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for tensor in X_train:\n    tensor = tensor.squeeze()\n    X.append(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.588956Z","iopub.execute_input":"2023-11-17T14:20:50.589334Z","iopub.status.idle":"2023-11-17T14:20:50.605411Z","shell.execute_reply.started":"2023-11-17T14:20:50.589302Z","shell.execute_reply":"2023-11-17T14:20:50.604151Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max_tensor = max(X, key=lambda x: x.numel())\n\nprint(max_tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.607205Z","iopub.execute_input":"2023-11-17T14:20:50.607554Z","iopub.status.idle":"2023-11-17T14:20:50.614738Z","shell.execute_reply.started":"2023-11-17T14:20:50.607521Z","shell.execute_reply":"2023-11-17T14:20:50.613347Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"torch.Size([213829])\n","output_type":"stream"}]},{"cell_type":"code","source":"type(X[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.616050Z","iopub.execute_input":"2023-11-17T14:20:50.616719Z","iopub.status.idle":"2023-11-17T14:20:50.626084Z","shell.execute_reply.started":"2023-11-17T14:20:50.616683Z","shell.execute_reply":"2023-11-17T14:20:50.624817Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.630509Z","iopub.execute_input":"2023-11-17T14:20:50.630874Z","iopub.status.idle":"2023-11-17T14:20:50.639289Z","shell.execute_reply.started":"2023-11-17T14:20:50.630843Z","shell.execute_reply":"2023-11-17T14:20:50.638264Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([0.0000, 0.0000, 0.0000,  ..., 0.0012, 0.0009, 0.0007])"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# Задаем желаемый размер\ndesired_size = (213830,)\nresized_tensors = []\n\nfor tensor in X:\n    # Рассчитываем разницу в размерах\n    padding = [0] * (len(desired_size) * 2)  # padding = [0, 0, 0, 0, 0, 0]\n    padding[:len(desired_size)] = [(desired_size[i] - tensor.shape[i]) for i in range(len(desired_size))]  # padding[:1] = [(6 - 3) // 2] = [1]\n\n    # Применяем padding\n    padded_tensor = F.pad(tensor, padding, value=0)\n    resized_tensors.append(padded_tensor)\n    \nX = resized_tensors","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:50.640675Z","iopub.execute_input":"2023-11-17T14:20:50.641065Z","iopub.status.idle":"2023-11-17T14:20:51.357240Z","shell.execute_reply.started":"2023-11-17T14:20:50.641031Z","shell.execute_reply":"2023-11-17T14:20:51.355944Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X[5].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.358812Z","iopub.execute_input":"2023-11-17T14:20:51.359306Z","iopub.status.idle":"2023-11-17T14:20:51.370250Z","shell.execute_reply.started":"2023-11-17T14:20:51.359259Z","shell.execute_reply":"2023-11-17T14:20:51.369029Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"torch.Size([213830])"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass AudioDataset(Dataset):\n    def __init__(self, audio_list):\n        self.audio_list = audio_list\n        #self.text_list = text_list\n        \n    def __len__(self):\n        return len(self.audio_list)\n    \n    def __getitem__(self, index):\n        audio = self.audio_list[index]\n        #text = self.text_list[index]\n        return audio #, text","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.371553Z","iopub.execute_input":"2023-11-17T14:20:51.371916Z","iopub.status.idle":"2023-11-17T14:20:51.380750Z","shell.execute_reply.started":"2023-11-17T14:20:51.371864Z","shell.execute_reply":"2023-11-17T14:20:51.379414Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n# Определение генератора\nclass Generator(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(Generator, self).__init__()\n        self.fc = nn.Linear(input_dim, 400)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(400, 800)\n        self.fc3 = nn.Linear(800, output_dim)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        x = self.relu(self.fc(x))\n        x = self.relu(self.fc2(x))\n        x = self.tanh(self.fc3(x))\n        return x\n\n# Определение дискриминатора\nclass Discriminator(nn.Module):\n    def __init__(self, input_dim):\n        super(Discriminator, self).__init__()\n        self.fc = nn.Linear(input_dim, 1024)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.relu(self.fc(x))\n        x = self.relu(self.fc2(x))\n        x = self.sigmoid(self.fc3(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.382588Z","iopub.execute_input":"2023-11-17T14:20:51.383985Z","iopub.status.idle":"2023-11-17T14:20:51.399087Z","shell.execute_reply.started":"2023-11-17T14:20:51.383931Z","shell.execute_reply":"2023-11-17T14:20:51.397736Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Функция обучения GAN\ndef train_gan(generator, discriminator, dataloader, num_epochs, device):\n    criterion = nn.BCELoss()\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n\n    for epoch in range(num_epochs):\n        for i, real_data in enumerate(dataloader):\n            \n            \"\"\"\"\"\"real_data = []\n            # Преобразовываем каждый элемент в тензор и перемещаем на устройство\n            for item in dataloader:\n                item = item.to(device)\n                real_data.append(item)\"\"\"\"\"\"\n            \n            real_data = real_data.to(device)\n\n            # Обучение дискриминатора\n            d_optimizer.zero_grad()\n            real_labels = torch.ones(real_data.size(0), 1).to(device)\n            fake_labels = torch.zeros(real_data.size(0), 1).to(device)\n\n            # Пропуск реальных данных через дискриминатор\n            real_outputs = discriminator(real_data)\n            \n            print(f'real_outputs: {real_outputs}')\n            print(f'real_labels: {real_labels.size()}')\n            \n            d_loss_real = criterion(real_outputs, real_labels)\n\n            # Генерация фейковых данных и пропуск их через дискриминатор\n            noise = torch.randn(real_data.size(0), 100).to(device)\n            fake_data = generator(noise)\n            fake_outputs = discriminator(fake_data.detach())\n            d_loss_fake = criterion(fake_outputs, fake_labels)\n\n            # Общая потеря дискриминатора\n            d_loss = d_loss_real + d_loss_fake\n            d_loss.backward()\n            d_optimizer.step()\n\n            # Обучение генератора\n            g_optimizer.zero_grad()\n            fake_outputs = discriminator(fake_data)\n            g_loss = criterion(fake_outputs, real_labels)\n            g_loss.backward()\n            g_optimizer.step()\n\n            # Вывод промежуточной информации\n            if (i + 1) % 100 == 0:\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}],\"\n                      f\" d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.400549Z","iopub.execute_input":"2023-11-17T14:20:51.400882Z","iopub.status.idle":"2023-11-17T14:20:51.418809Z","shell.execute_reply.started":"2023-11-17T14:20:51.400849Z","shell.execute_reply":"2023-11-17T14:20:51.417538Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'# Функция обучения GAN\\ndef train_gan(generator, discriminator, dataloader, num_epochs, device):\\n    criterion = nn.BCELoss()\\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\\n\\n    for epoch in range(num_epochs):\\n        for i, real_data in enumerate(dataloader):\\n            \\n            real_data = []\\n            # Преобразовываем каждый элемент в тензор и перемещаем на устройство\\n            for item in dataloader:\\n                item = item.to(device)\\n                real_data.append(item)\\n            \\n            real_data = real_data.to(device)\\n\\n            # Обучение дискриминатора\\n            d_optimizer.zero_grad()\\n            real_labels = torch.ones(real_data.size(0), 1).to(device)\\n            fake_labels = torch.zeros(real_data.size(0), 1).to(device)\\n\\n            # Пропуск реальных данных через дискриминатор\\n            real_outputs = discriminator(real_data)\\n            \\n            print(f\\'real_outputs: {real_outputs}\\')\\n            print(f\\'real_labels: {real_labels.size()}\\')\\n            \\n            d_loss_real = criterion(real_outputs, real_labels)\\n\\n            # Генерация фейковых данных и пропуск их через дискриминатор\\n            noise = torch.randn(real_data.size(0), 100).to(device)\\n            fake_data = generator(noise)\\n            fake_outputs = discriminator(fake_data.detach())\\n            d_loss_fake = criterion(fake_outputs, fake_labels)\\n\\n            # Общая потеря дискриминатора\\n            d_loss = d_loss_real + d_loss_fake\\n            d_loss.backward()\\n            d_optimizer.step()\\n\\n            # Обучение генератора\\n            g_optimizer.zero_grad()\\n            fake_outputs = discriminator(fake_data)\\n            g_loss = criterion(fake_outputs, real_labels)\\n            g_loss.backward()\\n            g_optimizer.step()\\n\\n            # Вывод промежуточной информации\\n            if (i + 1) % 100 == 0:\\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}],\"\\n                      f\" d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")'"},"metadata":{}}]},{"cell_type":"code","source":"# Функция обучения GAN\ndef train_gan(generator, discriminator, dataloader, num_epochs, device):\n    criterion = nn.BCELoss()\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n\n    for epoch in range(num_epochs):\n        for i, real_data in enumerate(dataloader):\n            \n            #print(real_data)\n            #real_data = torch.tensor(real_data)\n            #real_data = [torch.tensor(sample) for sample in real_data]\n            real_data = real_data.to(device)\n                        \n            #data = [torch.tensor(sample) for sample in data]\n\n            # Обучение дискриминатора\n            d_optimizer.zero_grad()\n            real_labels = torch.ones(real_data.size(0), 1).to(device)\n            fake_labels = torch.zeros(real_data.size(0), 1).to(device)\n            \n\n            # Пропуск реальных данных через дискриминатор\n            real_outputs = discriminator(real_data)\n            d_loss_real = criterion(real_outputs, real_labels)\n\n            # Генерация фейковых данных и пропуск их через дискриминатор\n            noise = torch.randn(real_data.size(0), 100).to(device)\n            fake_data = generator(noise)\n            fake_outputs = discriminator(fake_data.detach())\n            d_loss_fake = criterion(fake_outputs, fake_labels)\n\n            # Общая потеря дискриминатора\n            d_loss = d_loss_real + d_loss_fake\n            d_loss.backward()\n            d_optimizer.step()\n\n            # Обучение генератора\n            g_optimizer.zero_grad()\n            fake_outputs = discriminator(fake_data)\n            g_loss = criterion(fake_outputs, real_labels)\n            g_loss.backward()\n            g_optimizer.step()\n\n            # Вывод промежуточной информации\n            if (i + 1) % 100 == 0:\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}],\"\n                      f\" d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.420427Z","iopub.execute_input":"2023-11-17T14:20:51.420786Z","iopub.status.idle":"2023-11-17T14:20:51.436208Z","shell.execute_reply.started":"2023-11-17T14:20:51.420752Z","shell.execute_reply":"2023-11-17T14:20:51.435128Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Параметры генератора и дискриминатора\ninput_dim = 100  # Размерность входного шумового вектора\noutput_dim = 213830  # Размерность выходных данных (зависит от аудиоформата)\n\n# Создание генератора и дискриминатора\ngenerator = Generator(input_dim, output_dim).to(device)\ndiscriminator = Discriminator(output_dim).to(device)\n\n# Загрузка аудиоданных\ndataset = AudioDataset(X)  # Замените на свой собственный класс Dataset\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# Обучение GAN\nnum_epochs = 30\ntrain_gan(generator, discriminator, dataloader, num_epochs, device)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:20:51.437607Z","iopub.execute_input":"2023-11-17T14:20:51.438003Z","iopub.status.idle":"2023-11-17T14:21:29.091637Z","shell.execute_reply.started":"2023-11-17T14:20:51.437959Z","shell.execute_reply":"2023-11-17T14:21:29.089961Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch [1/30], Step [100/500], d_loss: 0.7460, g_loss: 38.6710\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2365063984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Обучение GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/810842331.py\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, dataloader, num_epochs, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Генерация фейковых данных и пропуск их через дискриминатор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mfake_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"dataloader.batch_size","metadata":{"execution":{"iopub.status.busy":"2023-11-17T12:23:59.589715Z","iopub.execute_input":"2023-11-17T12:23:59.590118Z","iopub.status.idle":"2023-11-17T12:23:59.599208Z","shell.execute_reply.started":"2023-11-17T12:23:59.590081Z","shell.execute_reply":"2023-11-17T12:23:59.598116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(generator.state_dict(), 'generator.pth')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T12:03:43.278656Z","iopub.execute_input":"2023-11-17T12:03:43.279611Z","iopub.status.idle":"2023-11-17T12:03:44.137397Z","shell.execute_reply.started":"2023-11-17T12:03:43.279572Z","shell.execute_reply":"2023-11-17T12:03:44.136080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создайте экземпляр генератора\ngenerator_1 = Generator(100, 213830)\n\n# Загрузите сохраненные веса в генератор\ngenerator_1.load_state_dict(torch.load('generator.pth'))\n\n# Переведите генератор в режим вывода\ngenerator_1.eval()\n\n# Сгенерируйте данные, передав случайные входные данные через генератор\nnum_samples = 10  # Количество сэмплов, которые вы хотите сгенерировать\nlatent_dim = 100\nrandom_input = torch.randn(num_samples, latent_dim)  # Здесь latent_dim - размерность входного шумового вектора\n\n# Перенесите случайные входные данные на GPU, если используете CUDA\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nrandom_input = random_input.to(device)\n\n# Генерация данных\ngenerated_data = generator_1(random_input)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T12:10:51.432722Z","iopub.execute_input":"2023-11-17T12:10:51.433474Z","iopub.status.idle":"2023-11-17T12:10:53.018258Z","shell.execute_reply.started":"2023-11-17T12:10:51.433438Z","shell.execute_reply":"2023-11-17T12:10:53.016578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wave\n\ndef get_wav_duration(directory):\n    total_duration = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            filepath = os.path.join(directory, filename)\n            with wave.open(filepath, 'r') as wav_file:\n                frames = wav_file.getnframes()\n                rate = wav_file.getframerate()\n                duration = frames / float(rate)\n                total_duration += duration\n    return total_duration\n\ndirectory = '/kaggle/input/upd-speech/mono_voice'\ntotal_duration = get_wav_duration(directory)\nprint('Total duration of WAV files:', total_duration, 'seconds')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:28:40.846121Z","iopub.status.idle":"2023-11-15T15:28:40.847287Z","shell.execute_reply.started":"2023-11-15T15:28:40.846975Z","shell.execute_reply":"2023-11-15T15:28:40.847011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return '{:02d}:{:02d}:{:02d}'.format(int(hours), int(minutes), int(seconds))\nseconds = 3661\nformatted_time = format_time(total_duration)\nprint(formatted_time)  # Output: '01:01:01'","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:28:40.849528Z","iopub.status.idle":"2023-11-15T15:28:40.850430Z","shell.execute_reply.started":"2023-11-15T15:28:40.850119Z","shell.execute_reply":"2023-11-15T15:28:40.850152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}